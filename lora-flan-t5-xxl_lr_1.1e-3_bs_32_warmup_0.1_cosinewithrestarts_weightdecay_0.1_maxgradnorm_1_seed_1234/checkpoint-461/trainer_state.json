{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 461,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "learning_rate": 4.761904761904762e-06,
      "loss": 1.1617,
      "step": 1
    },
    {
      "epoch": 0.0,
      "learning_rate": 9.523809523809525e-06,
      "loss": 1.1898,
      "step": 2
    },
    {
      "epoch": 0.01,
      "learning_rate": 1.4285714285714287e-05,
      "loss": 1.327,
      "step": 3
    },
    {
      "epoch": 0.01,
      "learning_rate": 1.904761904761905e-05,
      "loss": 1.218,
      "step": 4
    },
    {
      "epoch": 0.01,
      "learning_rate": 2.380952380952381e-05,
      "loss": 1.2591,
      "step": 5
    },
    {
      "epoch": 0.01,
      "learning_rate": 2.8571428571428574e-05,
      "loss": 1.1492,
      "step": 6
    },
    {
      "epoch": 0.02,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 1.208,
      "step": 7
    },
    {
      "epoch": 0.02,
      "learning_rate": 3.80952380952381e-05,
      "loss": 1.174,
      "step": 8
    },
    {
      "epoch": 0.02,
      "learning_rate": 4.2857142857142856e-05,
      "loss": 1.3839,
      "step": 9
    },
    {
      "epoch": 0.02,
      "learning_rate": 4.761904761904762e-05,
      "loss": 1.4591,
      "step": 10
    },
    {
      "epoch": 0.02,
      "learning_rate": 5.2380952380952384e-05,
      "loss": 1.1504,
      "step": 11
    },
    {
      "epoch": 0.03,
      "learning_rate": 5.714285714285715e-05,
      "loss": 1.1396,
      "step": 12
    },
    {
      "epoch": 0.03,
      "learning_rate": 6.19047619047619e-05,
      "loss": 1.2924,
      "step": 13
    },
    {
      "epoch": 0.03,
      "learning_rate": 6.666666666666667e-05,
      "loss": 1.2455,
      "step": 14
    },
    {
      "epoch": 0.03,
      "learning_rate": 7.142857142857142e-05,
      "loss": 1.2319,
      "step": 15
    },
    {
      "epoch": 0.03,
      "learning_rate": 7.61904761904762e-05,
      "loss": 1.2865,
      "step": 16
    },
    {
      "epoch": 0.04,
      "learning_rate": 8.095238095238096e-05,
      "loss": 1.3262,
      "step": 17
    },
    {
      "epoch": 0.04,
      "learning_rate": 8.571428571428571e-05,
      "loss": 1.2479,
      "step": 18
    },
    {
      "epoch": 0.04,
      "learning_rate": 9.047619047619049e-05,
      "loss": 1.1708,
      "step": 19
    },
    {
      "epoch": 0.04,
      "learning_rate": 9.523809523809524e-05,
      "loss": 1.1614,
      "step": 20
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0001,
      "loss": 1.1747,
      "step": 21
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00010476190476190477,
      "loss": 1.2501,
      "step": 22
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00010952380952380953,
      "loss": 1.148,
      "step": 23
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0001142857142857143,
      "loss": 1.0812,
      "step": 24
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00011904761904761905,
      "loss": 1.0734,
      "step": 25
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0001238095238095238,
      "loss": 0.9967,
      "step": 26
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.00012857142857142858,
      "loss": 1.1717,
      "step": 27
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.00013333333333333334,
      "loss": 1.1434,
      "step": 28
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0001380952380952381,
      "loss": 1.1338,
      "step": 29
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00014285714285714284,
      "loss": 1.2228,
      "step": 30
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00014761904761904763,
      "loss": 1.1715,
      "step": 31
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0001523809523809524,
      "loss": 1.2374,
      "step": 32
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00015714285714285713,
      "loss": 1.2187,
      "step": 33
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00016190476190476192,
      "loss": 1.0943,
      "step": 34
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0001666666666666667,
      "loss": 1.1378,
      "step": 35
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00017142857142857143,
      "loss": 1.2517,
      "step": 36
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0001761904761904762,
      "loss": 1.1442,
      "step": 37
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00018095238095238098,
      "loss": 1.2299,
      "step": 38
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00018571428571428572,
      "loss": 0.9945,
      "step": 39
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.00019047619047619048,
      "loss": 1.1778,
      "step": 40
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.00019523809523809527,
      "loss": 1.1461,
      "step": 41
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0002,
      "loss": 1.0111,
      "step": 42
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.00020476190476190477,
      "loss": 1.0295,
      "step": 43
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00020952380952380954,
      "loss": 1.0295,
      "step": 44
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0002142857142857143,
      "loss": 1.223,
      "step": 45
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00021904761904761907,
      "loss": 1.0604,
      "step": 46
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0002238095238095238,
      "loss": 1.1185,
      "step": 47
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0002285714285714286,
      "loss": 1.1667,
      "step": 48
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.00023333333333333336,
      "loss": 0.9367,
      "step": 49
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0002380952380952381,
      "loss": 1.0872,
      "step": 50
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.00024285714285714286,
      "loss": 1.1487,
      "step": 51
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0002476190476190476,
      "loss": 1.1709,
      "step": 52
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0002523809523809524,
      "loss": 1.1224,
      "step": 53
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.00025714285714285715,
      "loss": 0.9535,
      "step": 54
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0002619047619047619,
      "loss": 0.9769,
      "step": 55
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0002666666666666667,
      "loss": 1.0454,
      "step": 56
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.00027142857142857144,
      "loss": 1.1368,
      "step": 57
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0002761904761904762,
      "loss": 0.9113,
      "step": 58
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.00028095238095238097,
      "loss": 1.1784,
      "step": 59
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0002857142857142857,
      "loss": 1.1113,
      "step": 60
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0002904761904761905,
      "loss": 1.1161,
      "step": 61
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.00029523809523809526,
      "loss": 1.0205,
      "step": 62
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0003,
      "loss": 1.112,
      "step": 63
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0003047619047619048,
      "loss": 1.1515,
      "step": 64
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.00030952380952380956,
      "loss": 1.0219,
      "step": 65
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.00031428571428571427,
      "loss": 1.0658,
      "step": 66
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0003190476190476191,
      "loss": 1.1579,
      "step": 67
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.00032380952380952385,
      "loss": 1.1044,
      "step": 68
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.00032857142857142856,
      "loss": 1.1088,
      "step": 69
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0003333333333333334,
      "loss": 1.2589,
      "step": 70
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0003380952380952381,
      "loss": 1.1169,
      "step": 71
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00034285714285714285,
      "loss": 1.0543,
      "step": 72
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00034761904761904767,
      "loss": 1.0022,
      "step": 73
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0003523809523809524,
      "loss": 1.1101,
      "step": 74
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00035714285714285714,
      "loss": 1.0828,
      "step": 75
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00036190476190476196,
      "loss": 1.0609,
      "step": 76
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00036666666666666667,
      "loss": 1.0141,
      "step": 77
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00037142857142857143,
      "loss": 0.9626,
      "step": 78
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00037619047619047625,
      "loss": 1.1428,
      "step": 79
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00038095238095238096,
      "loss": 1.2117,
      "step": 80
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0003857142857142857,
      "loss": 1.0578,
      "step": 81
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00039047619047619055,
      "loss": 1.1568,
      "step": 82
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00039523809523809526,
      "loss": 1.0763,
      "step": 83
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0004,
      "loss": 1.1138,
      "step": 84
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0004047619047619048,
      "loss": 1.2269,
      "step": 85
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00040952380952380955,
      "loss": 0.9838,
      "step": 86
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0004142857142857143,
      "loss": 1.0871,
      "step": 87
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0004190476190476191,
      "loss": 1.1948,
      "step": 88
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00042380952380952384,
      "loss": 1.0919,
      "step": 89
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0004285714285714286,
      "loss": 1.0509,
      "step": 90
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.00043333333333333337,
      "loss": 1.0449,
      "step": 91
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.00043809523809523813,
      "loss": 1.0459,
      "step": 92
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0004428571428571429,
      "loss": 1.0923,
      "step": 93
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0004476190476190476,
      "loss": 1.1249,
      "step": 94
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0004523809523809524,
      "loss": 1.0277,
      "step": 95
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0004571428571428572,
      "loss": 1.0956,
      "step": 96
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0004619047619047619,
      "loss": 1.1037,
      "step": 97
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0004666666666666667,
      "loss": 1.1841,
      "step": 98
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0004714285714285714,
      "loss": 1.0986,
      "step": 99
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0004761904761904762,
      "loss": 0.9536,
      "step": 100
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.000480952380952381,
      "loss": 1.1791,
      "step": 101
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0004857142857142857,
      "loss": 1.1337,
      "step": 102
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0004904761904761905,
      "loss": 1.1143,
      "step": 103
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0004952380952380952,
      "loss": 1.0377,
      "step": 104
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0005,
      "loss": 1.2168,
      "step": 105
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0005047619047619048,
      "loss": 1.2536,
      "step": 106
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0005095238095238095,
      "loss": 0.9917,
      "step": 107
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0005142857142857143,
      "loss": 1.064,
      "step": 108
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0005190476190476191,
      "loss": 0.9559,
      "step": 109
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0005238095238095238,
      "loss": 1.1401,
      "step": 110
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0005285714285714286,
      "loss": 1.1446,
      "step": 111
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0005333333333333334,
      "loss": 1.0248,
      "step": 112
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0005380952380952381,
      "loss": 1.0981,
      "step": 113
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0005428571428571429,
      "loss": 1.1335,
      "step": 114
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0005476190476190477,
      "loss": 1.2065,
      "step": 115
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0005523809523809524,
      "loss": 1.0193,
      "step": 116
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0005571428571428571,
      "loss": 0.9503,
      "step": 117
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0005619047619047619,
      "loss": 1.1233,
      "step": 118
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0005666666666666667,
      "loss": 1.0532,
      "step": 119
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0005714285714285714,
      "loss": 0.9534,
      "step": 120
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0005761904761904762,
      "loss": 1.1166,
      "step": 121
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.000580952380952381,
      "loss": 1.0529,
      "step": 122
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0005857142857142857,
      "loss": 1.0593,
      "step": 123
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0005904761904761905,
      "loss": 1.0525,
      "step": 124
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0005952380952380953,
      "loss": 1.061,
      "step": 125
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0006,
      "loss": 1.1451,
      "step": 126
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0006047619047619048,
      "loss": 1.0474,
      "step": 127
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0006095238095238096,
      "loss": 1.1152,
      "step": 128
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0006142857142857142,
      "loss": 1.1225,
      "step": 129
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0006190476190476191,
      "loss": 1.1105,
      "step": 130
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0006238095238095239,
      "loss": 1.0207,
      "step": 131
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0006285714285714285,
      "loss": 0.9561,
      "step": 132
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0006333333333333334,
      "loss": 0.9768,
      "step": 133
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0006380952380952382,
      "loss": 1.2357,
      "step": 134
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0006428571428571428,
      "loss": 1.0368,
      "step": 135
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0006476190476190477,
      "loss": 1.1775,
      "step": 136
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0006523809523809525,
      "loss": 1.0268,
      "step": 137
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0006571428571428571,
      "loss": 0.952,
      "step": 138
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.000661904761904762,
      "loss": 1.1912,
      "step": 139
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0006666666666666668,
      "loss": 1.0609,
      "step": 140
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0006714285714285714,
      "loss": 1.1549,
      "step": 141
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0006761904761904762,
      "loss": 1.1871,
      "step": 142
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.000680952380952381,
      "loss": 1.095,
      "step": 143
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0006857142857142857,
      "loss": 1.1381,
      "step": 144
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0006904761904761905,
      "loss": 0.9804,
      "step": 145
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0006952380952380953,
      "loss": 1.08,
      "step": 146
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0007,
      "loss": 1.045,
      "step": 147
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0007047619047619048,
      "loss": 0.9514,
      "step": 148
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0007095238095238096,
      "loss": 1.0355,
      "step": 149
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0007142857142857143,
      "loss": 0.9885,
      "step": 150
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.000719047619047619,
      "loss": 1.1328,
      "step": 151
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0007238095238095239,
      "loss": 1.1715,
      "step": 152
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0007285714285714286,
      "loss": 1.1689,
      "step": 153
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0007333333333333333,
      "loss": 1.1137,
      "step": 154
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0007380952380952382,
      "loss": 1.1983,
      "step": 155
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0007428571428571429,
      "loss": 1.1942,
      "step": 156
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0007476190476190476,
      "loss": 0.9955,
      "step": 157
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0007523809523809525,
      "loss": 1.1777,
      "step": 158
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0007571428571428572,
      "loss": 1.085,
      "step": 159
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0007619047619047619,
      "loss": 1.039,
      "step": 160
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0007666666666666668,
      "loss": 1.136,
      "step": 161
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0007714285714285715,
      "loss": 1.4059,
      "step": 162
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0007761904761904762,
      "loss": 1.0174,
      "step": 163
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0007809523809523811,
      "loss": 1.066,
      "step": 164
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0007857142857142857,
      "loss": 1.2442,
      "step": 165
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0007904761904761905,
      "loss": 1.1203,
      "step": 166
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0007952380952380953,
      "loss": 1.1088,
      "step": 167
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0008,
      "loss": 1.2299,
      "step": 168
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0008047619047619048,
      "loss": 0.999,
      "step": 169
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0008095238095238096,
      "loss": 1.0817,
      "step": 170
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0008142857142857143,
      "loss": 1.092,
      "step": 171
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0008190476190476191,
      "loss": 1.1651,
      "step": 172
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0008238095238095239,
      "loss": 0.9344,
      "step": 173
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0008285714285714286,
      "loss": 1.2583,
      "step": 174
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0008333333333333334,
      "loss": 1.1566,
      "step": 175
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0008380952380952382,
      "loss": 0.9053,
      "step": 176
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0008428571428571429,
      "loss": 1.1809,
      "step": 177
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0008476190476190477,
      "loss": 1.1128,
      "step": 178
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0008523809523809524,
      "loss": 1.1149,
      "step": 179
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0008571428571428572,
      "loss": 1.0439,
      "step": 180
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.000861904761904762,
      "loss": 1.054,
      "step": 181
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0008666666666666667,
      "loss": 1.2299,
      "step": 182
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0008714285714285715,
      "loss": 1.0377,
      "step": 183
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0008761904761904763,
      "loss": 0.9899,
      "step": 184
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0008809523809523809,
      "loss": 1.0733,
      "step": 185
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0008857142857142858,
      "loss": 1.068,
      "step": 186
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0008904761904761906,
      "loss": 0.9688,
      "step": 187
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0008952380952380952,
      "loss": 1.0943,
      "step": 188
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0009000000000000001,
      "loss": 1.0366,
      "step": 189
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0009047619047619048,
      "loss": 1.1229,
      "step": 190
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0009095238095238095,
      "loss": 1.0948,
      "step": 191
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0009142857142857144,
      "loss": 1.1893,
      "step": 192
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0009190476190476191,
      "loss": 1.0768,
      "step": 193
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0009238095238095238,
      "loss": 0.9483,
      "step": 194
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0009285714285714286,
      "loss": 1.0088,
      "step": 195
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0009333333333333334,
      "loss": 1.0603,
      "step": 196
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0009380952380952381,
      "loss": 1.1701,
      "step": 197
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0009428571428571429,
      "loss": 1.1368,
      "step": 198
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0009476190476190477,
      "loss": 1.0364,
      "step": 199
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0009523809523809524,
      "loss": 1.2108,
      "step": 200
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0009571428571428571,
      "loss": 1.1637,
      "step": 201
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.000961904761904762,
      "loss": 1.0132,
      "step": 202
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0009666666666666667,
      "loss": 1.1213,
      "step": 203
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0009714285714285714,
      "loss": 1.1232,
      "step": 204
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0009761904761904763,
      "loss": 1.1797,
      "step": 205
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.000980952380952381,
      "loss": 1.0739,
      "step": 206
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0009857142857142857,
      "loss": 1.0057,
      "step": 207
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0009904761904761905,
      "loss": 1.0424,
      "step": 208
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0009952380952380953,
      "loss": 1.1246,
      "step": 209
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.001,
      "loss": 1.0387,
      "step": 210
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0010047619047619048,
      "loss": 1.0153,
      "step": 211
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0010095238095238095,
      "loss": 1.2063,
      "step": 212
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0010142857142857143,
      "loss": 1.1072,
      "step": 213
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.001019047619047619,
      "loss": 1.2984,
      "step": 214
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0010238095238095238,
      "loss": 1.0941,
      "step": 215
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0010285714285714286,
      "loss": 1.1715,
      "step": 216
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0010333333333333334,
      "loss": 1.18,
      "step": 217
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0010380952380952381,
      "loss": 1.0879,
      "step": 218
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001042857142857143,
      "loss": 1.0247,
      "step": 219
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0010476190476190477,
      "loss": 1.2003,
      "step": 220
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0010523809523809524,
      "loss": 0.9954,
      "step": 221
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0010571428571428572,
      "loss": 1.0825,
      "step": 222
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001061904761904762,
      "loss": 1.0917,
      "step": 223
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0010666666666666667,
      "loss": 0.9854,
      "step": 224
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0010714285714285715,
      "loss": 0.9895,
      "step": 225
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0010761904761904762,
      "loss": 1.1841,
      "step": 226
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.001080952380952381,
      "loss": 1.0046,
      "step": 227
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0010857142857142858,
      "loss": 0.9644,
      "step": 228
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0010904761904761905,
      "loss": 1.0903,
      "step": 229
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0010952380952380953,
      "loss": 1.183,
      "step": 230
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0011,
      "loss": 1.1775,
      "step": 231
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0010999993690210777,
      "loss": 1.1376,
      "step": 232
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0010999974760857582,
      "loss": 1.1125,
      "step": 233
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0010999943211983847,
      "loss": 1.1179,
      "step": 234
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0010999899043661965,
      "loss": 1.182,
      "step": 235
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0010999842255993272,
      "loss": 1.1112,
      "step": 236
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0010999772849108072,
      "loss": 1.0524,
      "step": 237
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0010999690823165612,
      "loss": 1.1455,
      "step": 238
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0010999596178354102,
      "loss": 1.0951,
      "step": 239
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0010999488914890697,
      "loss": 1.0976,
      "step": 240
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0010999369033021513,
      "loss": 1.0285,
      "step": 241
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0010999236533021615,
      "loss": 1.1058,
      "step": 242
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001099909141519502,
      "loss": 1.2302,
      "step": 243
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0010998933679874697,
      "loss": 1.0863,
      "step": 244
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0010998763327422561,
      "loss": 1.198,
      "step": 245
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0010998580358229486,
      "loss": 1.3188,
      "step": 246
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0010998384772715284,
      "loss": 1.1488,
      "step": 247
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0010998176571328723,
      "loss": 1.1904,
      "step": 248
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0010997955754547513,
      "loss": 1.188,
      "step": 249
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0010997722322878313,
      "loss": 0.9492,
      "step": 250
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.001099747627685672,
      "loss": 1.0807,
      "step": 251
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0010997217617047285,
      "loss": 1.1251,
      "step": 252
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0010996946344043492,
      "loss": 1.1194,
      "step": 253
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001099666245846777,
      "loss": 1.0665,
      "step": 254
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0010996365960971484,
      "loss": 1.3024,
      "step": 255
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0010996056852234936,
      "loss": 1.0386,
      "step": 256
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001099573513296737,
      "loss": 0.986,
      "step": 257
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0010995400803906962,
      "loss": 0.9906,
      "step": 258
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0010995053865820816,
      "loss": 1.1216,
      "step": 259
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0010994694319504971,
      "loss": 1.1592,
      "step": 260
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0010994322165784399,
      "loss": 1.1876,
      "step": 261
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0010993937405512988,
      "loss": 1.1403,
      "step": 262
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0010993540039573564,
      "loss": 1.1048,
      "step": 263
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001099313006887787,
      "loss": 1.0949,
      "step": 264
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001099270749436657,
      "loss": 1.0992,
      "step": 265
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0010992272317009244,
      "loss": 1.0634,
      "step": 266
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0010991824537804403,
      "loss": 0.9964,
      "step": 267
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0010991364157779452,
      "loss": 1.1986,
      "step": 268
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0010990891177990725,
      "loss": 1.2022,
      "step": 269
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0010990405599523457,
      "loss": 1.1281,
      "step": 270
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0010989907423491793,
      "loss": 1.2301,
      "step": 271
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0010989396651038782,
      "loss": 1.2892,
      "step": 272
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0010988873283336376,
      "loss": 1.1399,
      "step": 273
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0010988337321585426,
      "loss": 1.1814,
      "step": 274
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001098778876701568,
      "loss": 1.1877,
      "step": 275
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001098722762088578,
      "loss": 1.0681,
      "step": 276
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0010986653884483251,
      "loss": 1.1904,
      "step": 277
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0010986067559124524,
      "loss": 1.2438,
      "step": 278
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0010985468646154898,
      "loss": 1.2128,
      "step": 279
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0010984857146948562,
      "loss": 1.0908,
      "step": 280
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0010984233062908582,
      "loss": 1.2158,
      "step": 281
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0010983596395466896,
      "loss": 1.0402,
      "step": 282
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0010982947146084324,
      "loss": 1.1275,
      "step": 283
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0010982285316250542,
      "loss": 1.22,
      "step": 284
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0010981610907484104,
      "loss": 1.2701,
      "step": 285
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0010980923921332412,
      "loss": 1.1161,
      "step": 286
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001098022435937174,
      "loss": 1.286,
      "step": 287
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0010979512223207213,
      "loss": 1.1451,
      "step": 288
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00109787875144728,
      "loss": 1.1311,
      "step": 289
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0010978050234831326,
      "loss": 1.1808,
      "step": 290
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0010977300385974454,
      "loss": 1.1208,
      "step": 291
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.001097653796962269,
      "loss": 1.213,
      "step": 292
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0010975762987525375,
      "loss": 0.9636,
      "step": 293
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.001097497544146068,
      "loss": 1.0116,
      "step": 294
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0010974175333235605,
      "loss": 1.0733,
      "step": 295
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0010973362664685974,
      "loss": 1.1741,
      "step": 296
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.001097253743767643,
      "loss": 1.2162,
      "step": 297
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001097169965410043,
      "loss": 1.1103,
      "step": 298
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001097084931588024,
      "loss": 1.1546,
      "step": 299
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001096998642496694,
      "loss": 1.2778,
      "step": 300
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00109691109833404,
      "loss": 1.2551,
      "step": 301
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0010968222993009299,
      "loss": 1.0698,
      "step": 302
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00109673224560111,
      "loss": 1.1028,
      "step": 303
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001096640937441206,
      "loss": 1.0905,
      "step": 304
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0010965483750307212,
      "loss": 1.1723,
      "step": 305
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0010964545585820374,
      "loss": 1.201,
      "step": 306
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0010963594883104135,
      "loss": 1.2792,
      "step": 307
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.001096263164433985,
      "loss": 1.1579,
      "step": 308
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0010961655871737645,
      "loss": 1.149,
      "step": 309
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00109606675675364,
      "loss": 1.1148,
      "step": 310
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0010959666734003744,
      "loss": 1.1378,
      "step": 311
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0010958653373436059,
      "loss": 1.2014,
      "step": 312
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0010957627488158471,
      "loss": 1.1388,
      "step": 313
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0010956589080524841,
      "loss": 1.1348,
      "step": 314
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0010955538152917763,
      "loss": 1.0727,
      "step": 315
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0010954474707748558,
      "loss": 1.0331,
      "step": 316
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0010953398747457269,
      "loss": 1.1489,
      "step": 317
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0010952310274512651,
      "loss": 1.1908,
      "step": 318
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001095120929141217,
      "loss": 1.0383,
      "step": 319
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0010950095800682002,
      "loss": 1.2242,
      "step": 320
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0010948969804877014,
      "loss": 1.0906,
      "step": 321
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0010947831306580766,
      "loss": 1.1821,
      "step": 322
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.001094668030840551,
      "loss": 1.1381,
      "step": 323
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0010945516812992176,
      "loss": 1.0757,
      "step": 324
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0010944340823010367,
      "loss": 1.1926,
      "step": 325
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0010943152341158352,
      "loss": 1.0818,
      "step": 326
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0010941951370163072,
      "loss": 1.1263,
      "step": 327
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.001094073791278011,
      "loss": 0.963,
      "step": 328
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0010939511971793715,
      "loss": 1.1511,
      "step": 329
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0010938273550016762,
      "loss": 1.0638,
      "step": 330
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0010937022650290777,
      "loss": 1.0779,
      "step": 331
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0010935759275485905,
      "loss": 1.2071,
      "step": 332
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0010934483428500924,
      "loss": 1.1929,
      "step": 333
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0010933195112263227,
      "loss": 1.1106,
      "step": 334
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001093189432972881,
      "loss": 1.1699,
      "step": 335
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001093058108388228,
      "loss": 1.0622,
      "step": 336
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0010929255377736839,
      "loss": 1.0983,
      "step": 337
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001092791721433428,
      "loss": 1.2022,
      "step": 338
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0010926566596744975,
      "loss": 1.1773,
      "step": 339
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0010925203528067875,
      "loss": 1.0878,
      "step": 340
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0010923828011430497,
      "loss": 1.149,
      "step": 341
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0010922440049988924,
      "loss": 1.1312,
      "step": 342
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0010921039646927789,
      "loss": 0.9862,
      "step": 343
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0010919626805460272,
      "loss": 1.1026,
      "step": 344
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0010918201528828091,
      "loss": 1.0886,
      "step": 345
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0010916763820301508,
      "loss": 1.1676,
      "step": 346
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.001091531368317929,
      "loss": 1.1146,
      "step": 347
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0010913851120788738,
      "loss": 1.2471,
      "step": 348
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0010912376136485652,
      "loss": 1.1796,
      "step": 349
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001091088873365434,
      "loss": 1.1525,
      "step": 350
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0010909388915707602,
      "loss": 1.1309,
      "step": 351
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001090787668608672,
      "loss": 1.1094,
      "step": 352
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001090635204826146,
      "loss": 1.1464,
      "step": 353
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0010904815005730057,
      "loss": 1.2681,
      "step": 354
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0010903265562019204,
      "loss": 1.1556,
      "step": 355
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0010901703720684055,
      "loss": 1.016,
      "step": 356
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0010900129485308203,
      "loss": 1.0498,
      "step": 357
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0010898542859503683,
      "loss": 1.2061,
      "step": 358
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001089694384691096,
      "loss": 1.2446,
      "step": 359
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0010895332451198916,
      "loss": 1.1807,
      "step": 360
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001089370867606485,
      "loss": 1.0825,
      "step": 361
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0010892072525234462,
      "loss": 1.1481,
      "step": 362
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001089042400246185,
      "loss": 0.9913,
      "step": 363
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00108887631115295,
      "loss": 1.1531,
      "step": 364
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001088708985624827,
      "loss": 1.1672,
      "step": 365
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0010885404240457395,
      "loss": 1.2027,
      "step": 366
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001088370626802447,
      "loss": 1.071,
      "step": 367
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0010881995942845434,
      "loss": 1.3291,
      "step": 368
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001088027326884458,
      "loss": 1.2256,
      "step": 369
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0010878538249974525,
      "loss": 0.9931,
      "step": 370
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0010876790890216217,
      "loss": 1.2233,
      "step": 371
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0010875031193578924,
      "loss": 0.9766,
      "step": 372
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0010873259164100209,
      "loss": 1.066,
      "step": 373
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001087147480584594,
      "loss": 1.1488,
      "step": 374
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001086967812291027,
      "loss": 1.0561,
      "step": 375
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0010867869119415637,
      "loss": 1.3151,
      "step": 376
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0010866047799512738,
      "loss": 1.1597,
      "step": 377
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0010864214167380535,
      "loss": 0.9987,
      "step": 378
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0010862368227226244,
      "loss": 0.9232,
      "step": 379
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.001086050998328531,
      "loss": 1.0935,
      "step": 380
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0010858639439821423,
      "loss": 1.0011,
      "step": 381
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0010856756601126483,
      "loss": 1.0796,
      "step": 382
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0010854861471520604,
      "loss": 0.9847,
      "step": 383
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0010852954055352105,
      "loss": 1.1243,
      "step": 384
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0010851034356997489,
      "loss": 1.1682,
      "step": 385
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0010849102380861447,
      "loss": 1.2729,
      "step": 386
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0010847158131376835,
      "loss": 1.1838,
      "step": 387
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0010845201613004676,
      "loss": 1.0783,
      "step": 388
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001084323283023414,
      "loss": 0.9764,
      "step": 389
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0010841251787582534,
      "loss": 1.1822,
      "step": 390
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0010839258489595304,
      "loss": 1.0526,
      "step": 391
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0010837252940846006,
      "loss": 1.165,
      "step": 392
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001083523514593631,
      "loss": 1.0977,
      "step": 393
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0010833205109495984,
      "loss": 1.1967,
      "step": 394
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0010831162836182884,
      "loss": 1.0283,
      "step": 395
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0010829108330682941,
      "loss": 1.1945,
      "step": 396
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0010827041597710153,
      "loss": 1.1145,
      "step": 397
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0010824962642006577,
      "loss": 1.2762,
      "step": 398
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0010822871468342313,
      "loss": 1.1327,
      "step": 399
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.001082076808151549,
      "loss": 1.2921,
      "step": 400
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0010818652486352263,
      "loss": 1.1739,
      "step": 401
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0010816524687706803,
      "loss": 1.2279,
      "step": 402
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0010814384690461273,
      "loss": 1.2085,
      "step": 403
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0010812232499525835,
      "loss": 1.002,
      "step": 404
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0010810068119838621,
      "loss": 1.0878,
      "step": 405
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0010807891556365733,
      "loss": 1.0728,
      "step": 406
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0010805702814101227,
      "loss": 1.0781,
      "step": 407
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0010803501898067106,
      "loss": 1.1344,
      "step": 408
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0010801288813313303,
      "loss": 0.9994,
      "step": 409
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0010799063564917671,
      "loss": 1.2765,
      "step": 410
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0010796826157985974,
      "loss": 1.0887,
      "step": 411
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.001079457659765187,
      "loss": 1.2065,
      "step": 412
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0010792314889076907,
      "loss": 1.0861,
      "step": 413
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0010790041037450507,
      "loss": 1.1984,
      "step": 414
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0010787755047989946,
      "loss": 1.2797,
      "step": 415
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.001078545692594036,
      "loss": 1.0083,
      "step": 416
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0010783146676574715,
      "loss": 1.2851,
      "step": 417
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.001078082430519381,
      "loss": 1.2326,
      "step": 418
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0010778489817126252,
      "loss": 1.0273,
      "step": 419
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0010776143217728449,
      "loss": 0.9641,
      "step": 420
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0010773784512384604,
      "loss": 1.1023,
      "step": 421
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001077141370650669,
      "loss": 1.2001,
      "step": 422
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001076903080553445,
      "loss": 0.9974,
      "step": 423
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001076663581493537,
      "loss": 1.1214,
      "step": 424
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0010764228740204687,
      "loss": 1.1272,
      "step": 425
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0010761809586865357,
      "loss": 1.2653,
      "step": 426
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0010759378360468053,
      "loss": 1.1005,
      "step": 427
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0010756935066591146,
      "loss": 0.9897,
      "step": 428
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0010754479710840697,
      "loss": 1.137,
      "step": 429
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0010752012298850446,
      "loss": 1.0746,
      "step": 430
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0010749532836281793,
      "loss": 1.231,
      "step": 431
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0010747041328823784,
      "loss": 1.2117,
      "step": 432
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.001074453778219311,
      "loss": 1.1802,
      "step": 433
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0010742022202134076,
      "loss": 1.1761,
      "step": 434
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0010739494594418605,
      "loss": 1.192,
      "step": 435
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0010736954964846212,
      "loss": 1.0917,
      "step": 436
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0010734403319243998,
      "loss": 1.1196,
      "step": 437
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0010731839663466638,
      "loss": 1.0249,
      "step": 438
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0010729264003396357,
      "loss": 1.1124,
      "step": 439
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0010726676344942924,
      "loss": 1.1269,
      "step": 440
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0010724076694043647,
      "loss": 1.1057,
      "step": 441
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0010721465056663338,
      "loss": 1.0179,
      "step": 442
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0010718841438794322,
      "loss": 1.123,
      "step": 443
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0010716205846456404,
      "loss": 1.0585,
      "step": 444
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010713558285696874,
      "loss": 1.0478,
      "step": 445
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010710898762590472,
      "loss": 1.1368,
      "step": 446
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010708227283239393,
      "loss": 1.1601,
      "step": 447
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010705543853773267,
      "loss": 0.9971,
      "step": 448
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010702848480349132,
      "loss": 1.2492,
      "step": 449
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010700141169151442,
      "loss": 1.0257,
      "step": 450
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010697421926392037,
      "loss": 1.1342,
      "step": 451
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010694690758310138,
      "loss": 1.1574,
      "step": 452
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.001069194767117232,
      "loss": 1.1152,
      "step": 453
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010689192671272515,
      "loss": 1.0288,
      "step": 454
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010686425764931983,
      "loss": 1.1097,
      "step": 455
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010683646958499302,
      "loss": 1.0476,
      "step": 456
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010680856258350362,
      "loss": 1.2153,
      "step": 457
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.001067805367088833,
      "loss": 1.067,
      "step": 458
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010675239202543665,
      "loss": 1.1885,
      "step": 459
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010672412859774067,
      "loss": 1.0737,
      "step": 460
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010669574649064496,
      "loss": 1.1226,
      "step": 461
    }
  ],
  "logging_steps": 1,
  "max_steps": 2305,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "total_flos": 2.4942341612843827e+17,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
