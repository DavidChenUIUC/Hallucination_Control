{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 1844,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "learning_rate": 4.761904761904762e-06,
      "loss": 1.1617,
      "step": 1
    },
    {
      "epoch": 0.0,
      "learning_rate": 9.523809523809525e-06,
      "loss": 1.1898,
      "step": 2
    },
    {
      "epoch": 0.01,
      "learning_rate": 1.4285714285714287e-05,
      "loss": 1.327,
      "step": 3
    },
    {
      "epoch": 0.01,
      "learning_rate": 1.904761904761905e-05,
      "loss": 1.218,
      "step": 4
    },
    {
      "epoch": 0.01,
      "learning_rate": 2.380952380952381e-05,
      "loss": 1.2591,
      "step": 5
    },
    {
      "epoch": 0.01,
      "learning_rate": 2.8571428571428574e-05,
      "loss": 1.1492,
      "step": 6
    },
    {
      "epoch": 0.02,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 1.208,
      "step": 7
    },
    {
      "epoch": 0.02,
      "learning_rate": 3.80952380952381e-05,
      "loss": 1.174,
      "step": 8
    },
    {
      "epoch": 0.02,
      "learning_rate": 4.2857142857142856e-05,
      "loss": 1.3839,
      "step": 9
    },
    {
      "epoch": 0.02,
      "learning_rate": 4.761904761904762e-05,
      "loss": 1.4591,
      "step": 10
    },
    {
      "epoch": 0.02,
      "learning_rate": 5.2380952380952384e-05,
      "loss": 1.1504,
      "step": 11
    },
    {
      "epoch": 0.03,
      "learning_rate": 5.714285714285715e-05,
      "loss": 1.1396,
      "step": 12
    },
    {
      "epoch": 0.03,
      "learning_rate": 6.19047619047619e-05,
      "loss": 1.2924,
      "step": 13
    },
    {
      "epoch": 0.03,
      "learning_rate": 6.666666666666667e-05,
      "loss": 1.2455,
      "step": 14
    },
    {
      "epoch": 0.03,
      "learning_rate": 7.142857142857142e-05,
      "loss": 1.2319,
      "step": 15
    },
    {
      "epoch": 0.03,
      "learning_rate": 7.61904761904762e-05,
      "loss": 1.2865,
      "step": 16
    },
    {
      "epoch": 0.04,
      "learning_rate": 8.095238095238096e-05,
      "loss": 1.3262,
      "step": 17
    },
    {
      "epoch": 0.04,
      "learning_rate": 8.571428571428571e-05,
      "loss": 1.2479,
      "step": 18
    },
    {
      "epoch": 0.04,
      "learning_rate": 9.047619047619049e-05,
      "loss": 1.1708,
      "step": 19
    },
    {
      "epoch": 0.04,
      "learning_rate": 9.523809523809524e-05,
      "loss": 1.1614,
      "step": 20
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0001,
      "loss": 1.1747,
      "step": 21
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00010476190476190477,
      "loss": 1.2501,
      "step": 22
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00010952380952380953,
      "loss": 1.148,
      "step": 23
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0001142857142857143,
      "loss": 1.0812,
      "step": 24
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00011904761904761905,
      "loss": 1.0734,
      "step": 25
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0001238095238095238,
      "loss": 0.9967,
      "step": 26
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.00012857142857142858,
      "loss": 1.1717,
      "step": 27
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.00013333333333333334,
      "loss": 1.1434,
      "step": 28
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0001380952380952381,
      "loss": 1.1338,
      "step": 29
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00014285714285714284,
      "loss": 1.2228,
      "step": 30
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00014761904761904763,
      "loss": 1.1715,
      "step": 31
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0001523809523809524,
      "loss": 1.2374,
      "step": 32
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00015714285714285713,
      "loss": 1.2187,
      "step": 33
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00016190476190476192,
      "loss": 1.0943,
      "step": 34
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0001666666666666667,
      "loss": 1.1378,
      "step": 35
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00017142857142857143,
      "loss": 1.2517,
      "step": 36
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0001761904761904762,
      "loss": 1.1442,
      "step": 37
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00018095238095238098,
      "loss": 1.2299,
      "step": 38
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00018571428571428572,
      "loss": 0.9945,
      "step": 39
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.00019047619047619048,
      "loss": 1.1778,
      "step": 40
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.00019523809523809527,
      "loss": 1.1461,
      "step": 41
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0002,
      "loss": 1.0111,
      "step": 42
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.00020476190476190477,
      "loss": 1.0295,
      "step": 43
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00020952380952380954,
      "loss": 1.0295,
      "step": 44
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0002142857142857143,
      "loss": 1.223,
      "step": 45
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00021904761904761907,
      "loss": 1.0604,
      "step": 46
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0002238095238095238,
      "loss": 1.1185,
      "step": 47
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0002285714285714286,
      "loss": 1.1667,
      "step": 48
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.00023333333333333336,
      "loss": 0.9367,
      "step": 49
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0002380952380952381,
      "loss": 1.0872,
      "step": 50
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.00024285714285714286,
      "loss": 1.1487,
      "step": 51
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0002476190476190476,
      "loss": 1.1709,
      "step": 52
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0002523809523809524,
      "loss": 1.1224,
      "step": 53
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.00025714285714285715,
      "loss": 0.9535,
      "step": 54
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0002619047619047619,
      "loss": 0.9769,
      "step": 55
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0002666666666666667,
      "loss": 1.0454,
      "step": 56
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.00027142857142857144,
      "loss": 1.1368,
      "step": 57
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0002761904761904762,
      "loss": 0.9113,
      "step": 58
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.00028095238095238097,
      "loss": 1.1784,
      "step": 59
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0002857142857142857,
      "loss": 1.1113,
      "step": 60
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0002904761904761905,
      "loss": 1.1161,
      "step": 61
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.00029523809523809526,
      "loss": 1.0205,
      "step": 62
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0003,
      "loss": 1.112,
      "step": 63
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0003047619047619048,
      "loss": 1.1515,
      "step": 64
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.00030952380952380956,
      "loss": 1.0219,
      "step": 65
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.00031428571428571427,
      "loss": 1.0658,
      "step": 66
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0003190476190476191,
      "loss": 1.1579,
      "step": 67
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.00032380952380952385,
      "loss": 1.1044,
      "step": 68
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.00032857142857142856,
      "loss": 1.1088,
      "step": 69
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0003333333333333334,
      "loss": 1.2589,
      "step": 70
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0003380952380952381,
      "loss": 1.1169,
      "step": 71
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00034285714285714285,
      "loss": 1.0543,
      "step": 72
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00034761904761904767,
      "loss": 1.0022,
      "step": 73
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0003523809523809524,
      "loss": 1.1101,
      "step": 74
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00035714285714285714,
      "loss": 1.0828,
      "step": 75
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00036190476190476196,
      "loss": 1.0609,
      "step": 76
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00036666666666666667,
      "loss": 1.0141,
      "step": 77
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00037142857142857143,
      "loss": 0.9626,
      "step": 78
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00037619047619047625,
      "loss": 1.1428,
      "step": 79
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00038095238095238096,
      "loss": 1.2117,
      "step": 80
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0003857142857142857,
      "loss": 1.0578,
      "step": 81
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00039047619047619055,
      "loss": 1.1568,
      "step": 82
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00039523809523809526,
      "loss": 1.0763,
      "step": 83
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0004,
      "loss": 1.1138,
      "step": 84
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0004047619047619048,
      "loss": 1.2269,
      "step": 85
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00040952380952380955,
      "loss": 0.9838,
      "step": 86
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0004142857142857143,
      "loss": 1.0871,
      "step": 87
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0004190476190476191,
      "loss": 1.1948,
      "step": 88
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00042380952380952384,
      "loss": 1.0919,
      "step": 89
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0004285714285714286,
      "loss": 1.0509,
      "step": 90
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.00043333333333333337,
      "loss": 1.0449,
      "step": 91
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.00043809523809523813,
      "loss": 1.0459,
      "step": 92
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0004428571428571429,
      "loss": 1.0923,
      "step": 93
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0004476190476190476,
      "loss": 1.1249,
      "step": 94
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0004523809523809524,
      "loss": 1.0277,
      "step": 95
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0004571428571428572,
      "loss": 1.0956,
      "step": 96
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0004619047619047619,
      "loss": 1.1037,
      "step": 97
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0004666666666666667,
      "loss": 1.1841,
      "step": 98
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0004714285714285714,
      "loss": 1.0986,
      "step": 99
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0004761904761904762,
      "loss": 0.9536,
      "step": 100
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.000480952380952381,
      "loss": 1.1791,
      "step": 101
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0004857142857142857,
      "loss": 1.1337,
      "step": 102
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0004904761904761905,
      "loss": 1.1143,
      "step": 103
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0004952380952380952,
      "loss": 1.0377,
      "step": 104
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0005,
      "loss": 1.2168,
      "step": 105
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0005047619047619048,
      "loss": 1.2536,
      "step": 106
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0005095238095238095,
      "loss": 0.9917,
      "step": 107
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0005142857142857143,
      "loss": 1.064,
      "step": 108
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0005190476190476191,
      "loss": 0.9559,
      "step": 109
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0005238095238095238,
      "loss": 1.1401,
      "step": 110
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0005285714285714286,
      "loss": 1.1446,
      "step": 111
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0005333333333333334,
      "loss": 1.0248,
      "step": 112
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0005380952380952381,
      "loss": 1.0981,
      "step": 113
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0005428571428571429,
      "loss": 1.1335,
      "step": 114
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0005476190476190477,
      "loss": 1.2065,
      "step": 115
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0005523809523809524,
      "loss": 1.0193,
      "step": 116
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0005571428571428571,
      "loss": 0.9503,
      "step": 117
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0005619047619047619,
      "loss": 1.1233,
      "step": 118
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0005666666666666667,
      "loss": 1.0532,
      "step": 119
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0005714285714285714,
      "loss": 0.9534,
      "step": 120
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0005761904761904762,
      "loss": 1.1166,
      "step": 121
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.000580952380952381,
      "loss": 1.0529,
      "step": 122
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0005857142857142857,
      "loss": 1.0593,
      "step": 123
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0005904761904761905,
      "loss": 1.0525,
      "step": 124
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0005952380952380953,
      "loss": 1.061,
      "step": 125
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0006,
      "loss": 1.1451,
      "step": 126
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0006047619047619048,
      "loss": 1.0474,
      "step": 127
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0006095238095238096,
      "loss": 1.1152,
      "step": 128
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0006142857142857142,
      "loss": 1.1225,
      "step": 129
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0006190476190476191,
      "loss": 1.1105,
      "step": 130
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0006238095238095239,
      "loss": 1.0207,
      "step": 131
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0006285714285714285,
      "loss": 0.9561,
      "step": 132
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0006333333333333334,
      "loss": 0.9768,
      "step": 133
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0006380952380952382,
      "loss": 1.2357,
      "step": 134
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0006428571428571428,
      "loss": 1.0368,
      "step": 135
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0006476190476190477,
      "loss": 1.1775,
      "step": 136
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0006523809523809525,
      "loss": 1.0268,
      "step": 137
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0006571428571428571,
      "loss": 0.952,
      "step": 138
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.000661904761904762,
      "loss": 1.1912,
      "step": 139
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0006666666666666668,
      "loss": 1.0609,
      "step": 140
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0006714285714285714,
      "loss": 1.1549,
      "step": 141
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0006761904761904762,
      "loss": 1.1871,
      "step": 142
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.000680952380952381,
      "loss": 1.095,
      "step": 143
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0006857142857142857,
      "loss": 1.1381,
      "step": 144
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0006904761904761905,
      "loss": 0.9804,
      "step": 145
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0006952380952380953,
      "loss": 1.08,
      "step": 146
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0007,
      "loss": 1.045,
      "step": 147
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0007047619047619048,
      "loss": 0.9514,
      "step": 148
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0007095238095238096,
      "loss": 1.0355,
      "step": 149
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0007142857142857143,
      "loss": 0.9885,
      "step": 150
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.000719047619047619,
      "loss": 1.1328,
      "step": 151
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0007238095238095239,
      "loss": 1.1715,
      "step": 152
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0007285714285714286,
      "loss": 1.1689,
      "step": 153
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0007333333333333333,
      "loss": 1.1137,
      "step": 154
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0007380952380952382,
      "loss": 1.1983,
      "step": 155
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0007428571428571429,
      "loss": 1.1942,
      "step": 156
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0007476190476190476,
      "loss": 0.9955,
      "step": 157
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0007523809523809525,
      "loss": 1.1777,
      "step": 158
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0007571428571428572,
      "loss": 1.085,
      "step": 159
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0007619047619047619,
      "loss": 1.039,
      "step": 160
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0007666666666666668,
      "loss": 1.136,
      "step": 161
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0007714285714285715,
      "loss": 1.4059,
      "step": 162
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0007761904761904762,
      "loss": 1.0174,
      "step": 163
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0007809523809523811,
      "loss": 1.066,
      "step": 164
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0007857142857142857,
      "loss": 1.2442,
      "step": 165
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0007904761904761905,
      "loss": 1.1203,
      "step": 166
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0007952380952380953,
      "loss": 1.1088,
      "step": 167
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0008,
      "loss": 1.2299,
      "step": 168
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0008047619047619048,
      "loss": 0.999,
      "step": 169
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0008095238095238096,
      "loss": 1.0817,
      "step": 170
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0008142857142857143,
      "loss": 1.092,
      "step": 171
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0008190476190476191,
      "loss": 1.1651,
      "step": 172
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0008238095238095239,
      "loss": 0.9344,
      "step": 173
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0008285714285714286,
      "loss": 1.2583,
      "step": 174
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0008333333333333334,
      "loss": 1.1566,
      "step": 175
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0008380952380952382,
      "loss": 0.9053,
      "step": 176
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0008428571428571429,
      "loss": 1.1809,
      "step": 177
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0008476190476190477,
      "loss": 1.1128,
      "step": 178
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0008523809523809524,
      "loss": 1.1149,
      "step": 179
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0008571428571428572,
      "loss": 1.0439,
      "step": 180
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.000861904761904762,
      "loss": 1.054,
      "step": 181
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0008666666666666667,
      "loss": 1.2299,
      "step": 182
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0008714285714285715,
      "loss": 1.0377,
      "step": 183
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0008761904761904763,
      "loss": 0.9899,
      "step": 184
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0008809523809523809,
      "loss": 1.0733,
      "step": 185
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0008857142857142858,
      "loss": 1.068,
      "step": 186
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0008904761904761906,
      "loss": 0.9688,
      "step": 187
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0008952380952380952,
      "loss": 1.0943,
      "step": 188
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0009000000000000001,
      "loss": 1.0366,
      "step": 189
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0009047619047619048,
      "loss": 1.1229,
      "step": 190
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0009095238095238095,
      "loss": 1.0948,
      "step": 191
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0009142857142857144,
      "loss": 1.1893,
      "step": 192
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0009190476190476191,
      "loss": 1.0768,
      "step": 193
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0009238095238095238,
      "loss": 0.9483,
      "step": 194
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0009285714285714286,
      "loss": 1.0088,
      "step": 195
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0009333333333333334,
      "loss": 1.0603,
      "step": 196
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0009380952380952381,
      "loss": 1.1701,
      "step": 197
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0009428571428571429,
      "loss": 1.1368,
      "step": 198
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0009476190476190477,
      "loss": 1.0364,
      "step": 199
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0009523809523809524,
      "loss": 1.2108,
      "step": 200
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0009571428571428571,
      "loss": 1.1637,
      "step": 201
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.000961904761904762,
      "loss": 1.0132,
      "step": 202
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0009666666666666667,
      "loss": 1.1213,
      "step": 203
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0009714285714285714,
      "loss": 1.1232,
      "step": 204
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0009761904761904763,
      "loss": 1.1797,
      "step": 205
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.000980952380952381,
      "loss": 1.0739,
      "step": 206
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0009857142857142857,
      "loss": 1.0057,
      "step": 207
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0009904761904761905,
      "loss": 1.0424,
      "step": 208
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0009952380952380953,
      "loss": 1.1246,
      "step": 209
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.001,
      "loss": 1.0387,
      "step": 210
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0010047619047619048,
      "loss": 1.0153,
      "step": 211
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0010095238095238095,
      "loss": 1.2063,
      "step": 212
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0010142857142857143,
      "loss": 1.1072,
      "step": 213
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.001019047619047619,
      "loss": 1.2984,
      "step": 214
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0010238095238095238,
      "loss": 1.0941,
      "step": 215
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0010285714285714286,
      "loss": 1.1715,
      "step": 216
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0010333333333333334,
      "loss": 1.18,
      "step": 217
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0010380952380952381,
      "loss": 1.0879,
      "step": 218
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001042857142857143,
      "loss": 1.0247,
      "step": 219
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0010476190476190477,
      "loss": 1.2003,
      "step": 220
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0010523809523809524,
      "loss": 0.9954,
      "step": 221
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0010571428571428572,
      "loss": 1.0825,
      "step": 222
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001061904761904762,
      "loss": 1.0917,
      "step": 223
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0010666666666666667,
      "loss": 0.9854,
      "step": 224
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0010714285714285715,
      "loss": 0.9895,
      "step": 225
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0010761904761904762,
      "loss": 1.1841,
      "step": 226
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.001080952380952381,
      "loss": 1.0046,
      "step": 227
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0010857142857142858,
      "loss": 0.9644,
      "step": 228
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0010904761904761905,
      "loss": 1.0903,
      "step": 229
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0010952380952380953,
      "loss": 1.183,
      "step": 230
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0011,
      "loss": 1.1775,
      "step": 231
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0010999993690210777,
      "loss": 1.1376,
      "step": 232
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0010999974760857582,
      "loss": 1.1125,
      "step": 233
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0010999943211983847,
      "loss": 1.1179,
      "step": 234
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0010999899043661965,
      "loss": 1.182,
      "step": 235
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0010999842255993272,
      "loss": 1.1112,
      "step": 236
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0010999772849108072,
      "loss": 1.0524,
      "step": 237
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0010999690823165612,
      "loss": 1.1455,
      "step": 238
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0010999596178354102,
      "loss": 1.0951,
      "step": 239
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0010999488914890697,
      "loss": 1.0976,
      "step": 240
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0010999369033021513,
      "loss": 1.0285,
      "step": 241
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0010999236533021615,
      "loss": 1.1058,
      "step": 242
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001099909141519502,
      "loss": 1.2302,
      "step": 243
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0010998933679874697,
      "loss": 1.0863,
      "step": 244
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0010998763327422561,
      "loss": 1.198,
      "step": 245
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0010998580358229486,
      "loss": 1.3188,
      "step": 246
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0010998384772715284,
      "loss": 1.1488,
      "step": 247
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0010998176571328723,
      "loss": 1.1904,
      "step": 248
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0010997955754547513,
      "loss": 1.188,
      "step": 249
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0010997722322878313,
      "loss": 0.9492,
      "step": 250
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.001099747627685672,
      "loss": 1.0807,
      "step": 251
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0010997217617047285,
      "loss": 1.1251,
      "step": 252
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0010996946344043492,
      "loss": 1.1194,
      "step": 253
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001099666245846777,
      "loss": 1.0665,
      "step": 254
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0010996365960971484,
      "loss": 1.3024,
      "step": 255
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0010996056852234936,
      "loss": 1.0386,
      "step": 256
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.001099573513296737,
      "loss": 0.986,
      "step": 257
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0010995400803906962,
      "loss": 0.9906,
      "step": 258
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0010995053865820816,
      "loss": 1.1216,
      "step": 259
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0010994694319504971,
      "loss": 1.1592,
      "step": 260
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0010994322165784399,
      "loss": 1.1876,
      "step": 261
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0010993937405512988,
      "loss": 1.1403,
      "step": 262
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0010993540039573564,
      "loss": 1.1048,
      "step": 263
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001099313006887787,
      "loss": 1.0949,
      "step": 264
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001099270749436657,
      "loss": 1.0992,
      "step": 265
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0010992272317009244,
      "loss": 1.0634,
      "step": 266
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0010991824537804403,
      "loss": 0.9964,
      "step": 267
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0010991364157779452,
      "loss": 1.1986,
      "step": 268
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0010990891177990725,
      "loss": 1.2022,
      "step": 269
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0010990405599523457,
      "loss": 1.1281,
      "step": 270
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0010989907423491793,
      "loss": 1.2301,
      "step": 271
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0010989396651038782,
      "loss": 1.2892,
      "step": 272
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0010988873283336376,
      "loss": 1.1399,
      "step": 273
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0010988337321585426,
      "loss": 1.1814,
      "step": 274
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001098778876701568,
      "loss": 1.1877,
      "step": 275
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001098722762088578,
      "loss": 1.0681,
      "step": 276
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0010986653884483251,
      "loss": 1.1904,
      "step": 277
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0010986067559124524,
      "loss": 1.2438,
      "step": 278
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0010985468646154898,
      "loss": 1.2128,
      "step": 279
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0010984857146948562,
      "loss": 1.0908,
      "step": 280
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0010984233062908582,
      "loss": 1.2158,
      "step": 281
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0010983596395466896,
      "loss": 1.0402,
      "step": 282
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0010982947146084324,
      "loss": 1.1275,
      "step": 283
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0010982285316250542,
      "loss": 1.22,
      "step": 284
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0010981610907484104,
      "loss": 1.2701,
      "step": 285
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0010980923921332412,
      "loss": 1.1161,
      "step": 286
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.001098022435937174,
      "loss": 1.286,
      "step": 287
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0010979512223207213,
      "loss": 1.1451,
      "step": 288
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00109787875144728,
      "loss": 1.1311,
      "step": 289
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0010978050234831326,
      "loss": 1.1808,
      "step": 290
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0010977300385974454,
      "loss": 1.1208,
      "step": 291
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.001097653796962269,
      "loss": 1.213,
      "step": 292
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0010975762987525375,
      "loss": 0.9636,
      "step": 293
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.001097497544146068,
      "loss": 1.0116,
      "step": 294
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0010974175333235605,
      "loss": 1.0733,
      "step": 295
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0010973362664685974,
      "loss": 1.1741,
      "step": 296
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.001097253743767643,
      "loss": 1.2162,
      "step": 297
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001097169965410043,
      "loss": 1.1103,
      "step": 298
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001097084931588024,
      "loss": 1.1546,
      "step": 299
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.001096998642496694,
      "loss": 1.2778,
      "step": 300
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.00109691109833404,
      "loss": 1.2551,
      "step": 301
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0010968222993009299,
      "loss": 1.0698,
      "step": 302
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.00109673224560111,
      "loss": 1.1028,
      "step": 303
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.001096640937441206,
      "loss": 1.0905,
      "step": 304
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0010965483750307212,
      "loss": 1.1723,
      "step": 305
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0010964545585820374,
      "loss": 1.201,
      "step": 306
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0010963594883104135,
      "loss": 1.2792,
      "step": 307
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.001096263164433985,
      "loss": 1.1579,
      "step": 308
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0010961655871737645,
      "loss": 1.149,
      "step": 309
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00109606675675364,
      "loss": 1.1148,
      "step": 310
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0010959666734003744,
      "loss": 1.1378,
      "step": 311
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0010958653373436059,
      "loss": 1.2014,
      "step": 312
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0010957627488158471,
      "loss": 1.1388,
      "step": 313
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0010956589080524841,
      "loss": 1.1348,
      "step": 314
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0010955538152917763,
      "loss": 1.0727,
      "step": 315
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0010954474707748558,
      "loss": 1.0331,
      "step": 316
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0010953398747457269,
      "loss": 1.1489,
      "step": 317
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0010952310274512651,
      "loss": 1.1908,
      "step": 318
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.001095120929141217,
      "loss": 1.0383,
      "step": 319
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0010950095800682002,
      "loss": 1.2242,
      "step": 320
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0010948969804877014,
      "loss": 1.0906,
      "step": 321
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0010947831306580766,
      "loss": 1.1821,
      "step": 322
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.001094668030840551,
      "loss": 1.1381,
      "step": 323
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0010945516812992176,
      "loss": 1.0757,
      "step": 324
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0010944340823010367,
      "loss": 1.1926,
      "step": 325
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0010943152341158352,
      "loss": 1.0818,
      "step": 326
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0010941951370163072,
      "loss": 1.1263,
      "step": 327
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.001094073791278011,
      "loss": 0.963,
      "step": 328
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0010939511971793715,
      "loss": 1.1511,
      "step": 329
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0010938273550016762,
      "loss": 1.0638,
      "step": 330
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0010937022650290777,
      "loss": 1.0779,
      "step": 331
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0010935759275485905,
      "loss": 1.2071,
      "step": 332
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0010934483428500924,
      "loss": 1.1929,
      "step": 333
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0010933195112263227,
      "loss": 1.1106,
      "step": 334
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001093189432972881,
      "loss": 1.1699,
      "step": 335
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001093058108388228,
      "loss": 1.0622,
      "step": 336
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0010929255377736839,
      "loss": 1.0983,
      "step": 337
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001092791721433428,
      "loss": 1.2022,
      "step": 338
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0010926566596744975,
      "loss": 1.1773,
      "step": 339
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0010925203528067875,
      "loss": 1.0878,
      "step": 340
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0010923828011430497,
      "loss": 1.149,
      "step": 341
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0010922440049988924,
      "loss": 1.1312,
      "step": 342
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0010921039646927789,
      "loss": 0.9862,
      "step": 343
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0010919626805460272,
      "loss": 1.1026,
      "step": 344
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0010918201528828091,
      "loss": 1.0886,
      "step": 345
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0010916763820301508,
      "loss": 1.1676,
      "step": 346
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.001091531368317929,
      "loss": 1.1146,
      "step": 347
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0010913851120788738,
      "loss": 1.2471,
      "step": 348
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0010912376136485652,
      "loss": 1.1796,
      "step": 349
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001091088873365434,
      "loss": 1.1525,
      "step": 350
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0010909388915707602,
      "loss": 1.1309,
      "step": 351
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001090787668608672,
      "loss": 1.1094,
      "step": 352
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001090635204826146,
      "loss": 1.1464,
      "step": 353
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0010904815005730057,
      "loss": 1.2681,
      "step": 354
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0010903265562019204,
      "loss": 1.1556,
      "step": 355
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0010901703720684055,
      "loss": 1.016,
      "step": 356
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0010900129485308203,
      "loss": 1.0498,
      "step": 357
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0010898542859503683,
      "loss": 1.2061,
      "step": 358
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001089694384691096,
      "loss": 1.2446,
      "step": 359
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0010895332451198916,
      "loss": 1.1807,
      "step": 360
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001089370867606485,
      "loss": 1.0825,
      "step": 361
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0010892072525234462,
      "loss": 1.1481,
      "step": 362
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001089042400246185,
      "loss": 0.9913,
      "step": 363
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00108887631115295,
      "loss": 1.1531,
      "step": 364
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001088708985624827,
      "loss": 1.1672,
      "step": 365
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0010885404240457395,
      "loss": 1.2027,
      "step": 366
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001088370626802447,
      "loss": 1.071,
      "step": 367
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0010881995942845434,
      "loss": 1.3291,
      "step": 368
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001088027326884458,
      "loss": 1.2256,
      "step": 369
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0010878538249974525,
      "loss": 0.9931,
      "step": 370
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0010876790890216217,
      "loss": 1.2233,
      "step": 371
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0010875031193578924,
      "loss": 0.9766,
      "step": 372
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0010873259164100209,
      "loss": 1.066,
      "step": 373
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001087147480584594,
      "loss": 1.1488,
      "step": 374
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001086967812291027,
      "loss": 1.0561,
      "step": 375
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0010867869119415637,
      "loss": 1.3151,
      "step": 376
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0010866047799512738,
      "loss": 1.1597,
      "step": 377
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0010864214167380535,
      "loss": 0.9987,
      "step": 378
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0010862368227226244,
      "loss": 0.9232,
      "step": 379
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.001086050998328531,
      "loss": 1.0935,
      "step": 380
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0010858639439821423,
      "loss": 1.0011,
      "step": 381
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0010856756601126483,
      "loss": 1.0796,
      "step": 382
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0010854861471520604,
      "loss": 0.9847,
      "step": 383
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0010852954055352105,
      "loss": 1.1243,
      "step": 384
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0010851034356997489,
      "loss": 1.1682,
      "step": 385
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0010849102380861447,
      "loss": 1.2729,
      "step": 386
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0010847158131376835,
      "loss": 1.1838,
      "step": 387
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0010845201613004676,
      "loss": 1.0783,
      "step": 388
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.001084323283023414,
      "loss": 0.9764,
      "step": 389
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0010841251787582534,
      "loss": 1.1822,
      "step": 390
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0010839258489595304,
      "loss": 1.0526,
      "step": 391
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0010837252940846006,
      "loss": 1.165,
      "step": 392
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.001083523514593631,
      "loss": 1.0977,
      "step": 393
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0010833205109495984,
      "loss": 1.1967,
      "step": 394
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0010831162836182884,
      "loss": 1.0283,
      "step": 395
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0010829108330682941,
      "loss": 1.1945,
      "step": 396
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0010827041597710153,
      "loss": 1.1145,
      "step": 397
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0010824962642006577,
      "loss": 1.2762,
      "step": 398
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0010822871468342313,
      "loss": 1.1327,
      "step": 399
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.001082076808151549,
      "loss": 1.2921,
      "step": 400
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0010818652486352263,
      "loss": 1.1739,
      "step": 401
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0010816524687706803,
      "loss": 1.2279,
      "step": 402
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0010814384690461273,
      "loss": 1.2085,
      "step": 403
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0010812232499525835,
      "loss": 1.002,
      "step": 404
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0010810068119838621,
      "loss": 1.0878,
      "step": 405
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0010807891556365733,
      "loss": 1.0728,
      "step": 406
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0010805702814101227,
      "loss": 1.0781,
      "step": 407
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0010803501898067106,
      "loss": 1.1344,
      "step": 408
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0010801288813313303,
      "loss": 0.9994,
      "step": 409
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0010799063564917671,
      "loss": 1.2765,
      "step": 410
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0010796826157985974,
      "loss": 1.0887,
      "step": 411
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.001079457659765187,
      "loss": 1.2065,
      "step": 412
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0010792314889076907,
      "loss": 1.0861,
      "step": 413
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0010790041037450507,
      "loss": 1.1984,
      "step": 414
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0010787755047989946,
      "loss": 1.2797,
      "step": 415
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.001078545692594036,
      "loss": 1.0083,
      "step": 416
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0010783146676574715,
      "loss": 1.2851,
      "step": 417
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.001078082430519381,
      "loss": 1.2326,
      "step": 418
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0010778489817126252,
      "loss": 1.0273,
      "step": 419
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0010776143217728449,
      "loss": 0.9641,
      "step": 420
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0010773784512384604,
      "loss": 1.1023,
      "step": 421
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001077141370650669,
      "loss": 1.2001,
      "step": 422
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001076903080553445,
      "loss": 0.9974,
      "step": 423
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001076663581493537,
      "loss": 1.1214,
      "step": 424
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0010764228740204687,
      "loss": 1.1272,
      "step": 425
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0010761809586865357,
      "loss": 1.2653,
      "step": 426
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0010759378360468053,
      "loss": 1.1005,
      "step": 427
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0010756935066591146,
      "loss": 0.9897,
      "step": 428
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0010754479710840697,
      "loss": 1.137,
      "step": 429
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0010752012298850446,
      "loss": 1.0746,
      "step": 430
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0010749532836281793,
      "loss": 1.231,
      "step": 431
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0010747041328823784,
      "loss": 1.2117,
      "step": 432
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.001074453778219311,
      "loss": 1.1802,
      "step": 433
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0010742022202134076,
      "loss": 1.1761,
      "step": 434
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0010739494594418605,
      "loss": 1.192,
      "step": 435
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0010736954964846212,
      "loss": 1.0917,
      "step": 436
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0010734403319243998,
      "loss": 1.1196,
      "step": 437
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0010731839663466638,
      "loss": 1.0249,
      "step": 438
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0010729264003396357,
      "loss": 1.1124,
      "step": 439
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0010726676344942924,
      "loss": 1.1269,
      "step": 440
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0010724076694043647,
      "loss": 1.1057,
      "step": 441
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0010721465056663338,
      "loss": 1.0179,
      "step": 442
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0010718841438794322,
      "loss": 1.123,
      "step": 443
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0010716205846456404,
      "loss": 1.0585,
      "step": 444
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010713558285696874,
      "loss": 1.0478,
      "step": 445
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010710898762590472,
      "loss": 1.1368,
      "step": 446
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010708227283239393,
      "loss": 1.1601,
      "step": 447
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010705543853773267,
      "loss": 0.9971,
      "step": 448
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0010702848480349132,
      "loss": 1.2492,
      "step": 449
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010700141169151442,
      "loss": 1.0257,
      "step": 450
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010697421926392037,
      "loss": 1.1342,
      "step": 451
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010694690758310138,
      "loss": 1.1574,
      "step": 452
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.001069194767117232,
      "loss": 1.1152,
      "step": 453
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0010689192671272515,
      "loss": 1.0288,
      "step": 454
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010686425764931983,
      "loss": 1.1097,
      "step": 455
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010683646958499302,
      "loss": 1.0476,
      "step": 456
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0010680856258350362,
      "loss": 1.2153,
      "step": 457
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.001067805367088833,
      "loss": 1.067,
      "step": 458
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010675239202543665,
      "loss": 1.1885,
      "step": 459
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010672412859774067,
      "loss": 1.0737,
      "step": 460
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010669574649064496,
      "loss": 1.1226,
      "step": 461
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.001066672457692714,
      "loss": 1.1404,
      "step": 462
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0010663862649901398,
      "loss": 1.0029,
      "step": 463
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.001066098887455387,
      "loss": 1.0076,
      "step": 464
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.001065810325747835,
      "loss": 1.078,
      "step": 465
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0010655205805295792,
      "loss": 1.1606,
      "step": 466
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.001065229652465431,
      "loss": 1.1538,
      "step": 467
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010649375422229158,
      "loss": 1.1933,
      "step": 468
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010646442504722716,
      "loss": 1.2483,
      "step": 469
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001064349777886447,
      "loss": 0.9797,
      "step": 470
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010640541251411,
      "loss": 1.1275,
      "step": 471
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0010637572929145971,
      "loss": 1.1688,
      "step": 472
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010634592818880102,
      "loss": 1.0807,
      "step": 473
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010631600927451163,
      "loss": 1.1467,
      "step": 474
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010628597261723956,
      "loss": 1.0555,
      "step": 475
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010625581828590301,
      "loss": 1.2126,
      "step": 476
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010622554634969012,
      "loss": 0.9978,
      "step": 477
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0010619515687805892,
      "loss": 1.0108,
      "step": 478
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.001061646499407371,
      "loss": 1.1346,
      "step": 479
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.001061340256077219,
      "loss": 1.0333,
      "step": 480
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0010610328394927984,
      "loss": 1.3636,
      "step": 481
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0010607242503594672,
      "loss": 0.9869,
      "step": 482
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0010604144893852738,
      "loss": 1.1383,
      "step": 483
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.001060103557280955,
      "loss": 1.0112,
      "step": 484
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0010597914547599346,
      "loss": 1.2212,
      "step": 485
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0010594781825383223,
      "loss": 1.0129,
      "step": 486
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0010591637413349113,
      "loss": 1.0383,
      "step": 487
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0010588481318711774,
      "loss": 1.1296,
      "step": 488
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0010585313548712764,
      "loss": 0.9715,
      "step": 489
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0010582134110620433,
      "loss": 1.0909,
      "step": 490
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0010578943011729904,
      "loss": 1.0047,
      "step": 491
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0010575740259363051,
      "loss": 1.0463,
      "step": 492
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.001057252586086849,
      "loss": 1.0088,
      "step": 493
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0010569299823621563,
      "loss": 1.174,
      "step": 494
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0010566062155024304,
      "loss": 1.0703,
      "step": 495
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.001056281286250545,
      "loss": 1.0196,
      "step": 496
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0010559551953520398,
      "loss": 1.043,
      "step": 497
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.00105562794355512,
      "loss": 0.9903,
      "step": 498
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.001055299531610655,
      "loss": 1.1795,
      "step": 499
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0010549699602721756,
      "loss": 1.0686,
      "step": 500
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0010546392302958727,
      "loss": 1.0597,
      "step": 501
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0010543073424405963,
      "loss": 1.0819,
      "step": 502
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0010539742974678527,
      "loss": 1.1242,
      "step": 503
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.001053640096141803,
      "loss": 1.0812,
      "step": 504
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.001053304739229262,
      "loss": 1.0748,
      "step": 505
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0010529682274996953,
      "loss": 1.0825,
      "step": 506
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0010526305617252188,
      "loss": 0.9166,
      "step": 507
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.001052291742680596,
      "loss": 1.1131,
      "step": 508
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0010519517711432367,
      "loss": 0.9837,
      "step": 509
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0010516106478931952,
      "loss": 1.0852,
      "step": 510
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0010512683737131678,
      "loss": 1.1759,
      "step": 511
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0010509249493884918,
      "loss": 1.2375,
      "step": 512
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0010505803757071442,
      "loss": 1.0563,
      "step": 513
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.001050234653459738,
      "loss": 1.0775,
      "step": 514
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0010498877834395227,
      "loss": 0.9844,
      "step": 515
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.00104953976644238,
      "loss": 1.0283,
      "step": 516
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0010491906032668245,
      "loss": 1.1216,
      "step": 517
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0010488402947140003,
      "loss": 0.9794,
      "step": 518
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.001048488841587679,
      "loss": 1.1336,
      "step": 519
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0010481362446942593,
      "loss": 1.1223,
      "step": 520
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0010477825048427637,
      "loss": 1.0437,
      "step": 521
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.001047427622844837,
      "loss": 1.2251,
      "step": 522
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0010470715995147453,
      "loss": 1.1542,
      "step": 523
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0010467144356693721,
      "loss": 1.1186,
      "step": 524
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.00104635613212822,
      "loss": 1.1677,
      "step": 525
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0010459966897134044,
      "loss": 0.9944,
      "step": 526
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.001045636109249655,
      "loss": 1.175,
      "step": 527
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0010452743915643123,
      "loss": 0.9246,
      "step": 528
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0010449115374873267,
      "loss": 1.1266,
      "step": 529
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0010445475478512549,
      "loss": 1.2321,
      "step": 530
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0010441824234912601,
      "loss": 0.9855,
      "step": 531
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0010438161652451088,
      "loss": 1.0137,
      "step": 532
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.001043448773953169,
      "loss": 1.0282,
      "step": 533
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0010430802504584084,
      "loss": 1.1435,
      "step": 534
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.001042710595606393,
      "loss": 1.2096,
      "step": 535
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0010423398102452845,
      "loss": 1.0477,
      "step": 536
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0010419678952258377,
      "loss": 1.0505,
      "step": 537
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0010415948514014004,
      "loss": 1.1697,
      "step": 538
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.00104122067962791,
      "loss": 0.9149,
      "step": 539
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0010408453807638919,
      "loss": 1.0371,
      "step": 540
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0010404689556704578,
      "loss": 1.1483,
      "step": 541
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0010400914052113032,
      "loss": 1.0283,
      "step": 542
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0010397127302527057,
      "loss": 1.071,
      "step": 543
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0010393329316635237,
      "loss": 1.0162,
      "step": 544
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0010389520103151924,
      "loss": 1.18,
      "step": 545
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0010385699670817246,
      "loss": 1.2033,
      "step": 546
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0010381868028397066,
      "loss": 0.9455,
      "step": 547
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0010378025184682963,
      "loss": 1.1453,
      "step": 548
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0010374171148492227,
      "loss": 1.061,
      "step": 549
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0010370305928667821,
      "loss": 0.9749,
      "step": 550
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.001036642953407837,
      "loss": 1.1956,
      "step": 551
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0010362541973618145,
      "loss": 1.1932,
      "step": 552
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.001035864325620703,
      "loss": 0.9636,
      "step": 553
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0010354733390790512,
      "loss": 1.0252,
      "step": 554
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0010350812386339652,
      "loss": 1.1446,
      "step": 555
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0010346880251851072,
      "loss": 1.09,
      "step": 556
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0010342936996346936,
      "loss": 1.0541,
      "step": 557
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0010338982628874918,
      "loss": 1.0585,
      "step": 558
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0010335017158508194,
      "loss": 1.089,
      "step": 559
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0010331040594345406,
      "loss": 1.1842,
      "step": 560
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0010327052945510661,
      "loss": 0.8329,
      "step": 561
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0010323054221153497,
      "loss": 0.9641,
      "step": 562
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0010319044430448857,
      "loss": 1.0737,
      "step": 563
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.001031502358259708,
      "loss": 1.0465,
      "step": 564
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0010310991686823883,
      "loss": 0.9881,
      "step": 565
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.001030694875238032,
      "loss": 0.9751,
      "step": 566
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0010302894788542778,
      "loss": 1.1238,
      "step": 567
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0010298829804612952,
      "loss": 1.1027,
      "step": 568
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0010294753809917821,
      "loss": 1.1413,
      "step": 569
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0010290666813809626,
      "loss": 1.0951,
      "step": 570
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0010286568825665855,
      "loss": 1.2813,
      "step": 571
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.001028245985488921,
      "loss": 1.1563,
      "step": 572
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.00102783399109076,
      "loss": 1.0568,
      "step": 573
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0010274209003174105,
      "loss": 1.1968,
      "step": 574
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0010270067141166966,
      "loss": 1.0795,
      "step": 575
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0010265914334389556,
      "loss": 1.1026,
      "step": 576
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0010261750592370361,
      "loss": 1.0381,
      "step": 577
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0010257575924662954,
      "loss": 1.0629,
      "step": 578
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0010253390340845983,
      "loss": 1.015,
      "step": 579
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0010249193850523138,
      "loss": 1.0902,
      "step": 580
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0010244986463323138,
      "loss": 1.0271,
      "step": 581
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.00102407681888997,
      "loss": 1.0299,
      "step": 582
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.001023653903693152,
      "loss": 1.0592,
      "step": 583
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0010232299017122258,
      "loss": 1.0055,
      "step": 584
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.001022804813920051,
      "loss": 1.2111,
      "step": 585
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0010223786412919776,
      "loss": 1.0487,
      "step": 586
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0010219513848058462,
      "loss": 1.1544,
      "step": 587
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.001021523045441983,
      "loss": 1.0684,
      "step": 588
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.001021093624183199,
      "loss": 1.1944,
      "step": 589
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0010206631220147885,
      "loss": 1.1825,
      "step": 590
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0010202315399245251,
      "loss": 1.1701,
      "step": 591
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0010197988789026606,
      "loss": 1.1367,
      "step": 592
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.001019365139941922,
      "loss": 1.0371,
      "step": 593
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0010189303240375094,
      "loss": 1.0157,
      "step": 594
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0010184944321870951,
      "loss": 1.0897,
      "step": 595
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0010180574653908191,
      "loss": 1.1845,
      "step": 596
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0010176194246512879,
      "loss": 1.116,
      "step": 597
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0010171803109735723,
      "loss": 1.0898,
      "step": 598
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0010167401253652053,
      "loss": 0.9567,
      "step": 599
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0010162988688361787,
      "loss": 1.1682,
      "step": 600
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.001015856542398942,
      "loss": 1.0921,
      "step": 601
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0010154131470683995,
      "loss": 1.1003,
      "step": 602
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0010149686838619076,
      "loss": 0.9557,
      "step": 603
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0010145231537992735,
      "loss": 0.9993,
      "step": 604
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.001014076557902752,
      "loss": 1.1032,
      "step": 605
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0010136288971970436,
      "loss": 1.232,
      "step": 606
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.001013180172709292,
      "loss": 1.1895,
      "step": 607
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0010127303854690808,
      "loss": 1.0894,
      "step": 608
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0010122795365084334,
      "loss": 1.1536,
      "step": 609
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0010118276268618084,
      "loss": 0.9618,
      "step": 610
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0010113746575660986,
      "loss": 1.0582,
      "step": 611
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.001010920629660628,
      "loss": 1.0775,
      "step": 612
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.001010465544187149,
      "loss": 1.0359,
      "step": 613
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0010100094021898414,
      "loss": 1.0223,
      "step": 614
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0010095522047153089,
      "loss": 1.1875,
      "step": 615
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0010090939528125764,
      "loss": 1.1078,
      "step": 616
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.001008634647533089,
      "loss": 1.0231,
      "step": 617
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.001008174289930708,
      "loss": 1.2642,
      "step": 618
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.00100771288106171,
      "loss": 1.047,
      "step": 619
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.001007250421984783,
      "loss": 1.0739,
      "step": 620
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0010067869137610245,
      "loss": 1.053,
      "step": 621
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0010063223574539404,
      "loss": 1.0664,
      "step": 622
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0010058567541294404,
      "loss": 1.0731,
      "step": 623
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0010053901048558366,
      "loss": 1.1275,
      "step": 624
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0010049224107038415,
      "loss": 1.0117,
      "step": 625
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0010044536727465646,
      "loss": 1.0462,
      "step": 626
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0010039838920595104,
      "loss": 1.0994,
      "step": 627
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0010035130697205762,
      "loss": 1.2822,
      "step": 628
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0010030412068100492,
      "loss": 1.0709,
      "step": 629
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0010025683044106038,
      "loss": 1.0195,
      "step": 630
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0010020943636073003,
      "loss": 1.2209,
      "step": 631
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.001001619385487581,
      "loss": 1.0091,
      "step": 632
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.001001143371141268,
      "loss": 1.1014,
      "step": 633
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0010006663216605616,
      "loss": 1.0206,
      "step": 634
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0010001882381400371,
      "loss": 1.0418,
      "step": 635
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.000999709121676642,
      "loss": 1.0451,
      "step": 636
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.000999228973369694,
      "loss": 1.1494,
      "step": 637
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0009987477943208787,
      "loss": 1.1638,
      "step": 638
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0009982655856342463,
      "loss": 1.1161,
      "step": 639
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0009977823484162095,
      "loss": 1.0144,
      "step": 640
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0009972980837755414,
      "loss": 1.1296,
      "step": 641
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0009968127928233715,
      "loss": 1.1198,
      "step": 642
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0009963264766731854,
      "loss": 1.1086,
      "step": 643
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0009958391364408197,
      "loss": 1.1739,
      "step": 644
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0009953507732444618,
      "loss": 1.061,
      "step": 645
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0009948613882046456,
      "loss": 1.1093,
      "step": 646
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0009943709824442501,
      "loss": 1.1067,
      "step": 647
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0009938795570884958,
      "loss": 1.1981,
      "step": 648
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0009933871132649429,
      "loss": 1.1268,
      "step": 649
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.000992893652103488,
      "loss": 1.1227,
      "step": 650
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0009923991747363631,
      "loss": 1.2768,
      "step": 651
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0009919036822981307,
      "loss": 0.9886,
      "step": 652
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0009914071759256828,
      "loss": 1.0057,
      "step": 653
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0009909096567582375,
      "loss": 1.0438,
      "step": 654
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0009904111259373372,
      "loss": 1.1158,
      "step": 655
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0009899115846068458,
      "loss": 1.1039,
      "step": 656
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0009894110339129447,
      "loss": 1.093,
      "step": 657
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.000988909475004132,
      "loss": 0.9449,
      "step": 658
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0009884069090312186,
      "loss": 0.8947,
      "step": 659
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0009879033371473272,
      "loss": 1.0877,
      "step": 660
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0009873987605078874,
      "loss": 1.0592,
      "step": 661
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0009868931802706348,
      "loss": 1.2045,
      "step": 662
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.000986386597595607,
      "loss": 1.1231,
      "step": 663
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0009858790136451426,
      "loss": 1.0918,
      "step": 664
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0009853704295838769,
      "loss": 1.133,
      "step": 665
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.00098486084657874,
      "loss": 1.0704,
      "step": 666
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0009843502657989548,
      "loss": 1.1865,
      "step": 667
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0009838386884160324,
      "loss": 1.1217,
      "step": 668
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0009833261156037716,
      "loss": 1.0581,
      "step": 669
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0009828125485382543,
      "loss": 1.1267,
      "step": 670
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0009822979883978443,
      "loss": 1.1311,
      "step": 671
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0009817824363631837,
      "loss": 0.9564,
      "step": 672
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.000981265893617191,
      "loss": 1.0123,
      "step": 673
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0009807483613450566,
      "loss": 1.2219,
      "step": 674
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0009802298407342429,
      "loss": 1.0305,
      "step": 675
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.000979710332974479,
      "loss": 0.9032,
      "step": 676
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0009791898392577593,
      "loss": 1.1146,
      "step": 677
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0009786683607783402,
      "loss": 1.0173,
      "step": 678
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0009781458987327381,
      "loss": 0.9602,
      "step": 679
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0009776224543197258,
      "loss": 1.1646,
      "step": 680
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0009770980287403298,
      "loss": 1.0449,
      "step": 681
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.000976572623197829,
      "loss": 1.1755,
      "step": 682
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0009760462388977492,
      "loss": 1.1103,
      "step": 683
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0009755188770478632,
      "loss": 1.1578,
      "step": 684
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0009749905388581862,
      "loss": 1.2252,
      "step": 685
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.000974461225540974,
      "loss": 1.1619,
      "step": 686
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.000973930938310719,
      "loss": 1.1691,
      "step": 687
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0009733996783841489,
      "loss": 1.0529,
      "step": 688
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0009728674469802232,
      "loss": 1.1429,
      "step": 689
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.00097233424532013,
      "loss": 0.9341,
      "step": 690
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0009718000746272843,
      "loss": 1.0294,
      "step": 691
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0009712649361273234,
      "loss": 1.181,
      "step": 692
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0009707288310481065,
      "loss": 1.0474,
      "step": 693
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0009701917606197099,
      "loss": 1.0637,
      "step": 694
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0009696537260744247,
      "loss": 0.9841,
      "step": 695
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0009691147286467545,
      "loss": 1.053,
      "step": 696
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0009685747695734122,
      "loss": 1.0836,
      "step": 697
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0009680338500933169,
      "loss": 1.1363,
      "step": 698
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0009674919714475914,
      "loss": 1.0595,
      "step": 699
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0009669491348795596,
      "loss": 1.2199,
      "step": 700
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0009664053416347429,
      "loss": 1.1792,
      "step": 701
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0009658605929608581,
      "loss": 1.2195,
      "step": 702
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0009653148901078137,
      "loss": 0.9092,
      "step": 703
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0009647682343277082,
      "loss": 1.1735,
      "step": 704
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0009642206268748263,
      "loss": 0.9817,
      "step": 705
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0009636720690056358,
      "loss": 1.1186,
      "step": 706
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.000963122561978786,
      "loss": 1.1506,
      "step": 707
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0009625721070551035,
      "loss": 1.275,
      "step": 708
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.00096202070549759,
      "loss": 1.2122,
      "step": 709
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0009614683585714191,
      "loss": 1.1444,
      "step": 710
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0009609150675439337,
      "loss": 1.0875,
      "step": 711
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0009603608336846426,
      "loss": 1.0587,
      "step": 712
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0009598056582652185,
      "loss": 1.1097,
      "step": 713
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0009592495425594934,
      "loss": 0.9718,
      "step": 714
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0009586924878434584,
      "loss": 1.0863,
      "step": 715
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0009581344953952573,
      "loss": 0.925,
      "step": 716
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0009575755664951867,
      "loss": 1.0424,
      "step": 717
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0009570157024256916,
      "loss": 1.0051,
      "step": 718
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0009564549044713625,
      "loss": 1.1316,
      "step": 719
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.000955893173918933,
      "loss": 1.0874,
      "step": 720
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0009553305120572762,
      "loss": 1.2223,
      "step": 721
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0009547669201774023,
      "loss": 1.2249,
      "step": 722
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0009542023995724551,
      "loss": 1.1096,
      "step": 723
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0009536369515377096,
      "loss": 0.9816,
      "step": 724
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0009530705773705687,
      "loss": 1.1137,
      "step": 725
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0009525032783705603,
      "loss": 1.1784,
      "step": 726
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0009519350558393342,
      "loss": 1.0314,
      "step": 727
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0009513659110806594,
      "loss": 1.1816,
      "step": 728
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0009507958454004206,
      "loss": 0.9293,
      "step": 729
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0009502248601066159,
      "loss": 1.2141,
      "step": 730
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.000949652956509353,
      "loss": 0.9807,
      "step": 731
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0009490801359208471,
      "loss": 1.0131,
      "step": 732
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.000948506399655417,
      "loss": 1.0621,
      "step": 733
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.000947931749029483,
      "loss": 1.009,
      "step": 734
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0009473561853615628,
      "loss": 1.1793,
      "step": 735
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0009467797099722691,
      "loss": 0.9344,
      "step": 736
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.000946202324184307,
      "loss": 1.1101,
      "step": 737
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00094562402932247,
      "loss": 1.0944,
      "step": 738
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0009450448267136378,
      "loss": 1.1335,
      "step": 739
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0009444647176867725,
      "loss": 1.009,
      "step": 740
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0009438837035729164,
      "loss": 1.3471,
      "step": 741
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.000943301785705188,
      "loss": 1.1467,
      "step": 742
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.00094271896541878,
      "loss": 0.9941,
      "step": 743
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0009421352440509552,
      "loss": 1.1721,
      "step": 744
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.000941550622941044,
      "loss": 1.0013,
      "step": 745
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0009409651034304413,
      "loss": 1.1124,
      "step": 746
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0009403786868626035,
      "loss": 1.0724,
      "step": 747
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0009397913745830452,
      "loss": 0.9268,
      "step": 748
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0009392031679393357,
      "loss": 1.0505,
      "step": 749
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0009386140682810973,
      "loss": 1.1657,
      "step": 750
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0009380240769600004,
      "loss": 1.1354,
      "step": 751
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.000937433195329762,
      "loss": 1.0765,
      "step": 752
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0009368414247461411,
      "loss": 1.1725,
      "step": 753
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0009362487665669375,
      "loss": 1.1679,
      "step": 754
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0009356552221519864,
      "loss": 1.1381,
      "step": 755
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0009350607928631571,
      "loss": 1.1143,
      "step": 756
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.000934465480064349,
      "loss": 0.8823,
      "step": 757
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.000933869285121489,
      "loss": 1.0182,
      "step": 758
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0009332722094025275,
      "loss": 1.1544,
      "step": 759
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0009326742542774363,
      "loss": 1.1129,
      "step": 760
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0009320754211182046,
      "loss": 1.0376,
      "step": 761
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0009314757112988366,
      "loss": 1.1026,
      "step": 762
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0009308751261953479,
      "loss": 1.0453,
      "step": 763
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0009302736671857617,
      "loss": 0.9872,
      "step": 764
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0009296713356501076,
      "loss": 1.1171,
      "step": 765
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.000929068132970416,
      "loss": 1.252,
      "step": 766
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0009284640605307171,
      "loss": 0.9577,
      "step": 767
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0009278591197170359,
      "loss": 0.9487,
      "step": 768
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0009272533119173905,
      "loss": 1.0405,
      "step": 769
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0009266466385217878,
      "loss": 1.1627,
      "step": 770
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0009260391009222211,
      "loss": 1.0561,
      "step": 771
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0009254307005126664,
      "loss": 1.0111,
      "step": 772
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0009248214386890795,
      "loss": 1.1011,
      "step": 773
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0009242113168493926,
      "loss": 1.0953,
      "step": 774
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0009236003363935113,
      "loss": 1.1884,
      "step": 775
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0009229884987233111,
      "loss": 1.042,
      "step": 776
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0009223758052426347,
      "loss": 1.0514,
      "step": 777
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.000921762257357288,
      "loss": 1.0949,
      "step": 778
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0009211478564750374,
      "loss": 1.153,
      "step": 779
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0009205326040056065,
      "loss": 1.0117,
      "step": 780
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0009199165013606731,
      "loss": 1.0226,
      "step": 781
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0009192995499538657,
      "loss": 0.9561,
      "step": 782
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0009186817512007597,
      "loss": 1.1165,
      "step": 783
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0009180631065188752,
      "loss": 0.9971,
      "step": 784
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0009174436173276729,
      "loss": 1.0744,
      "step": 785
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0009168232850485519,
      "loss": 1.0573,
      "step": 786
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0009162021111048448,
      "loss": 1.0536,
      "step": 787
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0009155800969218162,
      "loss": 1.1478,
      "step": 788
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0009149572439266579,
      "loss": 1.0135,
      "step": 789
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0009143335535484871,
      "loss": 1.0592,
      "step": 790
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0009137090272183415,
      "loss": 1.0136,
      "step": 791
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0009130836663691775,
      "loss": 1.0592,
      "step": 792
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.000912457472435866,
      "loss": 1.0989,
      "step": 793
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0009118304468551895,
      "loss": 1.1418,
      "step": 794
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0009112025910658386,
      "loss": 1.1093,
      "step": 795
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.0009105739065084089,
      "loss": 0.9737,
      "step": 796
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.0009099443946253972,
      "loss": 0.9462,
      "step": 797
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.0009093140568611993,
      "loss": 1.2028,
      "step": 798
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.0009086828946621053,
      "loss": 0.9641,
      "step": 799
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0009080509094762972,
      "loss": 1.0133,
      "step": 800
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0009074181027538455,
      "loss": 1.1388,
      "step": 801
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0009067844759467051,
      "loss": 1.0788,
      "step": 802
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0009061500305087133,
      "loss": 1.0586,
      "step": 803
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0009055147678955852,
      "loss": 1.03,
      "step": 804
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.000904878689564911,
      "loss": 1.1382,
      "step": 805
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.0009042417969761527,
      "loss": 1.0767,
      "step": 806
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.0009036040915906406,
      "loss": 0.9567,
      "step": 807
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.0009029655748715695,
      "loss": 1.1342,
      "step": 808
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.0009023262482839965,
      "loss": 1.0948,
      "step": 809
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.000901686113294836,
      "loss": 1.1585,
      "step": 810
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.0009010451713728581,
      "loss": 1.2232,
      "step": 811
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.0009004034239886841,
      "loss": 0.9766,
      "step": 812
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.000899760872614783,
      "loss": 1.2205,
      "step": 813
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0008991175187254695,
      "loss": 1.1238,
      "step": 814
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0008984733637968985,
      "loss": 1.0011,
      "step": 815
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0008978284093070635,
      "loss": 1.0852,
      "step": 816
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0008971826567357927,
      "loss": 1.0158,
      "step": 817
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0008965361075647448,
      "loss": 1.0131,
      "step": 818
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.0008958887632774071,
      "loss": 1.1542,
      "step": 819
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.0008952406253590906,
      "loss": 1.1827,
      "step": 820
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.0008945916952969278,
      "loss": 1.1137,
      "step": 821
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.0008939419745798684,
      "loss": 0.9335,
      "step": 822
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.0008932914646986762,
      "loss": 0.943,
      "step": 823
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.0008926401671459259,
      "loss": 0.9853,
      "step": 824
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.0008919880834159994,
      "loss": 1.1093,
      "step": 825
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.0008913352150050826,
      "loss": 1.0393,
      "step": 826
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.0008906815634111615,
      "loss": 1.0724,
      "step": 827
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0008900271301340195,
      "loss": 1.0433,
      "step": 828
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0008893719166752332,
      "loss": 1.0917,
      "step": 829
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0008887159245381695,
      "loss": 1.0893,
      "step": 830
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0008880591552279821,
      "loss": 1.0524,
      "step": 831
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0008874016102516072,
      "loss": 1.1227,
      "step": 832
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.0008867432911177616,
      "loss": 1.0157,
      "step": 833
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.000886084199336938,
      "loss": 1.0966,
      "step": 834
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.0008854243364214018,
      "loss": 1.0927,
      "step": 835
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.000884763703885188,
      "loss": 1.2319,
      "step": 836
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0008841023032440973,
      "loss": 1.0476,
      "step": 837
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0008834401360156928,
      "loss": 1.1126,
      "step": 838
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0008827772037192966,
      "loss": 0.9981,
      "step": 839
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0008821135078759863,
      "loss": 1.2973,
      "step": 840
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0008814490500085911,
      "loss": 0.9629,
      "step": 841
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.000880783831641689,
      "loss": 1.1286,
      "step": 842
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.0008801178543016027,
      "loss": 1.0493,
      "step": 843
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.0008794511195163963,
      "loss": 1.0794,
      "step": 844
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.0008787836288158724,
      "loss": 1.048,
      "step": 845
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.0008781153837315671,
      "loss": 1.2469,
      "step": 846
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.0008774463857967481,
      "loss": 0.9597,
      "step": 847
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.0008767766365464105,
      "loss": 1.2623,
      "step": 848
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.0008761061375172728,
      "loss": 1.1013,
      "step": 849
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.0008754348902477743,
      "loss": 1.0207,
      "step": 850
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.0008747628962780708,
      "loss": 1.0976,
      "step": 851
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.0008740901571500315,
      "loss": 0.9401,
      "step": 852
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.0008734166744072354,
      "loss": 1.0533,
      "step": 853
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.0008727424495949674,
      "loss": 1.0543,
      "step": 854
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.0008720674842602156,
      "loss": 1.0871,
      "step": 855
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.000871391779951667,
      "loss": 1.0546,
      "step": 856
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.0008707153382197036,
      "loss": 0.9882,
      "step": 857
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.0008700381606164003,
      "loss": 1.0458,
      "step": 858
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.0008693602486955201,
      "loss": 1.1366,
      "step": 859
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.00086868160401251,
      "loss": 1.06,
      "step": 860
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.0008680022281244999,
      "loss": 1.09,
      "step": 861
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.000867322122590296,
      "loss": 1.2161,
      "step": 862
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.0008666412889703797,
      "loss": 1.0801,
      "step": 863
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.0008659597288269021,
      "loss": 0.9491,
      "step": 864
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.0008652774437236818,
      "loss": 1.111,
      "step": 865
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.0008645944352262009,
      "loss": 1.1165,
      "step": 866
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.0008639107049016008,
      "loss": 1.0536,
      "step": 867
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.0008632262543186796,
      "loss": 1.1694,
      "step": 868
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0008625410850478878,
      "loss": 0.9906,
      "step": 869
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0008618551986613248,
      "loss": 0.9933,
      "step": 870
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0008611685967327356,
      "loss": 1.0499,
      "step": 871
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0008604812808375071,
      "loss": 1.1751,
      "step": 872
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0008597932525526638,
      "loss": 1.0904,
      "step": 873
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.0008591045134568653,
      "loss": 1.089,
      "step": 874
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.0008584150651304022,
      "loss": 1.0211,
      "step": 875
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.0008577249091551918,
      "loss": 1.0613,
      "step": 876
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.0008570340471147755,
      "loss": 1.0569,
      "step": 877
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.0008563424805943153,
      "loss": 1.0715,
      "step": 878
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.0008556502111805882,
      "loss": 1.1439,
      "step": 879
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.0008549572404619852,
      "loss": 1.1322,
      "step": 880
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.0008542635700285059,
      "loss": 1.0702,
      "step": 881
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.0008535692014717556,
      "loss": 1.0998,
      "step": 882
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.0008528741363849412,
      "loss": 1.0371,
      "step": 883
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.0008521783763628679,
      "loss": 1.0884,
      "step": 884
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.0008514819230019353,
      "loss": 1.0117,
      "step": 885
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.0008507847779001338,
      "loss": 1.1264,
      "step": 886
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.0008500869426570414,
      "loss": 1.2186,
      "step": 887
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.000849388418873819,
      "loss": 0.9217,
      "step": 888
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.0008486892081532078,
      "loss": 1.1526,
      "step": 889
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.0008479893120995251,
      "loss": 1.1934,
      "step": 890
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.0008472887323186602,
      "loss": 1.1788,
      "step": 891
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.000846587470418072,
      "loss": 1.1598,
      "step": 892
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.0008458855280067836,
      "loss": 1.1514,
      "step": 893
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.0008451829066953804,
      "loss": 0.9769,
      "step": 894
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.0008444796080960048,
      "loss": 1.0553,
      "step": 895
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.0008437756338223534,
      "loss": 1.1935,
      "step": 896
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.0008430709854896737,
      "loss": 1.1273,
      "step": 897
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.000842365664714759,
      "loss": 1.0791,
      "step": 898
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.0008416596731159457,
      "loss": 0.9317,
      "step": 899
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.0008409530123131097,
      "loss": 1.07,
      "step": 900
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.0008402456839276621,
      "loss": 1.0625,
      "step": 901
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.0008395376895825458,
      "loss": 0.9059,
      "step": 902
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.0008388290309022318,
      "loss": 1.0737,
      "step": 903
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.0008381197095127152,
      "loss": 1.1439,
      "step": 904
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.0008374097270415121,
      "loss": 1.0491,
      "step": 905
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.0008366990851176549,
      "loss": 1.1279,
      "step": 906
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.0008359877853716893,
      "loss": 1.1324,
      "step": 907
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.0008352758294356703,
      "loss": 0.9909,
      "step": 908
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.000834563218943159,
      "loss": 1.1868,
      "step": 909
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.0008338499555292177,
      "loss": 1.043,
      "step": 910
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.000833136040830407,
      "loss": 1.1039,
      "step": 911
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.0008324214764847818,
      "loss": 0.9586,
      "step": 912
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.000831706264131888,
      "loss": 0.9687,
      "step": 913
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.0008309904054127579,
      "loss": 1.0651,
      "step": 914
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.0008302739019699072,
      "loss": 1.067,
      "step": 915
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.0008295567554473301,
      "loss": 0.9907,
      "step": 916
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.0008288389674904976,
      "loss": 1.0927,
      "step": 917
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.0008281205397463514,
      "loss": 0.9704,
      "step": 918
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.0008274014738633016,
      "loss": 1.0698,
      "step": 919
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.0008266817714912226,
      "loss": 0.9817,
      "step": 920
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.0008259614342814489,
      "loss": 1.0502,
      "step": 921
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.0008252404638867717,
      "loss": 1.1613,
      "step": 922
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.0008245188619614354,
      "loss": 1.014,
      "step": 923
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.0008237966301611327,
      "loss": 0.7682,
      "step": 924
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.0008230737701430022,
      "loss": 0.9582,
      "step": 925
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.0008223502835656237,
      "loss": 1.0093,
      "step": 926
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.0008216261720890144,
      "loss": 0.9552,
      "step": 927
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.0008209014373746255,
      "loss": 0.9506,
      "step": 928
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.0008201760810853382,
      "loss": 0.8549,
      "step": 929
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.0008194501048854602,
      "loss": 1.0552,
      "step": 930
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.000818723510440721,
      "loss": 1.0326,
      "step": 931
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.0008179962994182687,
      "loss": 0.9385,
      "step": 932
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.0008172684734866666,
      "loss": 0.9715,
      "step": 933
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.0008165400343158884,
      "loss": 0.9196,
      "step": 934
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.0008158109835773153,
      "loss": 0.8407,
      "step": 935
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.0008150813229437314,
      "loss": 1.237,
      "step": 936
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.00081435105408932,
      "loss": 1.0308,
      "step": 937
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.0008136201786896604,
      "loss": 0.9301,
      "step": 938
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.0008128886984217236,
      "loss": 1.0269,
      "step": 939
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.0008121566149638679,
      "loss": 1.04,
      "step": 940
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.0008114239299958361,
      "loss": 1.0313,
      "step": 941
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.0008106906451987513,
      "loss": 1.0143,
      "step": 942
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.0008099567622551121,
      "loss": 0.9877,
      "step": 943
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.0008092222828487905,
      "loss": 1.0149,
      "step": 944
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.0008084872086650261,
      "loss": 1.0122,
      "step": 945
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.000807751541390424,
      "loss": 0.8349,
      "step": 946
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.0008070152827129498,
      "loss": 0.96,
      "step": 947
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.000806278434321926,
      "loss": 0.9053,
      "step": 948
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.0008055409979080283,
      "loss": 0.9515,
      "step": 949
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.0008048029751632815,
      "loss": 0.9302,
      "step": 950
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.0008040643677810558,
      "loss": 0.982,
      "step": 951
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.0008033251774560627,
      "loss": 0.8816,
      "step": 952
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.0008025854058843515,
      "loss": 1.096,
      "step": 953
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.000801845054763305,
      "loss": 0.9704,
      "step": 954
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.0008011041257916355,
      "loss": 0.9452,
      "step": 955
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.0008003626206693817,
      "loss": 0.9329,
      "step": 956
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0007996205410979039,
      "loss": 1.1396,
      "step": 957
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0007988778887798807,
      "loss": 1.0956,
      "step": 958
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0007981346654193041,
      "loss": 0.9502,
      "step": 959
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0007973908727214775,
      "loss": 0.9976,
      "step": 960
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0007966465123930099,
      "loss": 1.032,
      "step": 961
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.0007959015861418127,
      "loss": 0.9931,
      "step": 962
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.0007951560956770962,
      "loss": 0.9286,
      "step": 963
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.0007944100427093646,
      "loss": 0.9997,
      "step": 964
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.0007936634289504137,
      "loss": 1.021,
      "step": 965
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.0007929162561133251,
      "loss": 1.013,
      "step": 966
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.0007921685259124639,
      "loss": 0.9938,
      "step": 967
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.000791420240063473,
      "loss": 0.9482,
      "step": 968
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.000790671400283272,
      "loss": 1.002,
      "step": 969
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.0007899220082900496,
      "loss": 1.024,
      "step": 970
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0007891720658032627,
      "loss": 1.0838,
      "step": 971
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0007884215745436309,
      "loss": 0.8622,
      "step": 972
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0007876705362331328,
      "loss": 1.1676,
      "step": 973
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0007869189525950025,
      "loss": 1.0287,
      "step": 974
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0007861668253537256,
      "loss": 0.9755,
      "step": 975
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.0007854141562350338,
      "loss": 0.8961,
      "step": 976
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.0007846609469659037,
      "loss": 0.9339,
      "step": 977
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.00078390719927455,
      "loss": 0.9013,
      "step": 978
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.0007831529148904235,
      "loss": 0.9289,
      "step": 979
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.000782398095544206,
      "loss": 0.9233,
      "step": 980
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.000781642742967807,
      "loss": 0.9203,
      "step": 981
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.0007808868588943594,
      "loss": 1.0156,
      "step": 982
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.000780130445058216,
      "loss": 0.9628,
      "step": 983
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.0007793735031949442,
      "loss": 0.9823,
      "step": 984
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.0007786160350413238,
      "loss": 1.0228,
      "step": 985
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.0007778580423353418,
      "loss": 0.95,
      "step": 986
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.0007770995268161889,
      "loss": 0.9808,
      "step": 987
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.0007763404902242551,
      "loss": 1.1065,
      "step": 988
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.0007755809343011264,
      "loss": 1.0033,
      "step": 989
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.00077482086078958,
      "loss": 0.8479,
      "step": 990
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.000774060271433581,
      "loss": 0.9736,
      "step": 991
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.0007732991679782779,
      "loss": 1.0184,
      "step": 992
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.0007725375521699988,
      "loss": 0.9418,
      "step": 993
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.0007717754257562474,
      "loss": 0.8202,
      "step": 994
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.0007710127904856991,
      "loss": 0.9067,
      "step": 995
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.0007702496481081966,
      "loss": 0.8444,
      "step": 996
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.0007694860003747465,
      "loss": 1.0876,
      "step": 997
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.0007687218490375144,
      "loss": 0.9414,
      "step": 998
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0007679571958498219,
      "loss": 1.0669,
      "step": 999
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0007671920425661421,
      "loss": 1.0401,
      "step": 1000
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0007664263909420948,
      "loss": 1.0463,
      "step": 1001
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0007656602427344443,
      "loss": 0.9856,
      "step": 1002
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.0007648935997010935,
      "loss": 1.1529,
      "step": 1003
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.0007641264636010807,
      "loss": 1.1291,
      "step": 1004
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.0007633588361945764,
      "loss": 1.1262,
      "step": 1005
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.000762590719242877,
      "loss": 0.9362,
      "step": 1006
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.0007618221145084035,
      "loss": 0.9235,
      "step": 1007
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.0007610530237546953,
      "loss": 1.0262,
      "step": 1008
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.000760283448746407,
      "loss": 0.9908,
      "step": 1009
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.0007595133912493043,
      "loss": 0.978,
      "step": 1010
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.0007587428530302605,
      "loss": 0.9778,
      "step": 1011
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.0007579718358572514,
      "loss": 1.101,
      "step": 1012
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.0007572003414993519,
      "loss": 0.8765,
      "step": 1013
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.0007564283717267315,
      "loss": 0.8922,
      "step": 1014
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.0007556559283106509,
      "loss": 0.9353,
      "step": 1015
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.0007548830130234576,
      "loss": 1.1295,
      "step": 1016
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.0007541096276385813,
      "loss": 0.9952,
      "step": 1017
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.0007533357739305309,
      "loss": 1.0076,
      "step": 1018
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.0007525614536748894,
      "loss": 0.991,
      "step": 1019
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.0007517866686483106,
      "loss": 1.0326,
      "step": 1020
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.0007510114206285145,
      "loss": 1.013,
      "step": 1021
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.0007502357113942838,
      "loss": 1.0466,
      "step": 1022
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.0007494595427254586,
      "loss": 0.7952,
      "step": 1023
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.0007486829164029343,
      "loss": 1.1964,
      "step": 1024
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.0007479058342086552,
      "loss": 0.971,
      "step": 1025
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.0007471282979256125,
      "loss": 0.9118,
      "step": 1026
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.0007463503093378389,
      "loss": 0.9637,
      "step": 1027
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.0007455718702304048,
      "loss": 0.9463,
      "step": 1028
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.0007447929823894147,
      "loss": 0.8714,
      "step": 1029
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.0007440136476020023,
      "loss": 1.0342,
      "step": 1030
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.0007432338676563268,
      "loss": 0.9478,
      "step": 1031
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.0007424536443415693,
      "loss": 0.959,
      "step": 1032
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.0007416729794479278,
      "loss": 1.059,
      "step": 1033
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.0007408918747666135,
      "loss": 1.0029,
      "step": 1034
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.0007401103320898464,
      "loss": 0.9563,
      "step": 1035
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.0007393283532108522,
      "loss": 0.988,
      "step": 1036
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.000738545939923857,
      "loss": 0.9762,
      "step": 1037
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.0007377630940240838,
      "loss": 0.9622,
      "step": 1038
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.0007369798173077477,
      "loss": 0.946,
      "step": 1039
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.0007361961115720526,
      "loss": 0.931,
      "step": 1040
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.0007354119786151877,
      "loss": 0.9155,
      "step": 1041
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.0007346274202363209,
      "loss": 0.9598,
      "step": 1042
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.000733842438235597,
      "loss": 1.0015,
      "step": 1043
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.0007330570344141329,
      "loss": 0.9674,
      "step": 1044
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.0007322712105740131,
      "loss": 1.0048,
      "step": 1045
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.000731484968518286,
      "loss": 0.9058,
      "step": 1046
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.0007306983100509592,
      "loss": 1.0196,
      "step": 1047
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.0007299112369769963,
      "loss": 1.0242,
      "step": 1048
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.0007291237511023117,
      "loss": 1.0203,
      "step": 1049
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.0007283358542337673,
      "loss": 1.04,
      "step": 1050
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.0007275475481791678,
      "loss": 0.9336,
      "step": 1051
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.000726758834747257,
      "loss": 0.9003,
      "step": 1052
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.0007259697157477132,
      "loss": 0.8518,
      "step": 1053
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.0007251801929911453,
      "loss": 0.8751,
      "step": 1054
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.0007243902682890885,
      "loss": 0.8949,
      "step": 1055
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.0007235999434540008,
      "loss": 0.9066,
      "step": 1056
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.0007228092202992574,
      "loss": 0.9579,
      "step": 1057
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.0007220181006391483,
      "loss": 0.8811,
      "step": 1058
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.0007212265862888728,
      "loss": 1.1231,
      "step": 1059
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.0007204346790645358,
      "loss": 0.9621,
      "step": 1060
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.0007196423807831433,
      "loss": 1.0233,
      "step": 1061
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.0007188496932625999,
      "loss": 1.0242,
      "step": 1062
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.0007180566183217019,
      "loss": 1.127,
      "step": 1063
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.000717263157780135,
      "loss": 0.9816,
      "step": 1064
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.0007164693134584695,
      "loss": 0.9868,
      "step": 1065
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.0007156750871781569,
      "loss": 0.9161,
      "step": 1066
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.0007148804807615242,
      "loss": 1.0945,
      "step": 1067
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.0007140854960317713,
      "loss": 0.9984,
      "step": 1068
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.0007132901348129658,
      "loss": 0.9901,
      "step": 1069
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.000712494398930039,
      "loss": 1.0667,
      "step": 1070
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.0007116982902087824,
      "loss": 1.08,
      "step": 1071
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.0007109018104758426,
      "loss": 1.0703,
      "step": 1072
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.0007101049615587171,
      "loss": 0.9584,
      "step": 1073
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.0007093077452857512,
      "loss": 0.9522,
      "step": 1074
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.0007085101634861328,
      "loss": 1.0609,
      "step": 1075
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.0007077122179898885,
      "loss": 0.9272,
      "step": 1076
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0007069139106278792,
      "loss": 1.0202,
      "step": 1077
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0007061152432317962,
      "loss": 0.9818,
      "step": 1078
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.000705316217634157,
      "loss": 0.9629,
      "step": 1079
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0007045168356683011,
      "loss": 0.9869,
      "step": 1080
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0007037170991683853,
      "loss": 1.0721,
      "step": 1081
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.00070291700996938,
      "loss": 0.9366,
      "step": 1082
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.0007021165699070649,
      "loss": 0.9898,
      "step": 1083
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.000701315780818025,
      "loss": 1.0883,
      "step": 1084
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.0007005146445396457,
      "loss": 0.9368,
      "step": 1085
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.0006997131629101091,
      "loss": 1.1215,
      "step": 1086
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.00069891133776839,
      "loss": 1.0065,
      "step": 1087
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.0006981091709542511,
      "loss": 1.0112,
      "step": 1088
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.0006973066643082392,
      "loss": 1.0481,
      "step": 1089
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.0006965038196716807,
      "loss": 0.9644,
      "step": 1090
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.0006957006388866776,
      "loss": 1.2019,
      "step": 1091
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.000694897123796103,
      "loss": 0.9431,
      "step": 1092
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.0006940932762435977,
      "loss": 1.0051,
      "step": 1093
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.0006932890980735642,
      "loss": 1.0731,
      "step": 1094
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0006924845911311646,
      "loss": 0.9595,
      "step": 1095
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0006916797572623149,
      "loss": 1.0119,
      "step": 1096
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0006908745983136812,
      "loss": 0.8638,
      "step": 1097
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0006900691161326758,
      "loss": 0.8903,
      "step": 1098
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0006892633125674525,
      "loss": 0.9606,
      "step": 1099
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.0006884571894669021,
      "loss": 0.9161,
      "step": 1100
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.0006876507486806492,
      "loss": 1.0605,
      "step": 1101
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.000686843992059047,
      "loss": 0.9771,
      "step": 1102
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.0006860369214531733,
      "loss": 1.0095,
      "step": 1103
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.0006852295387148264,
      "loss": 0.9405,
      "step": 1104
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.0006844218456965209,
      "loss": 0.9146,
      "step": 1105
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.0006836138442514833,
      "loss": 0.9173,
      "step": 1106
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.0006828055362336476,
      "loss": 1.1089,
      "step": 1107
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.0006819969234976513,
      "loss": 0.9138,
      "step": 1108
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0006811880078988312,
      "loss": 0.9262,
      "step": 1109
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0006803787912932189,
      "loss": 0.9291,
      "step": 1110
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0006795692755375368,
      "loss": 1.0369,
      "step": 1111
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0006787594624891932,
      "loss": 1.0133,
      "step": 1112
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0006779493540062791,
      "loss": 0.9246,
      "step": 1113
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.0006771389519475631,
      "loss": 0.9741,
      "step": 1114
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.0006763282581724877,
      "loss": 0.9677,
      "step": 1115
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.000675517274541164,
      "loss": 0.9137,
      "step": 1116
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.0006747060029143689,
      "loss": 1.0603,
      "step": 1117
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.00067389444515354,
      "loss": 1.0519,
      "step": 1118
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.0006730826031207711,
      "loss": 1.0394,
      "step": 1119
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.0006722704786788083,
      "loss": 0.9369,
      "step": 1120
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.0006714580736910459,
      "loss": 1.012,
      "step": 1121
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.0006706453900215219,
      "loss": 0.8915,
      "step": 1122
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.0006698324295349135,
      "loss": 1.0638,
      "step": 1123
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.0006690191940965334,
      "loss": 1.1088,
      "step": 1124
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.0006682056855723247,
      "loss": 0.9778,
      "step": 1125
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.0006673919058288575,
      "loss": 1.0291,
      "step": 1126
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.0006665778567333238,
      "loss": 0.9796,
      "step": 1127
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.0006657635401535342,
      "loss": 1.0672,
      "step": 1128
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.0006649489579579123,
      "loss": 0.9574,
      "step": 1129
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.0006641341120154919,
      "loss": 0.9301,
      "step": 1130
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.0006633190041959114,
      "loss": 0.9918,
      "step": 1131
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.0006625036363694106,
      "loss": 0.9968,
      "step": 1132
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.0006616880104068249,
      "loss": 1.0575,
      "step": 1133
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.0006608721281795831,
      "loss": 0.8694,
      "step": 1134
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.0006600559915597016,
      "loss": 0.8779,
      "step": 1135
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.0006592396024197801,
      "loss": 0.8827,
      "step": 1136
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.0006584229626329982,
      "loss": 0.977,
      "step": 1137
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.0006576060740731102,
      "loss": 1.075,
      "step": 1138
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.0006567889386144418,
      "loss": 0.9958,
      "step": 1139
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.0006559715581318847,
      "loss": 1.0274,
      "step": 1140
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.0006551539345008927,
      "loss": 1.0071,
      "step": 1141
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.0006543360695974778,
      "loss": 1.0871,
      "step": 1142
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.0006535179652982056,
      "loss": 0.9869,
      "step": 1143
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.0006526996234801909,
      "loss": 0.9712,
      "step": 1144
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.0006518810460210935,
      "loss": 1.0758,
      "step": 1145
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.0006510622347991137,
      "loss": 0.9403,
      "step": 1146
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.0006502431916929884,
      "loss": 1.1815,
      "step": 1147
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.0006494239185819865,
      "loss": 0.8805,
      "step": 1148
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.0006486044173459047,
      "loss": 1.0672,
      "step": 1149
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.0006477846898650627,
      "loss": 1.1133,
      "step": 1150
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.0006469647380202999,
      "loss": 1.1233,
      "step": 1151
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.0006461445636929702,
      "loss": 1.043,
      "step": 1152
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.0006453241687649379,
      "loss": 0.9481,
      "step": 1153
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.0006445035551185737,
      "loss": 1.0159,
      "step": 1154
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.0006436827246367497,
      "loss": 0.9134,
      "step": 1155
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.0006428616792028363,
      "loss": 1.0704,
      "step": 1156
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.0006420404207006966,
      "loss": 0.9461,
      "step": 1157
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.0006412189510146822,
      "loss": 0.9748,
      "step": 1158
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.0006403972720296301,
      "loss": 0.9552,
      "step": 1159
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.0006395753856308566,
      "loss": 1.0206,
      "step": 1160
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.000638753293704155,
      "loss": 1.0788,
      "step": 1161
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.0006379309981357894,
      "loss": 0.9553,
      "step": 1162
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.0006371085008124911,
      "loss": 1.0464,
      "step": 1163
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.0006362858036214546,
      "loss": 0.9986,
      "step": 1164
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.0006354629084503332,
      "loss": 0.866,
      "step": 1165
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.0006346398171872341,
      "loss": 1.0135,
      "step": 1166
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.0006338165317207144,
      "loss": 0.8265,
      "step": 1167
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.0006329930539397769,
      "loss": 1.0309,
      "step": 1168
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.0006321693857338659,
      "loss": 0.8503,
      "step": 1169
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.0006313455289928622,
      "loss": 1.0116,
      "step": 1170
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.0006305214856070797,
      "loss": 1.023,
      "step": 1171
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.0006296972574672599,
      "loss": 0.8888,
      "step": 1172
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.0006288728464645686,
      "loss": 0.859,
      "step": 1173
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.0006280482544905913,
      "loss": 0.9751,
      "step": 1174
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.0006272234834373285,
      "loss": 1.1632,
      "step": 1175
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.0006263985351971917,
      "loss": 0.9036,
      "step": 1176
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.0006255734116629986,
      "loss": 1.0074,
      "step": 1177
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.0006247481147279699,
      "loss": 0.9729,
      "step": 1178
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.0006239226462857235,
      "loss": 1.0195,
      "step": 1179
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.0006230970082302708,
      "loss": 0.9781,
      "step": 1180
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.0006222712024560125,
      "loss": 0.8922,
      "step": 1181
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.0006214452308577347,
      "loss": 0.9343,
      "step": 1182
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.0006206190953306031,
      "loss": 0.8982,
      "step": 1183
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.00061979279777016,
      "loss": 0.9114,
      "step": 1184
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.0006189663400723191,
      "loss": 0.9428,
      "step": 1185
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.0006181397241333622,
      "loss": 1.026,
      "step": 1186
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.0006173129518499337,
      "loss": 0.7639,
      "step": 1187
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.0006164860251190366,
      "loss": 1.0351,
      "step": 1188
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.0006156589458380287,
      "loss": 1.0223,
      "step": 1189
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.0006148317159046176,
      "loss": 0.8517,
      "step": 1190
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.0006140043372168565,
      "loss": 0.954,
      "step": 1191
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.00061317681167314,
      "loss": 0.9503,
      "step": 1192
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.0006123491411721997,
      "loss": 1.1151,
      "step": 1193
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.0006115213276130997,
      "loss": 0.9858,
      "step": 1194
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.0006106933728952325,
      "loss": 0.9453,
      "step": 1195
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.0006098652789183142,
      "loss": 1.1033,
      "step": 1196
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.0006090370475823806,
      "loss": 0.9565,
      "step": 1197
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.0006082086807877829,
      "loss": 0.9825,
      "step": 1198
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.0006073801804351828,
      "loss": 0.9416,
      "step": 1199
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.0006065515484255482,
      "loss": 0.9577,
      "step": 1200
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.0006057227866601499,
      "loss": 0.9691,
      "step": 1201
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.0006048938970405555,
      "loss": 1.0188,
      "step": 1202
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.0006040648814686266,
      "loss": 0.8886,
      "step": 1203
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.0006032357418465135,
      "loss": 0.9247,
      "step": 1204
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.0006024064800766513,
      "loss": 0.9846,
      "step": 1205
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.0006015770980617551,
      "loss": 0.9635,
      "step": 1206
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.0006007475977048162,
      "loss": 1.077,
      "step": 1207
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.0005999179809090972,
      "loss": 0.9927,
      "step": 1208
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.000599088249578128,
      "loss": 1.0923,
      "step": 1209
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.0005982584056157013,
      "loss": 1.0228,
      "step": 1210
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.000597428450925868,
      "loss": 0.9732,
      "step": 1211
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.0005965983874129336,
      "loss": 0.9952,
      "step": 1212
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.0005957682169814528,
      "loss": 1.0176,
      "step": 1213
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.0005949379415362254,
      "loss": 0.9105,
      "step": 1214
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.0005941075629822929,
      "loss": 0.9523,
      "step": 1215
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.000593277083224933,
      "loss": 1.0652,
      "step": 1216
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.0005924465041696556,
      "loss": 0.9629,
      "step": 1217
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.0005916158277221982,
      "loss": 0.9976,
      "step": 1218
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.0005907850557885223,
      "loss": 1.0593,
      "step": 1219
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.0005899541902748077,
      "loss": 0.9962,
      "step": 1220
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.0005891232330874499,
      "loss": 0.9194,
      "step": 1221
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.0005882921861330541,
      "loss": 1.0526,
      "step": 1222
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.0005874610513184316,
      "loss": 0.9766,
      "step": 1223
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.0005866298305505953,
      "loss": 1.0495,
      "step": 1224
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.0005857985257367552,
      "loss": 1.0083,
      "step": 1225
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.0005849671387843147,
      "loss": 1.0751,
      "step": 1226
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.0005841356716008647,
      "loss": 0.9922,
      "step": 1227
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.000583304126094181,
      "loss": 1.0856,
      "step": 1228
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.0005824725041722187,
      "loss": 0.9422,
      "step": 1229
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.0005816408077431085,
      "loss": 0.9197,
      "step": 1230
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.0005808090387151519,
      "loss": 0.8364,
      "step": 1231
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.0005799771989968168,
      "loss": 1.0412,
      "step": 1232
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.0005791452904967336,
      "loss": 0.9675,
      "step": 1233
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.0005783133151236906,
      "loss": 1.0652,
      "step": 1234
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.0005774812747866291,
      "loss": 0.9372,
      "step": 1235
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.0005766491713946398,
      "loss": 0.9454,
      "step": 1236
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.0005758170068569579,
      "loss": 1.0128,
      "step": 1237
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.0005749847830829591,
      "loss": 0.9941,
      "step": 1238
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.0005741525019821548,
      "loss": 1.0715,
      "step": 1239
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.0005733201654641881,
      "loss": 0.9326,
      "step": 1240
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.0005724877754388289,
      "loss": 1.0141,
      "step": 1241
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.0005716553338159706,
      "loss": 1.0138,
      "step": 1242
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.0005708228425056242,
      "loss": 1.0788,
      "step": 1243
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.0005699903034179153,
      "loss": 1.0344,
      "step": 1244
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.0005691577184630787,
      "loss": 0.9874,
      "step": 1245
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.0005683250895514544,
      "loss": 0.8702,
      "step": 1246
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.0005674924185934839,
      "loss": 0.9112,
      "step": 1247
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.0005666597074997047,
      "loss": 1.0293,
      "step": 1248
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.000565826958180746,
      "loss": 0.9877,
      "step": 1249
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.0005649941725473254,
      "loss": 0.9254,
      "step": 1250
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.0005641613525102438,
      "loss": 0.8822,
      "step": 1251
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.0005633284999803804,
      "loss": 0.9281,
      "step": 1252
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.0005624956168686896,
      "loss": 0.9514,
      "step": 1253
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.0005616627050861956,
      "loss": 1.0111,
      "step": 1254
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.0005608297665439887,
      "loss": 0.9496,
      "step": 1255
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.0005599968031532201,
      "loss": 0.9636,
      "step": 1256
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.0005591638168250986,
      "loss": 0.9445,
      "step": 1257
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.0005583308094708851,
      "loss": 1.0712,
      "step": 1258
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.0005574977830018891,
      "loss": 1.0779,
      "step": 1259
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.000556664739329464,
      "loss": 0.9633,
      "step": 1260
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.0005558316803650023,
      "loss": 1.0382,
      "step": 1261
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.0005549986080199319,
      "loss": 0.9035,
      "step": 1262
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.0005541655242057113,
      "loss": 1.0323,
      "step": 1263
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.0005533324308338255,
      "loss": 0.9987,
      "step": 1264
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.0005524993298157809,
      "loss": 1.092,
      "step": 1265
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.0005516662230631022,
      "loss": 1.0681,
      "step": 1266
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.0005508331124873263,
      "loss": 1.1226,
      "step": 1267
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.00055,
      "loss": 1.099,
      "step": 1268
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.0005491668875126737,
      "loss": 1.0102,
      "step": 1269
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.0005483337769368981,
      "loss": 1.022,
      "step": 1270
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.0005475006701842193,
      "loss": 0.9111,
      "step": 1271
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.0005466675691661747,
      "loss": 0.9622,
      "step": 1272
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.0005458344757942888,
      "loss": 1.0335,
      "step": 1273
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.0005450013919800682,
      "loss": 0.8951,
      "step": 1274
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0005441683196349978,
      "loss": 1.0301,
      "step": 1275
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0005433352606705361,
      "loss": 0.88,
      "step": 1276
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.000542502216998111,
      "loss": 0.9143,
      "step": 1277
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0005416691905291151,
      "loss": 0.9201,
      "step": 1278
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0005408361831749016,
      "loss": 0.9504,
      "step": 1279
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.0005400031968467799,
      "loss": 0.9728,
      "step": 1280
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.0005391702334560114,
      "loss": 0.8792,
      "step": 1281
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.0005383372949138046,
      "loss": 1.0234,
      "step": 1282
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.0005375043831313105,
      "loss": 0.8987,
      "step": 1283
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.0005366715000196196,
      "loss": 0.9295,
      "step": 1284
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.0005358386474897563,
      "loss": 1.0056,
      "step": 1285
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.0005350058274526746,
      "loss": 1.0556,
      "step": 1286
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.0005341730418192541,
      "loss": 0.8869,
      "step": 1287
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.0005333402925002956,
      "loss": 0.9557,
      "step": 1288
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.0005325075814065162,
      "loss": 1.0482,
      "step": 1289
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.0005316749104485456,
      "loss": 0.9842,
      "step": 1290
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.0005308422815369215,
      "loss": 0.9557,
      "step": 1291
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.0005300096965820849,
      "loss": 0.9294,
      "step": 1292
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.000529177157494376,
      "loss": 0.9947,
      "step": 1293
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.0005283446661840296,
      "loss": 0.9902,
      "step": 1294
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.0005275122245611711,
      "loss": 0.9248,
      "step": 1295
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.000526679834535812,
      "loss": 0.9523,
      "step": 1296
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.0005258474980178452,
      "loss": 1.0252,
      "step": 1297
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.0005250152169170408,
      "loss": 0.9362,
      "step": 1298
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.0005241829931430423,
      "loss": 0.9444,
      "step": 1299
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.0005233508286053602,
      "loss": 0.9461,
      "step": 1300
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.0005225187252133709,
      "loss": 0.8591,
      "step": 1301
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.0005216866848763095,
      "loss": 1.0148,
      "step": 1302
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.0005208547095032663,
      "loss": 0.9564,
      "step": 1303
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.0005200228010031834,
      "loss": 1.0243,
      "step": 1304
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.0005191909612848483,
      "loss": 0.9775,
      "step": 1305
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.0005183591922568916,
      "loss": 0.9511,
      "step": 1306
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.0005175274958277814,
      "loss": 0.8768,
      "step": 1307
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.0005166958739058191,
      "loss": 0.8541,
      "step": 1308
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.0005158643283991355,
      "loss": 0.9747,
      "step": 1309
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.0005150328612156856,
      "loss": 0.9866,
      "step": 1310
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.0005142014742632448,
      "loss": 1.0327,
      "step": 1311
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.0005133701694494049,
      "loss": 1.0466,
      "step": 1312
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.0005125389486815685,
      "loss": 0.8527,
      "step": 1313
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.0005117078138669459,
      "loss": 0.937,
      "step": 1314
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.0005108767669125503,
      "loss": 1.018,
      "step": 1315
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.0005100458097251925,
      "loss": 1.0122,
      "step": 1316
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.000509214944211478,
      "loss": 0.9921,
      "step": 1317
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.0005083841722778019,
      "loss": 0.9092,
      "step": 1318
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.0005075534958303446,
      "loss": 0.9,
      "step": 1319
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.0005067229167750669,
      "loss": 0.8895,
      "step": 1320
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.0005058924370177072,
      "loss": 0.9506,
      "step": 1321
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.0005050620584637748,
      "loss": 1.0543,
      "step": 1322
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.0005042317830185475,
      "loss": 0.9558,
      "step": 1323
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.0005034016125870665,
      "loss": 0.9814,
      "step": 1324
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.000502571549074132,
      "loss": 1.0122,
      "step": 1325
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.0005017415943842989,
      "loss": 1.1042,
      "step": 1326
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.0005009117504218721,
      "loss": 1.048,
      "step": 1327
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.000500082019090903,
      "loss": 0.8672,
      "step": 1328
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.000499252402295184,
      "loss": 0.8383,
      "step": 1329
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.0004984229019382451,
      "loss": 0.9361,
      "step": 1330
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.0004975935199233487,
      "loss": 0.9612,
      "step": 1331
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.0004967642581534867,
      "loss": 0.9538,
      "step": 1332
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.0004959351185313736,
      "loss": 0.9671,
      "step": 1333
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.0004951061029594447,
      "loss": 1.0382,
      "step": 1334
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.0004942772133398501,
      "loss": 1.0414,
      "step": 1335
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.0004934484515744517,
      "loss": 1.0429,
      "step": 1336
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.0004926198195648175,
      "loss": 0.9208,
      "step": 1337
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.0004917913192122172,
      "loss": 0.7632,
      "step": 1338
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.0004909629524176194,
      "loss": 1.0963,
      "step": 1339
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.0004901347210816859,
      "loss": 1.0399,
      "step": 1340
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.0004893066271047676,
      "loss": 0.9712,
      "step": 1341
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.0004884786723869004,
      "loss": 1.0197,
      "step": 1342
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.00048765085882780044,
      "loss": 0.8958,
      "step": 1343
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.0004868231883268601,
      "loss": 0.8869,
      "step": 1344
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.00048599566278314366,
      "loss": 0.8453,
      "step": 1345
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.00048516828409538254,
      "loss": 0.8905,
      "step": 1346
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.0004843410541619714,
      "loss": 0.8709,
      "step": 1347
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.00048351397488096364,
      "loss": 0.9267,
      "step": 1348
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.00048268704815006654,
      "loss": 1.0027,
      "step": 1349
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.000481860275866638,
      "loss": 1.0188,
      "step": 1350
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.00048103365992768104,
      "loss": 0.9359,
      "step": 1351
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.00048020720222984015,
      "loss": 1.0406,
      "step": 1352
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.00047938090466939697,
      "loss": 1.0036,
      "step": 1353
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.0004785547691422655,
      "loss": 1.0192,
      "step": 1354
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.0004777287975439876,
      "loss": 1.0863,
      "step": 1355
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.00047690299176972935,
      "loss": 0.9855,
      "step": 1356
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.00047607735371427666,
      "loss": 1.0959,
      "step": 1357
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.00047525188527203016,
      "loss": 1.0412,
      "step": 1358
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.00047442658833700136,
      "loss": 0.9398,
      "step": 1359
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.00047360146480280853,
      "loss": 0.935,
      "step": 1360
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.00047277651656267165,
      "loss": 0.9754,
      "step": 1361
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.00047195174550940884,
      "loss": 0.9399,
      "step": 1362
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.00047112715353543155,
      "loss": 0.9313,
      "step": 1363
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.0004703027425327403,
      "loss": 0.9286,
      "step": 1364
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.00046947851439292057,
      "loss": 1.0519,
      "step": 1365
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.0004686544710071379,
      "loss": 0.8855,
      "step": 1366
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.0004678306142661343,
      "loss": 0.8595,
      "step": 1367
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.0004670069460602232,
      "loss": 0.9184,
      "step": 1368
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.0004661834682792857,
      "loss": 0.8725,
      "step": 1369
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.00046536018281276596,
      "loss": 0.997,
      "step": 1370
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.00046453709154966705,
      "loss": 0.8836,
      "step": 1371
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.00046371419637854553,
      "loss": 0.9755,
      "step": 1372
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.00046289149918750903,
      "loss": 0.9168,
      "step": 1373
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.00046206900186421073,
      "loss": 0.9978,
      "step": 1374
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.00046124670629584495,
      "loss": 0.912,
      "step": 1375
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.0004604246143691435,
      "loss": 1.0428,
      "step": 1376
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.0004596027279703701,
      "loss": 1.0016,
      "step": 1377
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.00045878104898531793,
      "loss": 0.9542,
      "step": 1378
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.0004579595792993036,
      "loss": 0.897,
      "step": 1379
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.0004571383207971637,
      "loss": 1.0154,
      "step": 1380
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.00045631727536325024,
      "loss": 1.0134,
      "step": 1381
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.00045549644488142657,
      "loss": 1.0574,
      "step": 1382
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.0004546758312350623,
      "loss": 0.8112,
      "step": 1383
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.00045385543630703,
      "loss": 0.8843,
      "step": 1384
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.0004530352619797002,
      "loss": 0.842,
      "step": 1385
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.0004522153101349373,
      "loss": 0.8858,
      "step": 1386
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.00045139558265409554,
      "loss": 0.9866,
      "step": 1387
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.0004505760814180136,
      "loss": 0.8953,
      "step": 1388
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.00044975680830701165,
      "loss": 0.7941,
      "step": 1389
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.00044893776520088627,
      "loss": 0.9001,
      "step": 1390
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.00044811895397890657,
      "loss": 0.8047,
      "step": 1391
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.00044730037651980907,
      "loss": 0.9796,
      "step": 1392
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.0004464820347017946,
      "loss": 0.7566,
      "step": 1393
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.00044566393040252234,
      "loss": 0.9005,
      "step": 1394
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.0004448460654991075,
      "loss": 1.0989,
      "step": 1395
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.00044402844186811546,
      "loss": 0.8888,
      "step": 1396
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.0004432110613855582,
      "loss": 0.7974,
      "step": 1397
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.0004423939259268898,
      "loss": 0.9135,
      "step": 1398
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.000441577037367002,
      "loss": 0.9745,
      "step": 1399
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.00044076039758022,
      "loss": 0.894,
      "step": 1400
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.00043994400844029854,
      "loss": 0.8457,
      "step": 1401
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.00043912787182041684,
      "loss": 0.8824,
      "step": 1402
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.0004383119895931751,
      "loss": 0.9177,
      "step": 1403
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.0004374963636305897,
      "loss": 0.8961,
      "step": 1404
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.0004366809958040886,
      "loss": 0.7983,
      "step": 1405
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.00043586588798450815,
      "loss": 0.8438,
      "step": 1406
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.00043505104204208774,
      "loss": 0.9244,
      "step": 1407
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.0004342364598464659,
      "loss": 0.8318,
      "step": 1408
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.00043342214326667645,
      "loss": 0.8079,
      "step": 1409
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.0004326080941711428,
      "loss": 0.8656,
      "step": 1410
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.0004317943144276754,
      "loss": 0.9207,
      "step": 1411
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.0004309808059034667,
      "loss": 0.8899,
      "step": 1412
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.0004301675704650865,
      "loss": 0.9271,
      "step": 1413
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.00042935460997847816,
      "loss": 0.7508,
      "step": 1414
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.00042854192630895424,
      "loss": 0.8945,
      "step": 1415
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.0004277295213211919,
      "loss": 0.9525,
      "step": 1416
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.00042691739687922915,
      "loss": 0.8137,
      "step": 1417
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.0004261055548464601,
      "loss": 0.9705,
      "step": 1418
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.0004252939970856311,
      "loss": 0.7688,
      "step": 1419
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.0004244827254588362,
      "loss": 0.9138,
      "step": 1420
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.00042367174182751253,
      "loss": 0.8983,
      "step": 1421
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.000422861048052437,
      "loss": 0.876,
      "step": 1422
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.000422050645993721,
      "loss": 0.7884,
      "step": 1423
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.00042124053751080694,
      "loss": 0.7859,
      "step": 1424
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.00042043072446246323,
      "loss": 0.8127,
      "step": 1425
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.0004196212087067812,
      "loss": 0.8013,
      "step": 1426
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.0004188119921011689,
      "loss": 0.8105,
      "step": 1427
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.00041800307650234885,
      "loss": 0.8535,
      "step": 1428
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.0004171944637663525,
      "loss": 0.7163,
      "step": 1429
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.00041638615574851677,
      "loss": 0.9415,
      "step": 1430
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.00041557815430347933,
      "loss": 0.8516,
      "step": 1431
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.00041477046128517376,
      "loss": 0.8664,
      "step": 1432
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.00041396307854682686,
      "loss": 0.9203,
      "step": 1433
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.00041315600794095315,
      "loss": 0.7847,
      "step": 1434
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.00041234925131935086,
      "loss": 0.8279,
      "step": 1435
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.00041154281053309787,
      "loss": 0.9297,
      "step": 1436
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.0004107366874325477,
      "loss": 0.9078,
      "step": 1437
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.0004099308838673243,
      "loss": 0.8945,
      "step": 1438
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.00040912540168631885,
      "loss": 0.9723,
      "step": 1439
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.0004083202427376853,
      "loss": 0.8219,
      "step": 1440
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.0004075154088688356,
      "loss": 0.8354,
      "step": 1441
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.00040671090192643606,
      "loss": 0.9843,
      "step": 1442
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.0004059067237564026,
      "loss": 0.7833,
      "step": 1443
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.0004051028762038971,
      "loss": 0.8585,
      "step": 1444
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.0004042993611133226,
      "loss": 0.8214,
      "step": 1445
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.0004034961803283194,
      "loss": 0.9621,
      "step": 1446
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.00040269333569176077,
      "loss": 0.8269,
      "step": 1447
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.000401890829045749,
      "loss": 0.8939,
      "step": 1448
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.00040108866223161017,
      "loss": 0.8485,
      "step": 1449
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.00040028683708989097,
      "loss": 0.903,
      "step": 1450
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.00039948535546035444,
      "loss": 0.9922,
      "step": 1451
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.0003986842191819751,
      "loss": 0.8328,
      "step": 1452
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.0003978834300929352,
      "loss": 0.6984,
      "step": 1453
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.0003970829900306202,
      "loss": 0.9065,
      "step": 1454
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.00039628290083161484,
      "loss": 0.7838,
      "step": 1455
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.000395483164331699,
      "loss": 0.94,
      "step": 1456
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.00039468378236584296,
      "loss": 0.7836,
      "step": 1457
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.0003938847567682038,
      "loss": 0.913,
      "step": 1458
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.000393086089372121,
      "loss": 0.8557,
      "step": 1459
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.0003922877820101116,
      "loss": 0.849,
      "step": 1460
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.00039148983651386725,
      "loss": 1.0806,
      "step": 1461
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.0003906922547142488,
      "loss": 0.8152,
      "step": 1462
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.0003898950384412829,
      "loss": 0.8142,
      "step": 1463
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.00038909818952415775,
      "loss": 0.8054,
      "step": 1464
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.0003883017097912178,
      "loss": 0.816,
      "step": 1465
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.00038750560106996107,
      "loss": 0.7687,
      "step": 1466
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.00038670986518703427,
      "loss": 0.9334,
      "step": 1467
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.0003859145039682288,
      "loss": 0.8356,
      "step": 1468
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.0003851195192384758,
      "loss": 0.9092,
      "step": 1469
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.00038432491282184336,
      "loss": 0.8188,
      "step": 1470
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.00038353068654153053,
      "loss": 0.907,
      "step": 1471
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.00038273684221986525,
      "loss": 0.9501,
      "step": 1472
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.00038194338167829827,
      "loss": 0.8969,
      "step": 1473
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.00038115030673740015,
      "loss": 0.7448,
      "step": 1474
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.00038035761921685667,
      "loss": 0.8441,
      "step": 1475
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.00037956532093546457,
      "loss": 0.9615,
      "step": 1476
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.0003787734137111275,
      "loss": 1.0172,
      "step": 1477
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.0003779818993608518,
      "loss": 0.9947,
      "step": 1478
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.0003771907797007426,
      "loss": 0.9005,
      "step": 1479
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.00037640005654599937,
      "loss": 0.893,
      "step": 1480
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.00037560973171091164,
      "loss": 0.8409,
      "step": 1481
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.00037481980700885496,
      "loss": 0.8708,
      "step": 1482
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.00037403028425228704,
      "loss": 0.8833,
      "step": 1483
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.0003732411652527431,
      "loss": 0.9019,
      "step": 1484
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.0003724524518208322,
      "loss": 0.8376,
      "step": 1485
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.000371664145766233,
      "loss": 0.7619,
      "step": 1486
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.0003708762488976886,
      "loss": 0.9841,
      "step": 1487
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.0003700887630230039,
      "loss": 0.8969,
      "step": 1488
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.0003693016899490409,
      "loss": 0.9512,
      "step": 1489
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.00036851503148171413,
      "loss": 0.7238,
      "step": 1490
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.00036772878942598693,
      "loss": 0.9698,
      "step": 1491
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.0003669429655858672,
      "loss": 0.8582,
      "step": 1492
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.00036615756176440315,
      "loss": 0.8834,
      "step": 1493
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.0003653725797636793,
      "loss": 0.8299,
      "step": 1494
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.0003645880213848125,
      "loss": 0.8369,
      "step": 1495
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.0003638038884279473,
      "loss": 0.8139,
      "step": 1496
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.00036302018269225263,
      "loss": 1.0555,
      "step": 1497
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.0003622369059759165,
      "loss": 0.8438,
      "step": 1498
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.0003614540600761431,
      "loss": 0.858,
      "step": 1499
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.0003606716467891478,
      "loss": 0.8852,
      "step": 1500
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.0003598896679101537,
      "loss": 0.8632,
      "step": 1501
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.0003591081252333866,
      "loss": 0.9435,
      "step": 1502
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.0003583270205520724,
      "loss": 1.0224,
      "step": 1503
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.00035754635565843086,
      "loss": 0.8581,
      "step": 1504
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.00035676613234367324,
      "loss": 0.8549,
      "step": 1505
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.00035598635239799786,
      "loss": 0.8641,
      "step": 1506
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.0003552070176105854,
      "loss": 0.7951,
      "step": 1507
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.00035442812976959546,
      "loss": 0.8856,
      "step": 1508
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.00035364969066216135,
      "loss": 0.9483,
      "step": 1509
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.0003528717020743877,
      "loss": 0.789,
      "step": 1510
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.00035209416579134496,
      "loss": 0.7733,
      "step": 1511
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.0003513170835970659,
      "loss": 0.8558,
      "step": 1512
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.0003505404572745414,
      "loss": 0.803,
      "step": 1513
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.00034976428860571644,
      "loss": 0.988,
      "step": 1514
    },
    {
      "epoch": 3.29,
      "learning_rate": 0.0003489885793714855,
      "loss": 0.7541,
      "step": 1515
    },
    {
      "epoch": 3.29,
      "learning_rate": 0.00034821333135168946,
      "loss": 0.9337,
      "step": 1516
    },
    {
      "epoch": 3.29,
      "learning_rate": 0.0003474385463251107,
      "loss": 0.7773,
      "step": 1517
    },
    {
      "epoch": 3.29,
      "learning_rate": 0.00034666422606946924,
      "loss": 0.8642,
      "step": 1518
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.00034589037236141884,
      "loss": 0.8087,
      "step": 1519
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.0003451169869765426,
      "loss": 0.8862,
      "step": 1520
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.0003443440716893492,
      "loss": 0.7919,
      "step": 1521
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.0003435716282732687,
      "loss": 0.8475,
      "step": 1522
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.00034279965850064813,
      "loss": 0.8775,
      "step": 1523
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.0003420281641427486,
      "loss": 1.0066,
      "step": 1524
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.0003412571469697397,
      "loss": 0.7823,
      "step": 1525
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.00034048660875069577,
      "loss": 0.8808,
      "step": 1526
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.0003397165512535933,
      "loss": 0.8158,
      "step": 1527
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.0003389469762453049,
      "loss": 0.9566,
      "step": 1528
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.00033817788549159655,
      "loss": 0.8819,
      "step": 1529
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.000337409280757123,
      "loss": 0.832,
      "step": 1530
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.00033664116380542386,
      "loss": 0.8088,
      "step": 1531
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.00033587353639891936,
      "loss": 0.9449,
      "step": 1532
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.00033510640029890676,
      "loss": 0.9347,
      "step": 1533
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.0003343397572655559,
      "loss": 0.9236,
      "step": 1534
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.0003335736090579052,
      "loss": 0.8548,
      "step": 1535
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.0003328079574338582,
      "loss": 0.9951,
      "step": 1536
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.0003320428041501782,
      "loss": 0.893,
      "step": 1537
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.00033127815096248574,
      "loss": 0.9435,
      "step": 1538
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.0003305139996252537,
      "loss": 0.8471,
      "step": 1539
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.00032975035189180337,
      "loss": 0.8392,
      "step": 1540
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.0003289872095143009,
      "loss": 0.7925,
      "step": 1541
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.0003282245742437528,
      "loss": 0.9319,
      "step": 1542
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.0003274624478300013,
      "loss": 0.8367,
      "step": 1543
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.00032670083202172227,
      "loss": 0.7758,
      "step": 1544
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.00032593972856641913,
      "loss": 0.9916,
      "step": 1545
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.0003251791392104201,
      "loss": 0.8381,
      "step": 1546
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.0003244190656988738,
      "loss": 0.8885,
      "step": 1547
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.000323659509775745,
      "loss": 0.9773,
      "step": 1548
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.00032290047318381124,
      "loss": 0.8279,
      "step": 1549
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.00032214195766465826,
      "loss": 0.9178,
      "step": 1550
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.00032138396495867623,
      "loss": 0.8675,
      "step": 1551
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.0003206264968050559,
      "loss": 0.8854,
      "step": 1552
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.0003198695549417842,
      "loss": 0.8083,
      "step": 1553
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.00031911314110564046,
      "loss": 0.9766,
      "step": 1554
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.0003183572570321931,
      "loss": 0.7594,
      "step": 1555
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.0003176019044557941,
      "loss": 0.9538,
      "step": 1556
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.0003168470851095767,
      "loss": 0.8248,
      "step": 1557
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.0003160928007254502,
      "loss": 0.7943,
      "step": 1558
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.00031533905303409636,
      "loss": 0.7612,
      "step": 1559
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.00031458584376496625,
      "loss": 0.8314,
      "step": 1560
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.00031383317464627456,
      "loss": 0.8708,
      "step": 1561
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.0003130810474049975,
      "loss": 0.9286,
      "step": 1562
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.0003123294637668672,
      "loss": 0.9395,
      "step": 1563
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.00031157842545636937,
      "loss": 0.8209,
      "step": 1564
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.00031082793419673756,
      "loss": 0.7802,
      "step": 1565
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.0003100779917099505,
      "loss": 0.898,
      "step": 1566
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.00030932859971672825,
      "loss": 0.9406,
      "step": 1567
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.0003085797599365269,
      "loss": 0.9764,
      "step": 1568
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.0003078314740875365,
      "loss": 0.8886,
      "step": 1569
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.0003070837438866751,
      "loss": 0.8884,
      "step": 1570
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.00030633657104958646,
      "loss": 0.825,
      "step": 1571
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.0003055899572906353,
      "loss": 0.8819,
      "step": 1572
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.000304843904322904,
      "loss": 0.8849,
      "step": 1573
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.0003040984138581873,
      "loss": 0.9121,
      "step": 1574
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.00030335348760699023,
      "loss": 0.8496,
      "step": 1575
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.00030260912727852264,
      "loss": 0.8953,
      "step": 1576
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.0003018653345806959,
      "loss": 0.8289,
      "step": 1577
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.00030112211122011956,
      "loss": 0.8655,
      "step": 1578
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.0003003794589020961,
      "loss": 0.9049,
      "step": 1579
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.00029963737933061835,
      "loss": 1.0334,
      "step": 1580
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.00029889587420836464,
      "loss": 0.9133,
      "step": 1581
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.0002981549452366952,
      "loss": 0.8683,
      "step": 1582
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.0002974145941156487,
      "loss": 0.9258,
      "step": 1583
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.00029667482254393734,
      "loss": 0.8632,
      "step": 1584
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.0002959356322189442,
      "loss": 0.7648,
      "step": 1585
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.0002951970248367188,
      "loss": 0.9667,
      "step": 1586
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.0002944590020919719,
      "loss": 0.9592,
      "step": 1587
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.0002937215656780742,
      "loss": 0.8027,
      "step": 1588
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.0002929847172870503,
      "loss": 0.8248,
      "step": 1589
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.000292248458609576,
      "loss": 0.8609,
      "step": 1590
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.00029151279133497423,
      "loss": 0.9303,
      "step": 1591
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.00029077771715120977,
      "loss": 0.8743,
      "step": 1592
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.0002900432377448879,
      "loss": 0.9235,
      "step": 1593
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.0002893093548012489,
      "loss": 0.8035,
      "step": 1594
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.0002885760700041638,
      "loss": 0.7844,
      "step": 1595
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.0002878433850361322,
      "loss": 0.8056,
      "step": 1596
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.00028711130157827667,
      "loss": 0.8685,
      "step": 1597
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.0002863798213103397,
      "loss": 0.7875,
      "step": 1598
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.00028564894591068024,
      "loss": 0.8638,
      "step": 1599
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.0002849186770562688,
      "loss": 0.7686,
      "step": 1600
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.00028418901642268484,
      "loss": 0.9229,
      "step": 1601
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.0002834599656841118,
      "loss": 0.8825,
      "step": 1602
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.0002827315265133335,
      "loss": 0.798,
      "step": 1603
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.0002820037005817316,
      "loss": 0.8221,
      "step": 1604
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.0002812764895592792,
      "loss": 0.8503,
      "step": 1605
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.0002805498951145398,
      "loss": 0.8591,
      "step": 1606
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.0002798239189146617,
      "loss": 0.962,
      "step": 1607
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.00027909856262537465,
      "loss": 0.8464,
      "step": 1608
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.00027837382791098597,
      "loss": 0.9386,
      "step": 1609
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.0002776497164343765,
      "loss": 0.8194,
      "step": 1610
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.0002769262298569978,
      "loss": 0.9063,
      "step": 1611
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.00027620336983886736,
      "loss": 0.9083,
      "step": 1612
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.00027548113803856485,
      "loss": 0.8811,
      "step": 1613
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.0002747595361132283,
      "loss": 0.7643,
      "step": 1614
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.0002740385657185513,
      "loss": 0.8049,
      "step": 1615
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.0002733182285087774,
      "loss": 0.8403,
      "step": 1616
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.00027259852613669853,
      "loss": 0.8533,
      "step": 1617
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.00027187946025364866,
      "loss": 0.8746,
      "step": 1618
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.0002711610325095026,
      "loss": 0.848,
      "step": 1619
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.00027044324455267004,
      "loss": 0.7651,
      "step": 1620
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.000269726098030093,
      "loss": 0.8936,
      "step": 1621
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.00026900959458724225,
      "loss": 0.8901,
      "step": 1622
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.00026829373586811196,
      "loss": 0.9986,
      "step": 1623
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.0002675785235152183,
      "loss": 0.8761,
      "step": 1624
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.0002668639591695933,
      "loss": 0.9879,
      "step": 1625
    },
    {
      "epoch": 3.53,
      "learning_rate": 0.00026615004447078246,
      "loss": 0.8945,
      "step": 1626
    },
    {
      "epoch": 3.53,
      "learning_rate": 0.0002654367810568409,
      "loss": 0.8405,
      "step": 1627
    },
    {
      "epoch": 3.53,
      "learning_rate": 0.0002647241705643297,
      "loss": 0.9175,
      "step": 1628
    },
    {
      "epoch": 3.53,
      "learning_rate": 0.0002640122146283108,
      "loss": 0.8929,
      "step": 1629
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.00026330091488234545,
      "loss": 1.0487,
      "step": 1630
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.0002625902729584881,
      "loss": 0.8017,
      "step": 1631
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.0002618802904872848,
      "loss": 0.9489,
      "step": 1632
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.0002611709690977684,
      "loss": 0.8866,
      "step": 1633
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.00026046231041745426,
      "loss": 0.9134,
      "step": 1634
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.00025975431607233807,
      "loss": 0.9094,
      "step": 1635
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.0002590469876868905,
      "loss": 0.8213,
      "step": 1636
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.0002583403268840544,
      "loss": 0.7982,
      "step": 1637
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.00025763433528524127,
      "loss": 0.816,
      "step": 1638
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.00025692901451032635,
      "loss": 0.8548,
      "step": 1639
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.00025622436617764663,
      "loss": 0.8282,
      "step": 1640
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.0002555203919039955,
      "loss": 0.8878,
      "step": 1641
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.0002548170933046198,
      "loss": 0.9759,
      "step": 1642
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.0002541144719932166,
      "loss": 0.8301,
      "step": 1643
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.0002534125295819282,
      "loss": 0.8278,
      "step": 1644
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.00025271126768133974,
      "loss": 0.8891,
      "step": 1645
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.00025201068790047524,
      "loss": 0.9771,
      "step": 1646
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.0002513107918467924,
      "loss": 0.989,
      "step": 1647
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.00025061158112618106,
      "loss": 0.9426,
      "step": 1648
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.00024991305734295877,
      "loss": 0.8638,
      "step": 1649
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.0002492152220998662,
      "loss": 0.9254,
      "step": 1650
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.0002485180769980649,
      "loss": 0.8311,
      "step": 1651
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.00024782162363713234,
      "loss": 0.9207,
      "step": 1652
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.00024712586361505886,
      "loss": 0.8538,
      "step": 1653
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.00024643079852824446,
      "loss": 0.8344,
      "step": 1654
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.0002457364299714941,
      "loss": 0.7947,
      "step": 1655
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.0002450427595380149,
      "loss": 0.9448,
      "step": 1656
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.000244349788819412,
      "loss": 0.9007,
      "step": 1657
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.0002436575194056849,
      "loss": 0.8752,
      "step": 1658
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.00024296595288522452,
      "loss": 0.9176,
      "step": 1659
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.00024227509084480829,
      "loss": 0.8369,
      "step": 1660
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.00024158493486959809,
      "loss": 0.8055,
      "step": 1661
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.00024089548654313472,
      "loss": 0.8267,
      "step": 1662
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.00024020674744733633,
      "loss": 0.9498,
      "step": 1663
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.00023951871916249318,
      "loss": 0.9485,
      "step": 1664
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.00023883140326726445,
      "loss": 0.7966,
      "step": 1665
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.00023814480133867513,
      "loss": 0.8538,
      "step": 1666
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.00023745891495211227,
      "loss": 0.8873,
      "step": 1667
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.00023677374568132056,
      "loss": 0.9038,
      "step": 1668
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.00023608929509839923,
      "loss": 0.8862,
      "step": 1669
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.00023540556477379932,
      "loss": 0.8631,
      "step": 1670
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.0002347225562763182,
      "loss": 0.9137,
      "step": 1671
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.00023404027117309808,
      "loss": 0.7782,
      "step": 1672
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.00023335871102962038,
      "loss": 0.8504,
      "step": 1673
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.00023267787740970404,
      "loss": 0.8303,
      "step": 1674
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.00023199777187550035,
      "loss": 0.8771,
      "step": 1675
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.00023131839598749,
      "loss": 0.9946,
      "step": 1676
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.0002306397513044802,
      "loss": 0.799,
      "step": 1677
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.00022996183938359964,
      "loss": 0.7873,
      "step": 1678
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.00022928466178029642,
      "loss": 0.8501,
      "step": 1679
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.0002286082200483333,
      "loss": 0.7725,
      "step": 1680
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.0002279325157397845,
      "loss": 0.8246,
      "step": 1681
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.00022725755040503283,
      "loss": 0.8799,
      "step": 1682
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.00022658332559276484,
      "loss": 0.8743,
      "step": 1683
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.00022590984284996855,
      "loss": 0.9246,
      "step": 1684
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.00022523710372192952,
      "loss": 0.7752,
      "step": 1685
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.0002245651097522259,
      "loss": 0.9078,
      "step": 1686
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.00022389386248272718,
      "loss": 0.8372,
      "step": 1687
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.00022322336345358956,
      "loss": 0.8067,
      "step": 1688
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.0002225536142032518,
      "loss": 0.9139,
      "step": 1689
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.000221884616268433,
      "loss": 0.9395,
      "step": 1690
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.0002212163711841279,
      "loss": 0.787,
      "step": 1691
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.00022054888048360377,
      "loss": 0.9454,
      "step": 1692
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.00021988214569839754,
      "loss": 1.0062,
      "step": 1693
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.00021921616835831115,
      "loss": 0.8558,
      "step": 1694
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.00021855094999140905,
      "loss": 0.8535,
      "step": 1695
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.00021788649212401396,
      "loss": 0.8188,
      "step": 1696
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.00021722279628070347,
      "loss": 0.8364,
      "step": 1697
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.0002165598639843074,
      "loss": 0.7954,
      "step": 1698
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.00021589769675590283,
      "loss": 0.9441,
      "step": 1699
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.00021523629611481198,
      "loss": 0.8217,
      "step": 1700
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.0002145756635785983,
      "loss": 0.848,
      "step": 1701
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.0002139158006630622,
      "loss": 0.8871,
      "step": 1702
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.00021325670888223868,
      "loss": 0.8657,
      "step": 1703
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.00021259838974839297,
      "loss": 0.9685,
      "step": 1704
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.00021194084477201802,
      "loss": 0.9013,
      "step": 1705
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.0002112840754618305,
      "loss": 0.8173,
      "step": 1706
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.0002106280833247669,
      "loss": 0.8155,
      "step": 1707
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.00020997286986598052,
      "loss": 0.8503,
      "step": 1708
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.00020931843658883857,
      "loss": 0.7261,
      "step": 1709
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.00020866478499491746,
      "loss": 0.9032,
      "step": 1710
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.00020801191658400065,
      "loss": 0.8161,
      "step": 1711
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.0002073598328540741,
      "loss": 0.7925,
      "step": 1712
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.00020670853530132388,
      "loss": 0.981,
      "step": 1713
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.00020605802542013183,
      "loss": 0.8538,
      "step": 1714
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.0002054083047030722,
      "loss": 0.8579,
      "step": 1715
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.0002047593746409095,
      "loss": 0.8742,
      "step": 1716
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.00020411123672259298,
      "loss": 0.9139,
      "step": 1717
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.0002034638924352553,
      "loss": 0.8775,
      "step": 1718
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.00020281734326420763,
      "loss": 0.8431,
      "step": 1719
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.00020217159069293658,
      "loss": 0.8513,
      "step": 1720
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.0002015266362031015,
      "loss": 0.7909,
      "step": 1721
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.00020088248127453056,
      "loss": 0.736,
      "step": 1722
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.0002002391273852168,
      "loss": 0.8659,
      "step": 1723
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.00019959657601131616,
      "loss": 0.8007,
      "step": 1724
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.00019895482862714202,
      "loss": 0.8824,
      "step": 1725
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.00019831388670516406,
      "loss": 0.8772,
      "step": 1726
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.0001976737517160037,
      "loss": 1.0062,
      "step": 1727
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.0001970344251284304,
      "loss": 0.9107,
      "step": 1728
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.00019639590840935946,
      "loss": 0.8728,
      "step": 1729
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.00019575820302384736,
      "loss": 0.8018,
      "step": 1730
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.000195121310435089,
      "loss": 0.909,
      "step": 1731
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.00019448523210441494,
      "loss": 0.9966,
      "step": 1732
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.00019384996949128676,
      "loss": 0.7857,
      "step": 1733
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.000193215524053295,
      "loss": 0.828,
      "step": 1734
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.00019258189724615478,
      "loss": 0.887,
      "step": 1735
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.00019194909052370286,
      "loss": 0.9049,
      "step": 1736
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.00019131710533789486,
      "loss": 0.7377,
      "step": 1737
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.00019068594313880082,
      "loss": 0.8189,
      "step": 1738
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.0001900556053746027,
      "loss": 0.8934,
      "step": 1739
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.00018942609349159142,
      "loss": 0.8391,
      "step": 1740
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.00018879740893416156,
      "loss": 0.8998,
      "step": 1741
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.00018816955314481052,
      "loss": 0.841,
      "step": 1742
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.00018754252756413408,
      "loss": 0.8628,
      "step": 1743
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.00018691633363082248,
      "loss": 0.9283,
      "step": 1744
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.00018629097278165854,
      "loss": 1.0035,
      "step": 1745
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.00018566644645151307,
      "loss": 0.861,
      "step": 1746
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.00018504275607334207,
      "loss": 0.8952,
      "step": 1747
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.00018441990307818394,
      "loss": 0.9265,
      "step": 1748
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.00018379788889515518,
      "loss": 0.855,
      "step": 1749
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.00018317671495144823,
      "loss": 0.7874,
      "step": 1750
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.0001825563826723272,
      "loss": 0.8991,
      "step": 1751
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.000181936893481125,
      "loss": 0.7939,
      "step": 1752
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.0001813182487992405,
      "loss": 0.8519,
      "step": 1753
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.00018070045004613442,
      "loss": 0.9464,
      "step": 1754
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.00018008349863932695,
      "loss": 0.7765,
      "step": 1755
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.00017946739599439355,
      "loss": 0.9656,
      "step": 1756
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.00017885214352496287,
      "loss": 0.9262,
      "step": 1757
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.0001782377426427123,
      "loss": 0.8465,
      "step": 1758
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.00017762419475736543,
      "loss": 0.993,
      "step": 1759
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.00017701150127668884,
      "loss": 0.9532,
      "step": 1760
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.0001763996636064888,
      "loss": 0.9182,
      "step": 1761
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.0001757886831506076,
      "loss": 0.871,
      "step": 1762
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.00017517856131092066,
      "loss": 0.9387,
      "step": 1763
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.00017456929948733377,
      "loss": 0.9992,
      "step": 1764
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.00017396089907777896,
      "loss": 0.7378,
      "step": 1765
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.00017335336147821233,
      "loss": 1.0012,
      "step": 1766
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.00017274668808260952,
      "loss": 0.8419,
      "step": 1767
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.00017214088028296413,
      "loss": 0.8593,
      "step": 1768
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.00017153593946928308,
      "loss": 0.876,
      "step": 1769
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.00017093186702958396,
      "loss": 0.8175,
      "step": 1770
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.00017032866434989262,
      "loss": 0.8714,
      "step": 1771
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.00016972633281423828,
      "loss": 0.8183,
      "step": 1772
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.00016912487380465232,
      "loss": 0.8758,
      "step": 1773
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.00016852428870116354,
      "loss": 0.8302,
      "step": 1774
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.0001679245788817954,
      "loss": 0.9356,
      "step": 1775
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.0001673257457225639,
      "loss": 0.9676,
      "step": 1776
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.00016672779059747253,
      "loss": 0.8187,
      "step": 1777
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.00016613071487851094,
      "loss": 0.8585,
      "step": 1778
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.0001655345199356511,
      "loss": 0.863,
      "step": 1779
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.00016493920713684304,
      "loss": 0.8463,
      "step": 1780
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.00016434477784801364,
      "loss": 0.8391,
      "step": 1781
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.00016375123343306266,
      "loss": 0.8434,
      "step": 1782
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.00016315857525385882,
      "loss": 0.7726,
      "step": 1783
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.00016256680467023819,
      "loss": 0.8652,
      "step": 1784
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.00016197592303999976,
      "loss": 0.8264,
      "step": 1785
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.0001613859317189028,
      "loss": 0.8789,
      "step": 1786
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.00016079683206066442,
      "loss": 0.8943,
      "step": 1787
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.00016020862541695494,
      "loss": 0.8572,
      "step": 1788
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.00015962131313739658,
      "loss": 0.7673,
      "step": 1789
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.00015903489656955887,
      "loss": 0.8591,
      "step": 1790
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.0001584493770589562,
      "loss": 0.8242,
      "step": 1791
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.00015786475594904505,
      "loss": 0.9013,
      "step": 1792
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.00015728103458122008,
      "loss": 0.8936,
      "step": 1793
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.0001566982142948119,
      "loss": 0.8207,
      "step": 1794
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.00015611629642708381,
      "loss": 0.8179,
      "step": 1795
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.00015553528231322759,
      "loss": 0.8241,
      "step": 1796
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.00015495517328636223,
      "loss": 0.8344,
      "step": 1797
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.00015437597067753002,
      "loss": 0.9258,
      "step": 1798
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.00015379767581569304,
      "loss": 0.9485,
      "step": 1799
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.000153220290027731,
      "loss": 0.75,
      "step": 1800
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.00015264381463843743,
      "loss": 0.8702,
      "step": 1801
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.00015206825097051704,
      "loss": 0.9219,
      "step": 1802
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.000151493600344583,
      "loss": 0.8752,
      "step": 1803
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.0001509198640791529,
      "loss": 0.8714,
      "step": 1804
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.00015034704349064715,
      "loss": 0.8386,
      "step": 1805
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.0001497751398933844,
      "loss": 0.8639,
      "step": 1806
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.00014920415459957953,
      "loss": 0.9432,
      "step": 1807
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.0001486340889193408,
      "loss": 0.8334,
      "step": 1808
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.00014806494416066588,
      "loss": 0.8962,
      "step": 1809
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.00014749672162943982,
      "loss": 0.8261,
      "step": 1810
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.00014692942262943136,
      "loss": 0.965,
      "step": 1811
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.00014636304846229054,
      "loss": 0.8719,
      "step": 1812
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.00014579760042754517,
      "loss": 0.865,
      "step": 1813
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.00014523307982259784,
      "loss": 0.8592,
      "step": 1814
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.00014466948794272376,
      "loss": 0.892,
      "step": 1815
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.00014410682608106704,
      "loss": 0.8026,
      "step": 1816
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.00014354509552863757,
      "loss": 0.8342,
      "step": 1817
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.00014298429757430845,
      "loss": 0.8304,
      "step": 1818
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.00014242443350481344,
      "loss": 0.7301,
      "step": 1819
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.00014186550460474284,
      "loss": 0.8586,
      "step": 1820
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.00014130751215654183,
      "loss": 0.8662,
      "step": 1821
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.00014075045744050646,
      "loss": 0.9963,
      "step": 1822
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.00014019434173478167,
      "loss": 0.8607,
      "step": 1823
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.00013963916631535748,
      "loss": 0.882,
      "step": 1824
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.00013908493245606642,
      "loss": 0.8337,
      "step": 1825
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.00013853164142858102,
      "loss": 0.856,
      "step": 1826
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.00013797929450241005,
      "loss": 0.8954,
      "step": 1827
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.0001374278929448966,
      "loss": 0.8497,
      "step": 1828
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.0001368774380212142,
      "loss": 0.9244,
      "step": 1829
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.0001363279309943643,
      "loss": 0.898,
      "step": 1830
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.000135779373125174,
      "loss": 0.8833,
      "step": 1831
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.00013523176567229182,
      "loss": 0.8454,
      "step": 1832
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.00013468510989218628,
      "loss": 0.9122,
      "step": 1833
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.00013413940703914224,
      "loss": 0.8021,
      "step": 1834
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.00013359465836525726,
      "loss": 0.9114,
      "step": 1835
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.0001330508651204405,
      "loss": 0.9705,
      "step": 1836
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.00013250802855240871,
      "loss": 0.7817,
      "step": 1837
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.00013196614990668322,
      "loss": 0.8673,
      "step": 1838
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.00013142523042658795,
      "loss": 0.9069,
      "step": 1839
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.00013088527135324564,
      "loss": 0.8006,
      "step": 1840
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.00013034627392557538,
      "loss": 0.7808,
      "step": 1841
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.00012980823938029025,
      "loss": 0.8174,
      "step": 1842
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.00012927116895189344,
      "loss": 0.8326,
      "step": 1843
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.0001287350638726766,
      "loss": 1.2661,
      "step": 1844
    }
  ],
  "logging_steps": 1,
  "max_steps": 2305,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "total_flos": 9.976936645137531e+17,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
