{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.3383947939262475,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "learning_rate": 4.3290043290043295e-06,
      "loss": 1.1617,
      "step": 1
    },
    {
      "epoch": 0.0,
      "learning_rate": 8.658008658008659e-06,
      "loss": 1.1898,
      "step": 2
    },
    {
      "epoch": 0.01,
      "learning_rate": 1.2987012987012988e-05,
      "loss": 1.3332,
      "step": 3
    },
    {
      "epoch": 0.01,
      "learning_rate": 1.7316017316017318e-05,
      "loss": 1.219,
      "step": 4
    },
    {
      "epoch": 0.01,
      "learning_rate": 2.1645021645021645e-05,
      "loss": 1.2616,
      "step": 5
    },
    {
      "epoch": 0.01,
      "learning_rate": 2.5974025974025975e-05,
      "loss": 1.1432,
      "step": 6
    },
    {
      "epoch": 0.02,
      "learning_rate": 3.0303030303030306e-05,
      "loss": 1.2098,
      "step": 7
    },
    {
      "epoch": 0.02,
      "learning_rate": 3.4632034632034636e-05,
      "loss": 1.1696,
      "step": 8
    },
    {
      "epoch": 0.02,
      "learning_rate": 3.896103896103896e-05,
      "loss": 1.3881,
      "step": 9
    },
    {
      "epoch": 0.02,
      "learning_rate": 4.329004329004329e-05,
      "loss": 1.4587,
      "step": 10
    },
    {
      "epoch": 0.02,
      "learning_rate": 4.761904761904762e-05,
      "loss": 1.1513,
      "step": 11
    },
    {
      "epoch": 0.03,
      "learning_rate": 5.194805194805195e-05,
      "loss": 1.1447,
      "step": 12
    },
    {
      "epoch": 0.03,
      "learning_rate": 5.627705627705628e-05,
      "loss": 1.2901,
      "step": 13
    },
    {
      "epoch": 0.03,
      "learning_rate": 6.060606060606061e-05,
      "loss": 1.2426,
      "step": 14
    },
    {
      "epoch": 0.03,
      "learning_rate": 6.493506493506494e-05,
      "loss": 1.2356,
      "step": 15
    },
    {
      "epoch": 0.03,
      "learning_rate": 6.926406926406927e-05,
      "loss": 1.2904,
      "step": 16
    },
    {
      "epoch": 0.04,
      "learning_rate": 7.35930735930736e-05,
      "loss": 1.3295,
      "step": 17
    },
    {
      "epoch": 0.04,
      "learning_rate": 7.792207792207792e-05,
      "loss": 1.2475,
      "step": 18
    },
    {
      "epoch": 0.04,
      "learning_rate": 8.225108225108226e-05,
      "loss": 1.1702,
      "step": 19
    },
    {
      "epoch": 0.04,
      "learning_rate": 8.658008658008658e-05,
      "loss": 1.1636,
      "step": 20
    },
    {
      "epoch": 0.05,
      "learning_rate": 9.090909090909092e-05,
      "loss": 1.174,
      "step": 21
    },
    {
      "epoch": 0.05,
      "learning_rate": 9.523809523809524e-05,
      "loss": 1.2511,
      "step": 22
    },
    {
      "epoch": 0.05,
      "learning_rate": 9.956709956709956e-05,
      "loss": 1.1509,
      "step": 23
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.0001038961038961039,
      "loss": 1.0872,
      "step": 24
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00010822510822510823,
      "loss": 1.0713,
      "step": 25
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.00011255411255411256,
      "loss": 0.9988,
      "step": 26
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.00011688311688311689,
      "loss": 1.1712,
      "step": 27
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.00012121212121212122,
      "loss": 1.1446,
      "step": 28
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.00012554112554112555,
      "loss": 1.1416,
      "step": 29
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00012987012987012987,
      "loss": 1.2252,
      "step": 30
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00013419913419913422,
      "loss": 1.1702,
      "step": 31
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00013852813852813854,
      "loss": 1.2431,
      "step": 32
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00014285714285714284,
      "loss": 1.2268,
      "step": 33
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0001471861471861472,
      "loss": 1.1032,
      "step": 34
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00015151515151515152,
      "loss": 1.1437,
      "step": 35
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00015584415584415584,
      "loss": 1.2514,
      "step": 36
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00016017316017316016,
      "loss": 1.1492,
      "step": 37
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0001645021645021645,
      "loss": 1.23,
      "step": 38
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00016883116883116884,
      "loss": 1.0004,
      "step": 39
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.00017316017316017316,
      "loss": 1.1801,
      "step": 40
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0001774891774891775,
      "loss": 1.1502,
      "step": 41
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.00018181818181818183,
      "loss": 1.0138,
      "step": 42
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.00018614718614718616,
      "loss": 1.0334,
      "step": 43
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00019047619047619048,
      "loss": 1.0346,
      "step": 44
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00019480519480519483,
      "loss": 1.2256,
      "step": 45
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00019913419913419913,
      "loss": 1.0632,
      "step": 46
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00020346320346320345,
      "loss": 1.1218,
      "step": 47
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0002077922077922078,
      "loss": 1.1713,
      "step": 48
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.00021212121212121213,
      "loss": 0.9387,
      "step": 49
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.00021645021645021645,
      "loss": 1.0923,
      "step": 50
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.00022077922077922077,
      "loss": 1.1455,
      "step": 51
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.00022510822510822512,
      "loss": 1.1721,
      "step": 52
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.00022943722943722945,
      "loss": 1.1283,
      "step": 53
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.00023376623376623377,
      "loss": 0.9557,
      "step": 54
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0002380952380952381,
      "loss": 0.9764,
      "step": 55
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.00024242424242424245,
      "loss": 1.0478,
      "step": 56
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.00024675324675324674,
      "loss": 1.1368,
      "step": 57
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0002510822510822511,
      "loss": 0.9145,
      "step": 58
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.00025541125541125544,
      "loss": 1.1768,
      "step": 59
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.00025974025974025974,
      "loss": 1.1127,
      "step": 60
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0002640692640692641,
      "loss": 1.1232,
      "step": 61
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.00026839826839826844,
      "loss": 1.0216,
      "step": 62
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.00027272727272727274,
      "loss": 1.1187,
      "step": 63
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0002770562770562771,
      "loss": 1.152,
      "step": 64
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0002813852813852814,
      "loss": 1.0195,
      "step": 65
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0002857142857142857,
      "loss": 1.0721,
      "step": 66
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.00029004329004329003,
      "loss": 1.1548,
      "step": 67
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0002943722943722944,
      "loss": 1.104,
      "step": 68
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0002987012987012987,
      "loss": 1.1093,
      "step": 69
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.00030303030303030303,
      "loss": 1.2576,
      "step": 70
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0003073593073593073,
      "loss": 1.1204,
      "step": 71
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0003116883116883117,
      "loss": 1.0602,
      "step": 72
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00031601731601731603,
      "loss": 1.0054,
      "step": 73
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0003203463203463203,
      "loss": 1.1044,
      "step": 74
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0003246753246753247,
      "loss": 1.0843,
      "step": 75
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.000329004329004329,
      "loss": 1.0601,
      "step": 76
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0003333333333333333,
      "loss": 1.0156,
      "step": 77
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.00033766233766233767,
      "loss": 0.9607,
      "step": 78
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.000341991341991342,
      "loss": 1.154,
      "step": 79
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0003463203463203463,
      "loss": 1.2146,
      "step": 80
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00035064935064935067,
      "loss": 1.0535,
      "step": 81
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.000354978354978355,
      "loss": 1.1601,
      "step": 82
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0003593073593073593,
      "loss": 1.0783,
      "step": 83
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00036363636363636367,
      "loss": 1.1056,
      "step": 84
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.00036796536796536797,
      "loss": 1.2251,
      "step": 85
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0003722943722943723,
      "loss": 0.982,
      "step": 86
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00037662337662337667,
      "loss": 1.0853,
      "step": 87
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00038095238095238096,
      "loss": 1.2052,
      "step": 88
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0003852813852813853,
      "loss": 1.0963,
      "step": 89
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.00038961038961038966,
      "loss": 1.0572,
      "step": 90
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0003939393939393939,
      "loss": 1.0439,
      "step": 91
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.00039826839826839826,
      "loss": 1.0471,
      "step": 92
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0004025974025974026,
      "loss": 1.0932,
      "step": 93
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0004069264069264069,
      "loss": 1.1163,
      "step": 94
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.00041125541125541126,
      "loss": 1.0406,
      "step": 95
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0004155844155844156,
      "loss": 1.0928,
      "step": 96
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0004199134199134199,
      "loss": 1.1018,
      "step": 97
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.00042424242424242425,
      "loss": 1.1881,
      "step": 98
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.00042857142857142855,
      "loss": 1.0999,
      "step": 99
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0004329004329004329,
      "loss": 0.9565,
      "step": 100
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.00043722943722943725,
      "loss": 1.1886,
      "step": 101
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.00044155844155844155,
      "loss": 1.1295,
      "step": 102
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0004458874458874459,
      "loss": 1.124,
      "step": 103
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00045021645021645025,
      "loss": 1.0329,
      "step": 104
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00045454545454545455,
      "loss": 1.2198,
      "step": 105
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0004588744588744589,
      "loss": 1.2609,
      "step": 106
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00046320346320346325,
      "loss": 0.9913,
      "step": 107
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.00046753246753246754,
      "loss": 1.0694,
      "step": 108
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0004718614718614719,
      "loss": 0.9548,
      "step": 109
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0004761904761904762,
      "loss": 1.136,
      "step": 110
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00048051948051948054,
      "loss": 1.1562,
      "step": 111
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0004848484848484849,
      "loss": 1.0183,
      "step": 112
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0004891774891774891,
      "loss": 1.1124,
      "step": 113
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0004935064935064935,
      "loss": 1.1382,
      "step": 114
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0004978354978354978,
      "loss": 1.2109,
      "step": 115
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0005021645021645022,
      "loss": 1.0265,
      "step": 116
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0005064935064935064,
      "loss": 0.9446,
      "step": 117
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0005108225108225109,
      "loss": 1.1151,
      "step": 118
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0005151515151515151,
      "loss": 1.0562,
      "step": 119
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0005194805194805195,
      "loss": 0.9612,
      "step": 120
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0005238095238095238,
      "loss": 1.1316,
      "step": 121
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0005281385281385282,
      "loss": 1.0528,
      "step": 122
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0005324675324675324,
      "loss": 1.0687,
      "step": 123
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0005367965367965369,
      "loss": 1.0512,
      "step": 124
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0005411255411255411,
      "loss": 1.0515,
      "step": 125
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0005454545454545455,
      "loss": 1.1428,
      "step": 126
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0005497835497835498,
      "loss": 1.0574,
      "step": 127
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0005541125541125542,
      "loss": 1.1101,
      "step": 128
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0005584415584415584,
      "loss": 1.1335,
      "step": 129
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0005627705627705628,
      "loss": 1.1107,
      "step": 130
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0005670995670995671,
      "loss": 1.0149,
      "step": 131
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0005714285714285714,
      "loss": 0.9477,
      "step": 132
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0005757575757575758,
      "loss": 0.9633,
      "step": 133
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0005800865800865801,
      "loss": 1.2393,
      "step": 134
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0005844155844155844,
      "loss": 1.0296,
      "step": 135
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0005887445887445888,
      "loss": 1.1832,
      "step": 136
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0005930735930735931,
      "loss": 1.0307,
      "step": 137
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0005974025974025974,
      "loss": 0.9468,
      "step": 138
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0006017316017316018,
      "loss": 1.2039,
      "step": 139
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0006060606060606061,
      "loss": 1.058,
      "step": 140
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0006103896103896104,
      "loss": 1.1553,
      "step": 141
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0006147186147186147,
      "loss": 1.193,
      "step": 142
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0006190476190476191,
      "loss": 1.1,
      "step": 143
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0006233766233766234,
      "loss": 1.1334,
      "step": 144
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0006277056277056277,
      "loss": 0.989,
      "step": 145
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0006320346320346321,
      "loss": 1.0866,
      "step": 146
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0006363636363636364,
      "loss": 1.047,
      "step": 147
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0006406926406926406,
      "loss": 0.9385,
      "step": 148
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0006450216450216451,
      "loss": 1.0377,
      "step": 149
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0006493506493506494,
      "loss": 0.9881,
      "step": 150
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0006536796536796537,
      "loss": 1.1406,
      "step": 151
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.000658008658008658,
      "loss": 1.1592,
      "step": 152
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0006623376623376624,
      "loss": 1.1749,
      "step": 153
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0006666666666666666,
      "loss": 1.1113,
      "step": 154
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.000670995670995671,
      "loss": 1.189,
      "step": 155
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0006753246753246753,
      "loss": 1.1976,
      "step": 156
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0006796536796536796,
      "loss": 0.9917,
      "step": 157
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.000683982683982684,
      "loss": 1.1636,
      "step": 158
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0006883116883116883,
      "loss": 1.0841,
      "step": 159
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0006926406926406926,
      "loss": 1.0545,
      "step": 160
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.000696969696969697,
      "loss": 1.1414,
      "step": 161
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0007012987012987013,
      "loss": 1.3941,
      "step": 162
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0007056277056277056,
      "loss": 1.0043,
      "step": 163
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.00070995670995671,
      "loss": 1.061,
      "step": 164
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0007142857142857143,
      "loss": 1.2412,
      "step": 165
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0007186147186147186,
      "loss": 1.1175,
      "step": 166
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0007229437229437229,
      "loss": 1.1056,
      "step": 167
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0007272727272727273,
      "loss": 1.2278,
      "step": 168
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0007316017316017316,
      "loss": 0.9956,
      "step": 169
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0007359307359307359,
      "loss": 1.0814,
      "step": 170
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0007402597402597403,
      "loss": 1.079,
      "step": 171
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0007445887445887446,
      "loss": 1.17,
      "step": 172
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0007489177489177489,
      "loss": 0.9297,
      "step": 173
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0007532467532467533,
      "loss": 1.2585,
      "step": 174
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0007575757575757576,
      "loss": 1.1651,
      "step": 175
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0007619047619047619,
      "loss": 0.9147,
      "step": 176
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0007662337662337663,
      "loss": 1.1763,
      "step": 177
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0007705627705627706,
      "loss": 1.1119,
      "step": 178
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0007748917748917749,
      "loss": 1.1336,
      "step": 179
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0007792207792207793,
      "loss": 1.0272,
      "step": 180
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0007835497835497836,
      "loss": 1.0432,
      "step": 181
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0007878787878787878,
      "loss": 1.2221,
      "step": 182
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0007922077922077923,
      "loss": 1.0327,
      "step": 183
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0007965367965367965,
      "loss": 0.9938,
      "step": 184
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0008008658008658009,
      "loss": 1.0635,
      "step": 185
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0008051948051948052,
      "loss": 1.0654,
      "step": 186
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0008095238095238096,
      "loss": 0.9551,
      "step": 187
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0008138528138528138,
      "loss": 1.0965,
      "step": 188
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0008181818181818183,
      "loss": 1.0372,
      "step": 189
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0008225108225108225,
      "loss": 1.1125,
      "step": 190
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0008268398268398269,
      "loss": 1.1077,
      "step": 191
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0008311688311688312,
      "loss": 1.1882,
      "step": 192
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0008354978354978356,
      "loss": 1.0849,
      "step": 193
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0008398268398268398,
      "loss": 0.9623,
      "step": 194
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0008441558441558442,
      "loss": 0.9923,
      "step": 195
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0008484848484848485,
      "loss": 1.0692,
      "step": 196
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0008528138528138529,
      "loss": 1.1541,
      "step": 197
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0008571428571428571,
      "loss": 1.1534,
      "step": 198
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0008614718614718616,
      "loss": 1.0381,
      "step": 199
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0008658008658008658,
      "loss": 1.2251,
      "step": 200
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0008701298701298702,
      "loss": 1.1721,
      "step": 201
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0008744588744588745,
      "loss": 1.0083,
      "step": 202
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0008787878787878789,
      "loss": 1.1015,
      "step": 203
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0008831168831168831,
      "loss": 1.124,
      "step": 204
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0008874458874458876,
      "loss": 1.1537,
      "step": 205
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0008917748917748918,
      "loss": 1.0615,
      "step": 206
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.000896103896103896,
      "loss": 1.004,
      "step": 207
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0009004329004329005,
      "loss": 1.0419,
      "step": 208
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0009047619047619047,
      "loss": 1.0989,
      "step": 209
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0009090909090909091,
      "loss": 1.028,
      "step": 210
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0009134199134199134,
      "loss": 0.9792,
      "step": 211
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0009177489177489178,
      "loss": 1.2052,
      "step": 212
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.000922077922077922,
      "loss": 1.1148,
      "step": 213
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0009264069264069265,
      "loss": 1.2735,
      "step": 214
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0009307359307359307,
      "loss": 1.0826,
      "step": 215
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0009350649350649351,
      "loss": 1.1375,
      "step": 216
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0009393939393939394,
      "loss": 1.1593,
      "step": 217
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0009437229437229438,
      "loss": 1.0769,
      "step": 218
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.000948051948051948,
      "loss": 1.0118,
      "step": 219
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0009523809523809524,
      "loss": 1.2065,
      "step": 220
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0009567099567099567,
      "loss": 0.9922,
      "step": 221
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0009610389610389611,
      "loss": 1.0816,
      "step": 222
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0009653679653679653,
      "loss": 1.0983,
      "step": 223
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0009696969696969698,
      "loss": 1.0018,
      "step": 224
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.000974025974025974,
      "loss": 0.9904,
      "step": 225
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0009783549783549783,
      "loss": 1.1686,
      "step": 226
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0009826839826839828,
      "loss": 0.9818,
      "step": 227
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.000987012987012987,
      "loss": 0.956,
      "step": 228
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0009913419913419913,
      "loss": 1.0682,
      "step": 229
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0009956709956709957,
      "loss": 1.1628,
      "step": 230
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001,
      "loss": 1.1884,
      "step": 231
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0009995178399228545,
      "loss": 1.1141,
      "step": 232
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0009990356798457087,
      "loss": 1.1161,
      "step": 233
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0009985535197685632,
      "loss": 1.1194,
      "step": 234
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0009980713596914176,
      "loss": 1.1716,
      "step": 235
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.000997589199614272,
      "loss": 1.1003,
      "step": 236
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0009971070395371263,
      "loss": 1.0415,
      "step": 237
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0009966248794599807,
      "loss": 1.1521,
      "step": 238
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.000996142719382835,
      "loss": 1.1081,
      "step": 239
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0009956605593056896,
      "loss": 1.0926,
      "step": 240
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0009951783992285439,
      "loss": 1.0322,
      "step": 241
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0009946962391513983,
      "loss": 1.1246,
      "step": 242
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0009942140790742526,
      "loss": 1.2042,
      "step": 243
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.000993731918997107,
      "loss": 1.0714,
      "step": 244
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0009932497589199615,
      "loss": 1.1942,
      "step": 245
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.000992767598842816,
      "loss": 1.2986,
      "step": 246
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0009922854387656701,
      "loss": 1.1237,
      "step": 247
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0009918032786885246,
      "loss": 1.1658,
      "step": 248
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.000991321118611379,
      "loss": 1.1854,
      "step": 249
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0009908389585342333,
      "loss": 0.9304,
      "step": 250
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0009903567984570877,
      "loss": 1.0993,
      "step": 251
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0009898746383799422,
      "loss": 1.1299,
      "step": 252
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0009893924783027966,
      "loss": 1.1111,
      "step": 253
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0009889103182256509,
      "loss": 1.0308,
      "step": 254
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0009884281581485053,
      "loss": 1.3024,
      "step": 255
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0009879459980713598,
      "loss": 1.0254,
      "step": 256
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0009874638379942142,
      "loss": 0.9975,
      "step": 257
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0009869816779170685,
      "loss": 0.9905,
      "step": 258
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.000986499517839923,
      "loss": 1.0941,
      "step": 259
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0009860173577627771,
      "loss": 1.1293,
      "step": 260
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0009855351976856316,
      "loss": 1.1887,
      "step": 261
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.000985053037608486,
      "loss": 1.1322,
      "step": 262
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0009845708775313405,
      "loss": 1.1,
      "step": 263
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0009840887174541947,
      "loss": 1.0521,
      "step": 264
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0009836065573770492,
      "loss": 1.085,
      "step": 265
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0009831243972999036,
      "loss": 1.0351,
      "step": 266
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.000982642237222758,
      "loss": 0.9931,
      "step": 267
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0009821600771456123,
      "loss": 1.176,
      "step": 268
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0009816779170684668,
      "loss": 1.1864,
      "step": 269
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0009811957569913212,
      "loss": 1.0813,
      "step": 270
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0009807135969141755,
      "loss": 1.1721,
      "step": 271
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00098023143683703,
      "loss": 1.2572,
      "step": 272
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0009797492767598844,
      "loss": 1.0906,
      "step": 273
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0009792671166827388,
      "loss": 1.147,
      "step": 274
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.000978784956605593,
      "loss": 1.1785,
      "step": 275
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0009783027965284475,
      "loss": 1.0823,
      "step": 276
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0009778206364513017,
      "loss": 1.188,
      "step": 277
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0009773384763741564,
      "loss": 1.2174,
      "step": 278
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0009768563162970106,
      "loss": 1.1986,
      "step": 279
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0009763741562198651,
      "loss": 1.0602,
      "step": 280
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0009758919961427194,
      "loss": 1.2145,
      "step": 281
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0009754098360655738,
      "loss": 1.0329,
      "step": 282
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0009749276759884281,
      "loss": 1.1151,
      "step": 283
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0009744455159112827,
      "loss": 1.1944,
      "step": 284
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.000973963355834137,
      "loss": 1.2516,
      "step": 285
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0009734811957569913,
      "loss": 1.1092,
      "step": 286
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0009729990356798457,
      "loss": 1.2487,
      "step": 287
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0009725168756027,
      "loss": 1.1322,
      "step": 288
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0009720347155255546,
      "loss": 1.0949,
      "step": 289
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0009715525554484089,
      "loss": 1.185,
      "step": 290
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0009710703953712633,
      "loss": 1.1214,
      "step": 291
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0009705882352941176,
      "loss": 1.197,
      "step": 292
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0009701060752169721,
      "loss": 0.9487,
      "step": 293
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0009696239151398264,
      "loss": 0.9688,
      "step": 294
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0009691417550626809,
      "loss": 1.0108,
      "step": 295
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0009686595949855352,
      "loss": 1.1724,
      "step": 296
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0009681774349083897,
      "loss": 1.1858,
      "step": 297
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.000967695274831244,
      "loss": 1.0832,
      "step": 298
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0009672131147540983,
      "loss": 1.1093,
      "step": 299
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0009667309546769528,
      "loss": 1.2321,
      "step": 300
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0009662487945998072,
      "loss": 1.2301,
      "step": 301
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0009657666345226616,
      "loss": 1.0557,
      "step": 302
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0009652844744455159,
      "loss": 1.0947,
      "step": 303
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0009648023143683703,
      "loss": 1.0836,
      "step": 304
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0009643201542912246,
      "loss": 1.1577,
      "step": 305
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0009638379942140792,
      "loss": 1.1767,
      "step": 306
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0009633558341369335,
      "loss": 1.2526,
      "step": 307
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0009628736740597879,
      "loss": 1.1152,
      "step": 308
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0009623915139826422,
      "loss": 1.1214,
      "step": 309
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0009619093539054966,
      "loss": 1.0843,
      "step": 310
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0009614271938283511,
      "loss": 1.1068,
      "step": 311
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0009609450337512054,
      "loss": 1.1982,
      "step": 312
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0009604628736740598,
      "loss": 1.1096,
      "step": 313
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0009599807135969142,
      "loss": 1.111,
      "step": 314
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0009594985535197686,
      "loss": 1.0595,
      "step": 315
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0009590163934426229,
      "loss": 1.0352,
      "step": 316
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0009585342333654774,
      "loss": 1.1443,
      "step": 317
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0009580520732883318,
      "loss": 1.1725,
      "step": 318
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0009575699132111862,
      "loss": 1.0069,
      "step": 319
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0009570877531340405,
      "loss": 1.215,
      "step": 320
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0009566055930568948,
      "loss": 1.0561,
      "step": 321
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0009561234329797492,
      "loss": 1.1585,
      "step": 322
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0009556412729026037,
      "loss": 1.1111,
      "step": 323
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0009551591128254581,
      "loss": 1.0655,
      "step": 324
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0009546769527483124,
      "loss": 1.1824,
      "step": 325
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0009541947926711668,
      "loss": 1.0486,
      "step": 326
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0009537126325940212,
      "loss": 1.1046,
      "step": 327
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0009532304725168757,
      "loss": 0.9484,
      "step": 328
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.00095274831243973,
      "loss": 1.1309,
      "step": 329
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0009522661523625844,
      "loss": 1.0712,
      "step": 330
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0009517839922854388,
      "loss": 1.0693,
      "step": 331
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0009513018322082932,
      "loss": 1.1716,
      "step": 332
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0009508196721311475,
      "loss": 1.1924,
      "step": 333
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.000950337512054002,
      "loss": 1.1022,
      "step": 334
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0009498553519768564,
      "loss": 1.1383,
      "step": 335
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0009493731918997107,
      "loss": 1.0309,
      "step": 336
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0009488910318225651,
      "loss": 1.0752,
      "step": 337
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0009484088717454194,
      "loss": 1.1865,
      "step": 338
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.000947926711668274,
      "loss": 1.1604,
      "step": 339
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0009474445515911283,
      "loss": 1.0923,
      "step": 340
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0009469623915139827,
      "loss": 1.1492,
      "step": 341
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.000946480231436837,
      "loss": 1.1258,
      "step": 342
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0009459980713596914,
      "loss": 0.9758,
      "step": 343
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0009455159112825458,
      "loss": 1.0749,
      "step": 344
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0009450337512054003,
      "loss": 1.0664,
      "step": 345
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0009445515911282546,
      "loss": 1.1366,
      "step": 346
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0009440694310511089,
      "loss": 1.1221,
      "step": 347
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0009435872709739634,
      "loss": 1.2264,
      "step": 348
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0009431051108968177,
      "loss": 1.1622,
      "step": 349
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0009426229508196722,
      "loss": 1.148,
      "step": 350
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0009421407907425265,
      "loss": 1.1276,
      "step": 351
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.000941658630665381,
      "loss": 1.1088,
      "step": 352
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0009411764705882353,
      "loss": 1.1337,
      "step": 353
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0009406943105110897,
      "loss": 1.2428,
      "step": 354
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.000940212150433944,
      "loss": 1.1288,
      "step": 355
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0009397299903567986,
      "loss": 0.9991,
      "step": 356
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0009392478302796529,
      "loss": 1.0376,
      "step": 357
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0009387656702025072,
      "loss": 1.1639,
      "step": 358
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0009382835101253616,
      "loss": 1.2164,
      "step": 359
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0009378013500482159,
      "loss": 1.1442,
      "step": 360
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0009373191899710705,
      "loss": 1.079,
      "step": 361
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0009368370298939248,
      "loss": 1.1376,
      "step": 362
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0009363548698167792,
      "loss": 0.9937,
      "step": 363
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0009358727097396335,
      "loss": 1.1088,
      "step": 364
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.000935390549662488,
      "loss": 1.1518,
      "step": 365
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0009349083895853423,
      "loss": 1.2147,
      "step": 366
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0009344262295081968,
      "loss": 1.0479,
      "step": 367
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0009339440694310511,
      "loss": 1.3238,
      "step": 368
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0009334619093539056,
      "loss": 1.2031,
      "step": 369
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0009329797492767599,
      "loss": 0.9516,
      "step": 370
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0009324975891996142,
      "loss": 1.2049,
      "step": 371
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0009320154291224687,
      "loss": 1.0044,
      "step": 372
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0009315332690453231,
      "loss": 1.0627,
      "step": 373
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0009310511089681775,
      "loss": 1.142,
      "step": 374
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0009305689488910318,
      "loss": 1.0385,
      "step": 375
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0009300867888138862,
      "loss": 1.2763,
      "step": 376
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0009296046287367405,
      "loss": 1.1706,
      "step": 377
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0009291224686595951,
      "loss": 1.0039,
      "step": 378
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0009286403085824494,
      "loss": 0.9058,
      "step": 379
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0009281581485053038,
      "loss": 1.1065,
      "step": 380
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0009276759884281581,
      "loss": 0.989,
      "step": 381
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0009271938283510126,
      "loss": 1.0565,
      "step": 382
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.000926711668273867,
      "loss": 0.954,
      "step": 383
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0009262295081967213,
      "loss": 1.0987,
      "step": 384
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0009257473481195757,
      "loss": 1.1354,
      "step": 385
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0009252651880424301,
      "loss": 1.262,
      "step": 386
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0009247830279652845,
      "loss": 1.1574,
      "step": 387
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0009243008678881388,
      "loss": 1.0632,
      "step": 388
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0009238187078109933,
      "loss": 0.9562,
      "step": 389
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0009233365477338477,
      "loss": 1.1612,
      "step": 390
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0009228543876567021,
      "loss": 1.0302,
      "step": 391
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0009223722275795564,
      "loss": 1.1272,
      "step": 392
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0009218900675024107,
      "loss": 1.064,
      "step": 393
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0009214079074252653,
      "loss": 1.196,
      "step": 394
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0009209257473481197,
      "loss": 1.0008,
      "step": 395
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.000920443587270974,
      "loss": 1.1617,
      "step": 396
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0009199614271938283,
      "loss": 1.1154,
      "step": 397
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0009194792671166827,
      "loss": 1.242,
      "step": 398
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0009189971070395371,
      "loss": 1.0921,
      "step": 399
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0009185149469623916,
      "loss": 1.2603,
      "step": 400
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0009180327868852459,
      "loss": 1.1152,
      "step": 401
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0009175506268081003,
      "loss": 1.2011,
      "step": 402
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0009170684667309547,
      "loss": 1.2023,
      "step": 403
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0009165863066538091,
      "loss": 0.9507,
      "step": 404
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0009161041465766635,
      "loss": 1.0748,
      "step": 405
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0009156219864995179,
      "loss": 1.0345,
      "step": 406
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0009151398264223723,
      "loss": 1.006,
      "step": 407
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0009146576663452266,
      "loss": 1.1116,
      "step": 408
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.000914175506268081,
      "loss": 0.9627,
      "step": 409
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0009136933461909353,
      "loss": 1.2604,
      "step": 410
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0009132111861137899,
      "loss": 1.0962,
      "step": 411
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0009127290260366442,
      "loss": 1.1556,
      "step": 412
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0009122468659594986,
      "loss": 1.0787,
      "step": 413
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0009117647058823529,
      "loss": 1.1848,
      "step": 414
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0009112825458052073,
      "loss": 1.2585,
      "step": 415
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0009108003857280618,
      "loss": 0.9717,
      "step": 416
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0009103182256509162,
      "loss": 1.2535,
      "step": 417
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0009098360655737705,
      "loss": 1.2018,
      "step": 418
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0009093539054966248,
      "loss": 0.9874,
      "step": 419
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0009088717454194793,
      "loss": 0.9723,
      "step": 420
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0009083895853423336,
      "loss": 1.0743,
      "step": 421
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0009079074252651881,
      "loss": 1.2116,
      "step": 422
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0009074252651880424,
      "loss": 0.97,
      "step": 423
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0009069431051108969,
      "loss": 1.1013,
      "step": 424
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0009064609450337512,
      "loss": 1.1132,
      "step": 425
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0009059787849566056,
      "loss": 1.2468,
      "step": 426
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.00090549662487946,
      "loss": 1.0855,
      "step": 427
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0009050144648023145,
      "loss": 0.9831,
      "step": 428
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0009045323047251688,
      "loss": 1.0923,
      "step": 429
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0009040501446480232,
      "loss": 1.0554,
      "step": 430
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0009035679845708775,
      "loss": 1.1851,
      "step": 431
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0009030858244937318,
      "loss": 1.1928,
      "step": 432
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0009026036644165864,
      "loss": 1.1661,
      "step": 433
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0009021215043394407,
      "loss": 1.1555,
      "step": 434
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0009016393442622951,
      "loss": 1.156,
      "step": 435
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0009011571841851494,
      "loss": 1.0366,
      "step": 436
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0009006750241080039,
      "loss": 1.1027,
      "step": 437
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0009001928640308583,
      "loss": 0.9956,
      "step": 438
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0008997107039537127,
      "loss": 1.1107,
      "step": 439
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.000899228543876567,
      "loss": 1.0954,
      "step": 440
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0008987463837994215,
      "loss": 1.0944,
      "step": 441
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0008982642237222758,
      "loss": 0.9789,
      "step": 442
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0008977820636451301,
      "loss": 1.1113,
      "step": 443
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0008972999035679846,
      "loss": 1.0485,
      "step": 444
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.000896817743490839,
      "loss": 1.045,
      "step": 445
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0008963355834136934,
      "loss": 1.1127,
      "step": 446
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0008958534233365477,
      "loss": 1.1398,
      "step": 447
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0008953712632594021,
      "loss": 0.9725,
      "step": 448
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0008948891031822566,
      "loss": 1.2104,
      "step": 449
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.000894406943105111,
      "loss": 1.0226,
      "step": 450
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0008939247830279653,
      "loss": 1.1138,
      "step": 451
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0008934426229508197,
      "loss": 1.1227,
      "step": 452
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.000892960462873674,
      "loss": 1.0894,
      "step": 453
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0008924783027965285,
      "loss": 1.0022,
      "step": 454
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0008919961427193829,
      "loss": 1.1137,
      "step": 455
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0008915139826422372,
      "loss": 1.0367,
      "step": 456
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0008910318225650916,
      "loss": 1.228,
      "step": 457
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.000890549662487946,
      "loss": 1.0575,
      "step": 458
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0008900675024108004,
      "loss": 1.1908,
      "step": 459
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0008895853423336548,
      "loss": 1.0898,
      "step": 460
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0008891031822565092,
      "loss": 1.0916,
      "step": 461
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0008886210221793636,
      "loss": 1.1198,
      "step": 462
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.000888138862102218,
      "loss": 0.9583,
      "step": 463
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0008876567020250723,
      "loss": 1.0544,
      "step": 464
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0008871745419479267,
      "loss": 1.0445,
      "step": 465
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0008866923818707812,
      "loss": 1.1481,
      "step": 466
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0008862102217936356,
      "loss": 1.1319,
      "step": 467
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0008857280617164899,
      "loss": 1.1882,
      "step": 468
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0008852459016393442,
      "loss": 1.227,
      "step": 469
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0008847637415621986,
      "loss": 0.9746,
      "step": 470
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0008842815814850531,
      "loss": 1.0935,
      "step": 471
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0008837994214079075,
      "loss": 1.1487,
      "step": 472
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0008833172613307618,
      "loss": 1.0635,
      "step": 473
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0008828351012536162,
      "loss": 1.1246,
      "step": 474
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0008823529411764706,
      "loss": 1.0325,
      "step": 475
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.000881870781099325,
      "loss": 1.1848,
      "step": 476
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0008813886210221794,
      "loss": 0.9926,
      "step": 477
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0008809064609450338,
      "loss": 1.0038,
      "step": 478
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0008804243008678882,
      "loss": 1.0971,
      "step": 479
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0008799421407907425,
      "loss": 1.0208,
      "step": 480
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0008794599807135969,
      "loss": 1.3191,
      "step": 481
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0008789778206364513,
      "loss": 1.0049,
      "step": 482
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0008784956605593058,
      "loss": 1.1153,
      "step": 483
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0008780135004821601,
      "loss": 1.0162,
      "step": 484
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0008775313404050145,
      "loss": 1.1778,
      "step": 485
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0008770491803278688,
      "loss": 0.9949,
      "step": 486
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0008765670202507232,
      "loss": 1.0271,
      "step": 487
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0008760848601735777,
      "loss": 1.134,
      "step": 488
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0008756027000964321,
      "loss": 0.9451,
      "step": 489
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0008751205400192864,
      "loss": 1.0568,
      "step": 490
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0008746383799421407,
      "loss": 0.9944,
      "step": 491
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0008741562198649952,
      "loss": 1.0101,
      "step": 492
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0008736740597878495,
      "loss": 1.003,
      "step": 493
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.000873191899710704,
      "loss": 1.1771,
      "step": 494
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0008727097396335583,
      "loss": 1.055,
      "step": 495
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0008722275795564128,
      "loss": 1.013,
      "step": 496
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0008717454194792671,
      "loss": 1.0184,
      "step": 497
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0008712632594021215,
      "loss": 0.9978,
      "step": 498
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0008707810993249759,
      "loss": 1.1559,
      "step": 499
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0008702989392478304,
      "loss": 1.0473,
      "step": 500
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008698167791706847,
      "loss": 1.0426,
      "step": 501
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008693346190935391,
      "loss": 1.085,
      "step": 502
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008688524590163934,
      "loss": 1.0977,
      "step": 503
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0008683702989392477,
      "loss": 1.0556,
      "step": 504
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008678881388621023,
      "loss": 1.029,
      "step": 505
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008674059787849566,
      "loss": 1.0404,
      "step": 506
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.000866923818707811,
      "loss": 0.8903,
      "step": 507
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008664416586306653,
      "loss": 1.0897,
      "step": 508
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0008659594985535198,
      "loss": 0.9421,
      "step": 509
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008654773384763742,
      "loss": 1.0863,
      "step": 510
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008649951783992286,
      "loss": 1.1676,
      "step": 511
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008645130183220829,
      "loss": 1.2369,
      "step": 512
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008640308582449374,
      "loss": 1.0418,
      "step": 513
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0008635486981677917,
      "loss": 1.0736,
      "step": 514
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.000863066538090646,
      "loss": 0.9336,
      "step": 515
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008625843780135005,
      "loss": 1.0159,
      "step": 516
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.000862102217936355,
      "loss": 1.0964,
      "step": 517
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0008616200578592093,
      "loss": 0.9792,
      "step": 518
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008611378977820636,
      "loss": 1.1221,
      "step": 519
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.000860655737704918,
      "loss": 1.0956,
      "step": 520
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008601735776277725,
      "loss": 1.0059,
      "step": 521
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008596914175506269,
      "loss": 1.2022,
      "step": 522
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0008592092574734812,
      "loss": 1.1426,
      "step": 523
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008587270973963356,
      "loss": 1.1001,
      "step": 524
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008582449373191899,
      "loss": 1.1615,
      "step": 525
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008577627772420444,
      "loss": 0.9731,
      "step": 526
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0008572806171648988,
      "loss": 1.1764,
      "step": 527
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008567984570877532,
      "loss": 0.9236,
      "step": 528
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008563162970106075,
      "loss": 1.1189,
      "step": 529
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008558341369334619,
      "loss": 1.2268,
      "step": 530
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008553519768563163,
      "loss": 0.9648,
      "step": 531
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0008548698167791707,
      "loss": 1.0084,
      "step": 532
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0008543876567020251,
      "loss": 0.9866,
      "step": 533
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0008539054966248795,
      "loss": 1.1246,
      "step": 534
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0008534233365477339,
      "loss": 1.2147,
      "step": 535
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0008529411764705882,
      "loss": 1.0698,
      "step": 536
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0008524590163934426,
      "loss": 1.0189,
      "step": 537
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0008519768563162971,
      "loss": 1.1573,
      "step": 538
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0008514946962391515,
      "loss": 0.9102,
      "step": 539
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0008510125361620058,
      "loss": 1.0354,
      "step": 540
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0008505303760848601,
      "loss": 1.1473,
      "step": 541
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0008500482160077145,
      "loss": 1.0148,
      "step": 542
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.000849566055930569,
      "loss": 1.0467,
      "step": 543
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0008490838958534234,
      "loss": 0.9783,
      "step": 544
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0008486017357762777,
      "loss": 1.1575,
      "step": 545
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0008481195756991321,
      "loss": 1.1897,
      "step": 546
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0008476374156219865,
      "loss": 0.9405,
      "step": 547
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0008471552555448409,
      "loss": 1.1367,
      "step": 548
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0008466730954676953,
      "loss": 1.0622,
      "step": 549
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0008461909353905497,
      "loss": 0.9698,
      "step": 550
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0008457087753134041,
      "loss": 1.1352,
      "step": 551
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0008452266152362585,
      "loss": 1.1795,
      "step": 552
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0008447444551591128,
      "loss": 0.9561,
      "step": 553
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0008442622950819672,
      "loss": 1.0126,
      "step": 554
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0008437801350048217,
      "loss": 1.1289,
      "step": 555
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.000843297974927676,
      "loss": 1.0724,
      "step": 556
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0008428158148505304,
      "loss": 1.0385,
      "step": 557
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0008423336547733847,
      "loss": 1.0436,
      "step": 558
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0008418514946962391,
      "loss": 1.0969,
      "step": 559
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0008413693346190936,
      "loss": 1.1783,
      "step": 560
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.000840887174541948,
      "loss": 0.827,
      "step": 561
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0008404050144648023,
      "loss": 0.9303,
      "step": 562
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0008399228543876567,
      "loss": 1.0594,
      "step": 563
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0008394406943105111,
      "loss": 1.0594,
      "step": 564
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0008389585342333656,
      "loss": 1.0038,
      "step": 565
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0008384763741562199,
      "loss": 0.9673,
      "step": 566
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0008379942140790742,
      "loss": 1.1196,
      "step": 567
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0008375120540019287,
      "loss": 1.0763,
      "step": 568
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.000837029893924783,
      "loss": 1.1149,
      "step": 569
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0008365477338476374,
      "loss": 1.0662,
      "step": 570
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0008360655737704918,
      "loss": 1.2822,
      "step": 571
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0008355834136933463,
      "loss": 1.1552,
      "step": 572
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0008351012536162006,
      "loss": 1.0322,
      "step": 573
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.000834619093539055,
      "loss": 1.1437,
      "step": 574
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0008341369334619093,
      "loss": 1.0526,
      "step": 575
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0008336547733847639,
      "loss": 1.0704,
      "step": 576
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0008331726133076182,
      "loss": 1.0279,
      "step": 577
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0008326904532304725,
      "loss": 1.018,
      "step": 578
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0008322082931533269,
      "loss": 0.9848,
      "step": 579
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0008317261330761812,
      "loss": 1.0542,
      "step": 580
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0008312439729990357,
      "loss": 1.0116,
      "step": 581
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0008307618129218901,
      "loss": 0.9952,
      "step": 582
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0008302796528447445,
      "loss": 1.0252,
      "step": 583
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0008297974927675988,
      "loss": 0.9885,
      "step": 584
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0008293153326904533,
      "loss": 1.1983,
      "step": 585
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0008288331726133076,
      "loss": 1.08,
      "step": 586
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0008283510125361621,
      "loss": 1.126,
      "step": 587
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0008278688524590164,
      "loss": 1.0558,
      "step": 588
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0008273866923818709,
      "loss": 1.166,
      "step": 589
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0008269045323047252,
      "loss": 1.1502,
      "step": 590
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0008264223722275795,
      "loss": 1.1002,
      "step": 591
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0008259402121504339,
      "loss": 1.1237,
      "step": 592
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0008254580520732884,
      "loss": 1.0144,
      "step": 593
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0008249758919961428,
      "loss": 1.0103,
      "step": 594
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0008244937319189971,
      "loss": 1.07,
      "step": 595
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0008240115718418515,
      "loss": 1.142,
      "step": 596
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0008235294117647058,
      "loss": 1.0855,
      "step": 597
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0008230472516875604,
      "loss": 1.0312,
      "step": 598
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0008225650916104147,
      "loss": 0.917,
      "step": 599
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.000822082931533269,
      "loss": 1.1494,
      "step": 600
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0008216007714561234,
      "loss": 1.0559,
      "step": 601
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0008211186113789778,
      "loss": 1.108,
      "step": 602
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0008206364513018322,
      "loss": 0.9409,
      "step": 603
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0008201542912246866,
      "loss": 0.9672,
      "step": 604
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.000819672131147541,
      "loss": 1.0579,
      "step": 605
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0008191899710703954,
      "loss": 1.1659,
      "step": 606
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0008187078109932498,
      "loss": 1.1733,
      "step": 607
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0008182256509161041,
      "loss": 1.0583,
      "step": 608
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0008177434908389586,
      "loss": 1.1313,
      "step": 609
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.000817261330761813,
      "loss": 0.9519,
      "step": 610
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0008167791706846674,
      "loss": 1.0193,
      "step": 611
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0008162970106075217,
      "loss": 1.0417,
      "step": 612
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.000815814850530376,
      "loss": 1.0202,
      "step": 613
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0008153326904532304,
      "loss": 1.0245,
      "step": 614
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.000814850530376085,
      "loss": 1.1455,
      "step": 615
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0008143683702989393,
      "loss": 1.095,
      "step": 616
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0008138862102217936,
      "loss": 1.0078,
      "step": 617
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.000813404050144648,
      "loss": 1.2362,
      "step": 618
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0008129218900675024,
      "loss": 1.0398,
      "step": 619
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0008124397299903569,
      "loss": 1.0449,
      "step": 620
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0008119575699132112,
      "loss": 1.0303,
      "step": 621
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0008114754098360656,
      "loss": 1.0374,
      "step": 622
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.00081099324975892,
      "loss": 1.0453,
      "step": 623
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0008105110896817744,
      "loss": 1.1168,
      "step": 624
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0008100289296046287,
      "loss": 0.9666,
      "step": 625
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0008095467695274831,
      "loss": 1.0142,
      "step": 626
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0008090646094503376,
      "loss": 1.078,
      "step": 627
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0008085824493731919,
      "loss": 1.2622,
      "step": 628
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0008081002892960463,
      "loss": 1.0153,
      "step": 629
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0008076181292189006,
      "loss": 1.0276,
      "step": 630
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0008071359691417552,
      "loss": 1.2108,
      "step": 631
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0008066538090646095,
      "loss": 1.0004,
      "step": 632
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0008061716489874639,
      "loss": 1.0675,
      "step": 633
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0008056894889103182,
      "loss": 1.0286,
      "step": 634
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0008052073288331726,
      "loss": 1.027,
      "step": 635
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.000804725168756027,
      "loss": 1.0286,
      "step": 636
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0008042430086788815,
      "loss": 1.1526,
      "step": 637
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0008037608486017358,
      "loss": 1.1572,
      "step": 638
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0008032786885245901,
      "loss": 1.0907,
      "step": 639
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0008027965284474446,
      "loss": 0.9963,
      "step": 640
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0008023143683702989,
      "loss": 1.1124,
      "step": 641
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0008018322082931534,
      "loss": 1.113,
      "step": 642
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0008013500482160077,
      "loss": 1.0804,
      "step": 643
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0008008678881388622,
      "loss": 1.1701,
      "step": 644
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0008003857280617165,
      "loss": 1.0606,
      "step": 645
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0007999035679845709,
      "loss": 1.0892,
      "step": 646
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0007994214079074252,
      "loss": 1.059,
      "step": 647
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0007989392478302798,
      "loss": 1.2008,
      "step": 648
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0007984570877531341,
      "loss": 1.0894,
      "step": 649
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0007979749276759884,
      "loss": 1.0922,
      "step": 650
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0007974927675988428,
      "loss": 1.2766,
      "step": 651
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0007970106075216971,
      "loss": 0.9833,
      "step": 652
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0007965284474445517,
      "loss": 1.0018,
      "step": 653
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.000796046287367406,
      "loss": 1.0181,
      "step": 654
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0007955641272902604,
      "loss": 1.0681,
      "step": 655
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0007950819672131147,
      "loss": 1.0764,
      "step": 656
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0007945998071359692,
      "loss": 1.0458,
      "step": 657
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0007941176470588235,
      "loss": 0.9658,
      "step": 658
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.000793635486981678,
      "loss": 0.8785,
      "step": 659
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0007931533269045323,
      "loss": 1.0566,
      "step": 660
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0007926711668273868,
      "loss": 1.0215,
      "step": 661
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0007921890067502411,
      "loss": 1.1886,
      "step": 662
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0007917068466730954,
      "loss": 1.1202,
      "step": 663
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0007912246865959498,
      "loss": 1.073,
      "step": 664
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0007907425265188043,
      "loss": 1.0868,
      "step": 665
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0007902603664416587,
      "loss": 1.0764,
      "step": 666
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.000789778206364513,
      "loss": 1.1784,
      "step": 667
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0007892960462873674,
      "loss": 1.101,
      "step": 668
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0007888138862102217,
      "loss": 1.027,
      "step": 669
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0007883317261330763,
      "loss": 1.1182,
      "step": 670
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0007878495660559306,
      "loss": 1.1047,
      "step": 671
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.000787367405978785,
      "loss": 0.9351,
      "step": 672
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0007868852459016393,
      "loss": 0.9908,
      "step": 673
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0007864030858244938,
      "loss": 1.168,
      "step": 674
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0007859209257473481,
      "loss": 0.9895,
      "step": 675
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0007854387656702025,
      "loss": 0.8862,
      "step": 676
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0007849566055930569,
      "loss": 1.0756,
      "step": 677
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0007844744455159113,
      "loss": 0.9927,
      "step": 678
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0007839922854387657,
      "loss": 0.9173,
      "step": 679
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.00078351012536162,
      "loss": 1.1517,
      "step": 680
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0007830279652844745,
      "loss": 1.0678,
      "step": 681
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0007825458052073289,
      "loss": 1.1485,
      "step": 682
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0007820636451301833,
      "loss": 1.0989,
      "step": 683
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0007815814850530376,
      "loss": 1.1312,
      "step": 684
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.000781099324975892,
      "loss": 1.2199,
      "step": 685
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0007806171648987463,
      "loss": 1.128,
      "step": 686
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0007801350048216009,
      "loss": 1.1446,
      "step": 687
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0007796528447444552,
      "loss": 1.0141,
      "step": 688
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0007791706846673095,
      "loss": 1.0733,
      "step": 689
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0007786885245901639,
      "loss": 0.9076,
      "step": 690
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0007782063645130183,
      "loss": 1.0017,
      "step": 691
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0007777242044358728,
      "loss": 1.1586,
      "step": 692
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0007772420443587271,
      "loss": 1.0245,
      "step": 693
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0007767598842815815,
      "loss": 1.031,
      "step": 694
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0007762777242044359,
      "loss": 0.9675,
      "step": 695
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0007757955641272903,
      "loss": 1.0335,
      "step": 696
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0007753134040501446,
      "loss": 1.0847,
      "step": 697
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.000774831243972999,
      "loss": 1.0991,
      "step": 698
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0007743490838958535,
      "loss": 1.0502,
      "step": 699
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0007738669238187078,
      "loss": 1.1933,
      "step": 700
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0007733847637415622,
      "loss": 1.1591,
      "step": 701
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0007729026036644165,
      "loss": 1.2157,
      "step": 702
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0007724204435872711,
      "loss": 0.8561,
      "step": 703
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0007719382835101254,
      "loss": 1.1706,
      "step": 704
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0007714561234329798,
      "loss": 0.9493,
      "step": 705
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0007709739633558341,
      "loss": 1.0889,
      "step": 706
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0007704918032786885,
      "loss": 1.1517,
      "step": 707
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0007700096432015429,
      "loss": 1.2808,
      "step": 708
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0007695274831243974,
      "loss": 1.1846,
      "step": 709
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0007690453230472517,
      "loss": 1.1333,
      "step": 710
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.000768563162970106,
      "loss": 1.0859,
      "step": 711
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0007680810028929605,
      "loss": 1.0418,
      "step": 712
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0007675988428158148,
      "loss": 1.0998,
      "step": 713
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0007671166827386693,
      "loss": 0.964,
      "step": 714
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0007666345226615236,
      "loss": 1.0466,
      "step": 715
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0007661523625843781,
      "loss": 0.9154,
      "step": 716
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0007656702025072324,
      "loss": 1.0316,
      "step": 717
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0007651880424300868,
      "loss": 0.9918,
      "step": 718
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0007647058823529411,
      "loss": 1.1009,
      "step": 719
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0007642237222757957,
      "loss": 1.0473,
      "step": 720
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.00076374156219865,
      "loss": 1.2249,
      "step": 721
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0007632594021215044,
      "loss": 1.1807,
      "step": 722
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0007627772420443587,
      "loss": 1.078,
      "step": 723
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.000762295081967213,
      "loss": 0.9627,
      "step": 724
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0007618129218900676,
      "loss": 1.0833,
      "step": 725
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0007613307618129219,
      "loss": 1.1887,
      "step": 726
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0007608486017357763,
      "loss": 1.0047,
      "step": 727
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0007603664416586306,
      "loss": 1.1554,
      "step": 728
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0007598842815814851,
      "loss": 0.8803,
      "step": 729
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0007594021215043394,
      "loss": 1.1791,
      "step": 730
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0007589199614271939,
      "loss": 0.9507,
      "step": 731
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0007584378013500482,
      "loss": 0.9954,
      "step": 732
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0007579556412729027,
      "loss": 1.0454,
      "step": 733
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.000757473481195757,
      "loss": 1.0107,
      "step": 734
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0007569913211186113,
      "loss": 1.1575,
      "step": 735
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0007565091610414658,
      "loss": 0.9125,
      "step": 736
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0007560270009643202,
      "loss": 1.035,
      "step": 737
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0007555448408871746,
      "loss": 1.0789,
      "step": 738
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0007550626808100289,
      "loss": 1.0819,
      "step": 739
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0007545805207328833,
      "loss": 0.967,
      "step": 740
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0007540983606557376,
      "loss": 1.3091,
      "step": 741
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0007536162005785922,
      "loss": 1.1077,
      "step": 742
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0007531340405014465,
      "loss": 0.974,
      "step": 743
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0007526518804243009,
      "loss": 1.1048,
      "step": 744
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0007521697203471552,
      "loss": 0.983,
      "step": 745
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0007516875602700097,
      "loss": 1.0409,
      "step": 746
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0007512054001928641,
      "loss": 1.0654,
      "step": 747
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0007507232401157184,
      "loss": 0.9247,
      "step": 748
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0007502410800385728,
      "loss": 1.0141,
      "step": 749
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0007497589199614272,
      "loss": 1.1257,
      "step": 750
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0007492767598842816,
      "loss": 1.1568,
      "step": 751
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0007487945998071359,
      "loss": 1.0819,
      "step": 752
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0007483124397299904,
      "loss": 1.1643,
      "step": 753
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0007478302796528448,
      "loss": 1.1167,
      "step": 754
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0007473481195756992,
      "loss": 1.1221,
      "step": 755
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0007468659594985535,
      "loss": 1.0771,
      "step": 756
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0007463837994214079,
      "loss": 0.8771,
      "step": 757
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0007459016393442624,
      "loss": 1.0058,
      "step": 758
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0007454194792671168,
      "loss": 1.1441,
      "step": 759
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0007449373191899711,
      "loss": 1.1183,
      "step": 760
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0007444551591128254,
      "loss": 1.0336,
      "step": 761
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0007439729990356798,
      "loss": 1.0693,
      "step": 762
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0007434908389585342,
      "loss": 1.0374,
      "step": 763
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0007430086788813887,
      "loss": 0.9704,
      "step": 764
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.000742526518804243,
      "loss": 1.1111,
      "step": 765
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0007420443587270974,
      "loss": 1.2217,
      "step": 766
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0007415621986499518,
      "loss": 0.966,
      "step": 767
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0007410800385728062,
      "loss": 0.9262,
      "step": 768
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0007405978784956606,
      "loss": 1.0035,
      "step": 769
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.000740115718418515,
      "loss": 1.1498,
      "step": 770
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0007396335583413694,
      "loss": 1.0386,
      "step": 771
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0007391513982642237,
      "loss": 1.0048,
      "step": 772
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0007386692381870781,
      "loss": 1.0917,
      "step": 773
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0007381870781099324,
      "loss": 1.0998,
      "step": 774
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.000737704918032787,
      "loss": 1.1526,
      "step": 775
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0007372227579556413,
      "loss": 1.0204,
      "step": 776
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0007367405978784957,
      "loss": 1.0593,
      "step": 777
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.00073625843780135,
      "loss": 1.0883,
      "step": 778
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0007357762777242044,
      "loss": 1.1083,
      "step": 779
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0007352941176470589,
      "loss": 0.9958,
      "step": 780
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0007348119575699133,
      "loss": 1.0059,
      "step": 781
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0007343297974927676,
      "loss": 0.9452,
      "step": 782
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.000733847637415622,
      "loss": 1.1131,
      "step": 783
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0007333654773384764,
      "loss": 1.0083,
      "step": 784
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0007328833172613307,
      "loss": 1.0568,
      "step": 785
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0007324011571841852,
      "loss": 1.0146,
      "step": 786
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0007319189971070395,
      "loss": 1.0273,
      "step": 787
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.000731436837029894,
      "loss": 1.1359,
      "step": 788
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0007309546769527483,
      "loss": 1.003,
      "step": 789
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0007304725168756027,
      "loss": 1.0456,
      "step": 790
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0007299903567984571,
      "loss": 1.0064,
      "step": 791
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0007295081967213116,
      "loss": 1.0594,
      "step": 792
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0007290260366441659,
      "loss": 1.0591,
      "step": 793
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0007285438765670203,
      "loss": 1.1441,
      "step": 794
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0007280617164898746,
      "loss": 1.0743,
      "step": 795
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.0007275795564127289,
      "loss": 0.9452,
      "step": 796
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.0007270973963355835,
      "loss": 0.9126,
      "step": 797
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.0007266152362584378,
      "loss": 1.1653,
      "step": 798
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.0007261330761812922,
      "loss": 0.9555,
      "step": 799
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0007256509161041465,
      "loss": 0.9762,
      "step": 800
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.000725168756027001,
      "loss": 1.1166,
      "step": 801
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0007246865959498554,
      "loss": 1.0618,
      "step": 802
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0007242044358727098,
      "loss": 1.033,
      "step": 803
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0007237222757955641,
      "loss": 1.0232,
      "step": 804
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.0007232401157184186,
      "loss": 1.1064,
      "step": 805
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.0007227579556412729,
      "loss": 1.0691,
      "step": 806
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.0007222757955641273,
      "loss": 0.9102,
      "step": 807
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.0007217936354869817,
      "loss": 1.1473,
      "step": 808
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.0007213114754098362,
      "loss": 1.0974,
      "step": 809
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.0007208293153326905,
      "loss": 1.1552,
      "step": 810
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.0007203471552555448,
      "loss": 1.1848,
      "step": 811
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.0007198649951783992,
      "loss": 0.9633,
      "step": 812
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.0007193828351012537,
      "loss": 1.1888,
      "step": 813
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0007189006750241081,
      "loss": 1.1083,
      "step": 814
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0007184185149469624,
      "loss": 1.0027,
      "step": 815
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0007179363548698168,
      "loss": 1.0739,
      "step": 816
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0007174541947926711,
      "loss": 1.0106,
      "step": 817
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0007169720347155256,
      "loss": 1.0084,
      "step": 818
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.00071648987463838,
      "loss": 1.1448,
      "step": 819
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.0007160077145612344,
      "loss": 1.1963,
      "step": 820
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.0007155255544840887,
      "loss": 1.0951,
      "step": 821
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.0007150433944069431,
      "loss": 0.9172,
      "step": 822
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.0007145612343297975,
      "loss": 0.9272,
      "step": 823
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.0007140790742526519,
      "loss": 0.9833,
      "step": 824
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.0007135969141755063,
      "loss": 1.1178,
      "step": 825
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.0007131147540983607,
      "loss": 1.0497,
      "step": 826
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.0007126325940212151,
      "loss": 1.0593,
      "step": 827
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0007121504339440694,
      "loss": 1.014,
      "step": 828
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0007116682738669238,
      "loss": 1.0971,
      "step": 829
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0007111861137897783,
      "loss": 1.0408,
      "step": 830
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0007107039537126327,
      "loss": 1.0473,
      "step": 831
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.000710221793635487,
      "loss": 1.0983,
      "step": 832
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.0007097396335583413,
      "loss": 0.9985,
      "step": 833
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.0007092574734811957,
      "loss": 1.0532,
      "step": 834
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.0007087753134040502,
      "loss": 1.0621,
      "step": 835
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.0007082931533269046,
      "loss": 1.2265,
      "step": 836
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0007078109932497589,
      "loss": 1.0318,
      "step": 837
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0007073288331726133,
      "loss": 1.0901,
      "step": 838
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0007068466730954677,
      "loss": 0.9659,
      "step": 839
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0007063645130183221,
      "loss": 1.2602,
      "step": 840
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0007058823529411765,
      "loss": 0.9417,
      "step": 841
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.0007054001928640309,
      "loss": 1.1271,
      "step": 842
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.0007049180327868853,
      "loss": 1.0569,
      "step": 843
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.0007044358727097397,
      "loss": 1.0556,
      "step": 844
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.000703953712632594,
      "loss": 1.0258,
      "step": 845
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.0007034715525554483,
      "loss": 1.2045,
      "step": 846
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.0007029893924783029,
      "loss": 0.944,
      "step": 847
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.0007025072324011572,
      "loss": 1.2429,
      "step": 848
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.0007020250723240116,
      "loss": 1.0729,
      "step": 849
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.0007015429122468659,
      "loss": 1.0123,
      "step": 850
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.0007010607521697203,
      "loss": 1.0793,
      "step": 851
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.0007005785920925748,
      "loss": 0.9514,
      "step": 852
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.0007000964320154292,
      "loss": 1.037,
      "step": 853
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.0006996142719382835,
      "loss": 1.037,
      "step": 854
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.0006991321118611379,
      "loss": 1.0674,
      "step": 855
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.0006986499517839923,
      "loss": 1.0288,
      "step": 856
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.0006981677917068466,
      "loss": 0.9805,
      "step": 857
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.0006976856316297011,
      "loss": 1.0386,
      "step": 858
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.0006972034715525554,
      "loss": 1.1265,
      "step": 859
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.0006967213114754099,
      "loss": 1.0609,
      "step": 860
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.0006962391513982642,
      "loss": 1.0822,
      "step": 861
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.0006957569913211186,
      "loss": 1.1862,
      "step": 862
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.000695274831243973,
      "loss": 1.0682,
      "step": 863
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.0006947926711668275,
      "loss": 0.9604,
      "step": 864
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.0006943105110896818,
      "loss": 1.1129,
      "step": 865
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.0006938283510125362,
      "loss": 1.0731,
      "step": 866
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.0006933461909353905,
      "loss": 1.0575,
      "step": 867
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.0006928640308582448,
      "loss": 1.1215,
      "step": 868
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0006923818707810994,
      "loss": 0.9758,
      "step": 869
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0006918997107039537,
      "loss": 0.9426,
      "step": 870
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0006914175506268081,
      "loss": 1.0214,
      "step": 871
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0006909353905496624,
      "loss": 1.1699,
      "step": 872
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0006904532304725169,
      "loss": 1.0891,
      "step": 873
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.0006899710703953713,
      "loss": 1.079,
      "step": 874
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.0006894889103182257,
      "loss": 1.0034,
      "step": 875
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.00068900675024108,
      "loss": 1.0434,
      "step": 876
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.0006885245901639345,
      "loss": 1.0492,
      "step": 877
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.0006880424300867888,
      "loss": 1.0614,
      "step": 878
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.0006875602700096432,
      "loss": 1.1515,
      "step": 879
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.0006870781099324976,
      "loss": 1.0967,
      "step": 880
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.0006865959498553521,
      "loss": 1.046,
      "step": 881
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.0006861137897782064,
      "loss": 1.0718,
      "step": 882
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.0006856316297010607,
      "loss": 1.0201,
      "step": 883
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.0006851494696239151,
      "loss": 1.048,
      "step": 884
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.0006846673095467696,
      "loss": 0.977,
      "step": 885
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.000684185149469624,
      "loss": 1.0941,
      "step": 886
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.0006837029893924783,
      "loss": 1.19,
      "step": 887
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.0006832208293153327,
      "loss": 0.8927,
      "step": 888
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.000682738669238187,
      "loss": 1.1143,
      "step": 889
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.0006822565091610415,
      "loss": 1.1328,
      "step": 890
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.0006817743490838959,
      "loss": 1.1446,
      "step": 891
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.0006812921890067503,
      "loss": 1.1434,
      "step": 892
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.0006808100289296046,
      "loss": 1.1254,
      "step": 893
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.000680327868852459,
      "loss": 0.967,
      "step": 894
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.0006798457087753134,
      "loss": 1.0547,
      "step": 895
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.0006793635486981678,
      "loss": 1.1674,
      "step": 896
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.0006788813886210222,
      "loss": 1.106,
      "step": 897
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.0006783992285438766,
      "loss": 1.0611,
      "step": 898
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.000677917068466731,
      "loss": 0.9221,
      "step": 899
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.0006774349083895853,
      "loss": 1.0426,
      "step": 900
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.0006769527483124397,
      "loss": 1.0533,
      "step": 901
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.0006764705882352942,
      "loss": 0.9053,
      "step": 902
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.0006759884281581486,
      "loss": 1.0504,
      "step": 903
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.0006755062680810029,
      "loss": 1.1117,
      "step": 904
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.0006750241080038572,
      "loss": 1.0347,
      "step": 905
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.0006745419479267116,
      "loss": 1.0974,
      "step": 906
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.0006740597878495661,
      "loss": 1.1229,
      "step": 907
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.0006735776277724205,
      "loss": 1.0022,
      "step": 908
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.0006730954676952748,
      "loss": 1.1696,
      "step": 909
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.0006726133076181292,
      "loss": 1.0328,
      "step": 910
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.0006721311475409836,
      "loss": 1.0789,
      "step": 911
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.000671648987463838,
      "loss": 0.9383,
      "step": 912
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.0006711668273866924,
      "loss": 0.9694,
      "step": 913
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.0006706846673095468,
      "loss": 1.0385,
      "step": 914
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.0006702025072324012,
      "loss": 1.0456,
      "step": 915
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.0006697203471552556,
      "loss": 0.9766,
      "step": 916
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.0006692381870781099,
      "loss": 1.033,
      "step": 917
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.0006687560270009643,
      "loss": 0.9741,
      "step": 918
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.0006682738669238188,
      "loss": 1.0916,
      "step": 919
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.0006677917068466731,
      "loss": 0.9836,
      "step": 920
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.0006673095467695275,
      "loss": 1.0623,
      "step": 921
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.0006668273866923818,
      "loss": 1.1781,
      "step": 922
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.0006663452266152362,
      "loss": 0.991,
      "step": 923
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.0006658630665380907,
      "loss": 0.7773,
      "step": 924
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.0006653809064609451,
      "loss": 0.9571,
      "step": 925
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.0006648987463837994,
      "loss": 0.9957,
      "step": 926
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.0006644165863066538,
      "loss": 0.9441,
      "step": 927
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.0006639344262295082,
      "loss": 0.9636,
      "step": 928
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.0006634522661523627,
      "loss": 0.8467,
      "step": 929
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.000662970106075217,
      "loss": 1.0412,
      "step": 930
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.0006624879459980713,
      "loss": 1.033,
      "step": 931
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.0006620057859209258,
      "loss": 0.921,
      "step": 932
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.0006615236258437801,
      "loss": 0.9234,
      "step": 933
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.0006610414657666345,
      "loss": 0.8934,
      "step": 934
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.0006605593056894889,
      "loss": 0.8217,
      "step": 935
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.0006600771456123434,
      "loss": 1.2248,
      "step": 936
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.0006595949855351977,
      "loss": 1.0307,
      "step": 937
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.0006591128254580521,
      "loss": 0.9694,
      "step": 938
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.0006586306653809064,
      "loss": 1.0218,
      "step": 939
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.000658148505303761,
      "loss": 1.0096,
      "step": 940
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.0006576663452266153,
      "loss": 1.0222,
      "step": 941
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.0006571841851494697,
      "loss": 0.9756,
      "step": 942
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.000656702025072324,
      "loss": 0.9609,
      "step": 943
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.0006562198649951783,
      "loss": 1.0081,
      "step": 944
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.0006557377049180328,
      "loss": 1.018,
      "step": 945
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.0006552555448408872,
      "loss": 0.8037,
      "step": 946
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.0006547733847637416,
      "loss": 0.9165,
      "step": 947
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.0006542912246865959,
      "loss": 0.9158,
      "step": 948
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.0006538090646094504,
      "loss": 0.9365,
      "step": 949
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.0006533269045323047,
      "loss": 0.884,
      "step": 950
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.0006528447444551592,
      "loss": 0.9421,
      "step": 951
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.0006523625843780135,
      "loss": 0.872,
      "step": 952
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.000651880424300868,
      "loss": 1.099,
      "step": 953
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.0006513982642237223,
      "loss": 0.9751,
      "step": 954
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.0006509161041465766,
      "loss": 0.9493,
      "step": 955
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.000650433944069431,
      "loss": 0.9719,
      "step": 956
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0006499517839922855,
      "loss": 1.1257,
      "step": 957
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0006494696239151399,
      "loss": 1.0668,
      "step": 958
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0006489874638379942,
      "loss": 0.9383,
      "step": 959
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0006485053037608486,
      "loss": 0.9781,
      "step": 960
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0006480231436837029,
      "loss": 1.0197,
      "step": 961
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.0006475409836065575,
      "loss": 0.9494,
      "step": 962
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.0006470588235294118,
      "loss": 0.8956,
      "step": 963
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.0006465766634522662,
      "loss": 1.0014,
      "step": 964
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.0006460945033751205,
      "loss": 1.0017,
      "step": 965
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.000645612343297975,
      "loss": 1.0175,
      "step": 966
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.0006451301832208293,
      "loss": 0.9785,
      "step": 967
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.0006446480231436837,
      "loss": 0.9561,
      "step": 968
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.0006441658630665381,
      "loss": 1.0022,
      "step": 969
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.0006436837029893925,
      "loss": 0.9966,
      "step": 970
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0006432015429122469,
      "loss": 1.0623,
      "step": 971
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0006427193828351012,
      "loss": 0.8799,
      "step": 972
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0006422372227579557,
      "loss": 1.1197,
      "step": 973
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0006417550626808101,
      "loss": 1.052,
      "step": 974
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0006412729026036645,
      "loss": 0.9673,
      "step": 975
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.0006407907425265188,
      "loss": 0.898,
      "step": 976
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.0006403085824493732,
      "loss": 0.8991,
      "step": 977
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.0006398264223722275,
      "loss": 0.9029,
      "step": 978
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.000639344262295082,
      "loss": 0.9413,
      "step": 979
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.0006388621022179364,
      "loss": 0.9271,
      "step": 980
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.0006383799421407907,
      "loss": 0.8941,
      "step": 981
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.0006378977820636451,
      "loss": 1.0447,
      "step": 982
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.0006374156219864995,
      "loss": 0.9298,
      "step": 983
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.000636933461909354,
      "loss": 0.978,
      "step": 984
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.0006364513018322083,
      "loss": 1.002,
      "step": 985
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.0006359691417550627,
      "loss": 0.9734,
      "step": 986
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.0006354869816779171,
      "loss": 0.921,
      "step": 987
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.0006350048216007715,
      "loss": 1.0704,
      "step": 988
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.0006345226615236258,
      "loss": 0.9897,
      "step": 989
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.0006340405014464803,
      "loss": 0.855,
      "step": 990
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.0006335583413693347,
      "loss": 0.941,
      "step": 991
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.000633076181292189,
      "loss": 1.0273,
      "step": 992
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.0006325940212150434,
      "loss": 0.9007,
      "step": 993
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.0006321118611378977,
      "loss": 0.8228,
      "step": 994
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.0006316297010607523,
      "loss": 0.8861,
      "step": 995
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.0006311475409836066,
      "loss": 0.8315,
      "step": 996
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.000630665380906461,
      "loss": 1.0848,
      "step": 997
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.0006301832208293153,
      "loss": 0.9326,
      "step": 998
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0006297010607521697,
      "loss": 1.0843,
      "step": 999
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0006292189006750241,
      "loss": 1.0083,
      "step": 1000
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0006287367405978786,
      "loss": 1.0103,
      "step": 1001
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0006282545805207329,
      "loss": 0.9691,
      "step": 1002
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.0006277724204435872,
      "loss": 1.1532,
      "step": 1003
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.0006272902603664417,
      "loss": 1.146,
      "step": 1004
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.000626808100289296,
      "loss": 1.1315,
      "step": 1005
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.0006263259402121505,
      "loss": 0.9267,
      "step": 1006
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.0006258437801350048,
      "loss": 0.9223,
      "step": 1007
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.0006253616200578593,
      "loss": 1.0227,
      "step": 1008
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.0006248794599807136,
      "loss": 0.9588,
      "step": 1009
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.000624397299903568,
      "loss": 0.976,
      "step": 1010
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.0006239151398264223,
      "loss": 0.9918,
      "step": 1011
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.0006234329797492769,
      "loss": 1.0981,
      "step": 1012
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.0006229508196721312,
      "loss": 0.869,
      "step": 1013
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.0006224686595949856,
      "loss": 0.8867,
      "step": 1014
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.0006219864995178399,
      "loss": 0.9198,
      "step": 1015
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.0006215043394406942,
      "loss": 1.1387,
      "step": 1016
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.0006210221793635487,
      "loss": 0.9898,
      "step": 1017
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.0006205400192864031,
      "loss": 0.9884,
      "step": 1018
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.0006200578592092575,
      "loss": 0.9798,
      "step": 1019
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.0006195756991321118,
      "loss": 1.0296,
      "step": 1020
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.0006190935390549663,
      "loss": 0.9787,
      "step": 1021
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.0006186113789778206,
      "loss": 1.0218,
      "step": 1022
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.0006181292189006751,
      "loss": 0.8143,
      "step": 1023
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.0006176470588235294,
      "loss": 1.1868,
      "step": 1024
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.0006171648987463839,
      "loss": 0.9519,
      "step": 1025
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.0006166827386692382,
      "loss": 0.9298,
      "step": 1026
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.0006162005785920925,
      "loss": 0.9522,
      "step": 1027
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.0006157184185149469,
      "loss": 0.9177,
      "step": 1028
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.0006152362584378014,
      "loss": 0.8758,
      "step": 1029
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.0006147540983606558,
      "loss": 1.017,
      "step": 1030
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.0006142719382835101,
      "loss": 0.9439,
      "step": 1031
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.0006137897782063645,
      "loss": 0.9404,
      "step": 1032
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.0006133076181292188,
      "loss": 1.015,
      "step": 1033
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.0006128254580520734,
      "loss": 1.0121,
      "step": 1034
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.0006123432979749277,
      "loss": 0.942,
      "step": 1035
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.0006118611378977821,
      "loss": 1.0113,
      "step": 1036
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.0006113789778206364,
      "loss": 0.9455,
      "step": 1037
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.0006108968177434909,
      "loss": 0.9343,
      "step": 1038
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.0006104146576663452,
      "loss": 0.9288,
      "step": 1039
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.0006099324975891996,
      "loss": 0.9611,
      "step": 1040
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.000609450337512054,
      "loss": 0.9175,
      "step": 1041
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.0006089681774349084,
      "loss": 0.9614,
      "step": 1042
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.0006084860173577628,
      "loss": 1.0075,
      "step": 1043
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.0006080038572806171,
      "loss": 0.979,
      "step": 1044
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.0006075216972034716,
      "loss": 1.0383,
      "step": 1045
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.000607039537126326,
      "loss": 0.8931,
      "step": 1046
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.0006065573770491804,
      "loss": 0.9966,
      "step": 1047
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.0006060752169720347,
      "loss": 1.0447,
      "step": 1048
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.0006055930568948891,
      "loss": 0.9926,
      "step": 1049
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.0006051108968177434,
      "loss": 1.017,
      "step": 1050
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.000604628736740598,
      "loss": 0.924,
      "step": 1051
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.0006041465766634523,
      "loss": 0.8852,
      "step": 1052
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.0006036644165863066,
      "loss": 0.8692,
      "step": 1053
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.000603182256509161,
      "loss": 0.8648,
      "step": 1054
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.0006027000964320154,
      "loss": 0.8796,
      "step": 1055
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.0006022179363548699,
      "loss": 0.8911,
      "step": 1056
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.0006017357762777242,
      "loss": 0.9377,
      "step": 1057
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.0006012536162005786,
      "loss": 0.8776,
      "step": 1058
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.000600771456123433,
      "loss": 1.1044,
      "step": 1059
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.0006002892960462874,
      "loss": 0.9599,
      "step": 1060
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.0005998071359691417,
      "loss": 0.9978,
      "step": 1061
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.0005993249758919962,
      "loss": 1.0222,
      "step": 1062
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.0005988428158148506,
      "loss": 1.0989,
      "step": 1063
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.000598360655737705,
      "loss": 0.9811,
      "step": 1064
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.0005978784956605593,
      "loss": 0.9749,
      "step": 1065
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.0005973963355834136,
      "loss": 0.9346,
      "step": 1066
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.0005969141755062682,
      "loss": 1.0524,
      "step": 1067
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.0005964320154291225,
      "loss": 0.975,
      "step": 1068
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.0005959498553519769,
      "loss": 0.9896,
      "step": 1069
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.0005954676952748312,
      "loss": 1.0244,
      "step": 1070
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.0005949855351976856,
      "loss": 1.0807,
      "step": 1071
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.00059450337512054,
      "loss": 1.0357,
      "step": 1072
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.0005940212150433945,
      "loss": 0.9438,
      "step": 1073
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.0005935390549662488,
      "loss": 0.9397,
      "step": 1074
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.0005930568948891031,
      "loss": 1.0491,
      "step": 1075
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.0005925747348119576,
      "loss": 0.9268,
      "step": 1076
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0005920925747348119,
      "loss": 0.9788,
      "step": 1077
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0005916104146576664,
      "loss": 0.9739,
      "step": 1078
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0005911282545805207,
      "loss": 0.9661,
      "step": 1079
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0005906460945033752,
      "loss": 0.9519,
      "step": 1080
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0005901639344262295,
      "loss": 1.0535,
      "step": 1081
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.0005896817743490839,
      "loss": 0.9439,
      "step": 1082
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.0005891996142719382,
      "loss": 0.9797,
      "step": 1083
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.0005887174541947928,
      "loss": 1.0756,
      "step": 1084
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.0005882352941176471,
      "loss": 0.9165,
      "step": 1085
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.0005877531340405015,
      "loss": 1.1244,
      "step": 1086
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.0005872709739633558,
      "loss": 0.9761,
      "step": 1087
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.0005867888138862101,
      "loss": 0.9679,
      "step": 1088
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.0005863066538090647,
      "loss": 1.0121,
      "step": 1089
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.000585824493731919,
      "loss": 0.934,
      "step": 1090
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.0005853423336547734,
      "loss": 1.1939,
      "step": 1091
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.0005848601735776277,
      "loss": 0.9339,
      "step": 1092
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.0005843780135004822,
      "loss": 0.9882,
      "step": 1093
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.0005838958534233365,
      "loss": 1.0752,
      "step": 1094
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.000583413693346191,
      "loss": 0.9411,
      "step": 1095
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0005829315332690453,
      "loss": 1.0066,
      "step": 1096
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0005824493731918998,
      "loss": 0.8654,
      "step": 1097
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0005819672131147541,
      "loss": 0.932,
      "step": 1098
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0005814850530376085,
      "loss": 0.941,
      "step": 1099
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.0005810028929604629,
      "loss": 0.9256,
      "step": 1100
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.0005805207328833174,
      "loss": 1.0432,
      "step": 1101
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.0005800385728061717,
      "loss": 0.9845,
      "step": 1102
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.000579556412729026,
      "loss": 0.9919,
      "step": 1103
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.0005790742526518804,
      "loss": 0.9509,
      "step": 1104
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.0005785920925747347,
      "loss": 0.9121,
      "step": 1105
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.0005781099324975893,
      "loss": 0.8971,
      "step": 1106
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.0005776277724204436,
      "loss": 1.0993,
      "step": 1107
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.000577145612343298,
      "loss": 0.8731,
      "step": 1108
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0005766634522661523,
      "loss": 0.9319,
      "step": 1109
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0005761812921890068,
      "loss": 0.9179,
      "step": 1110
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0005756991321118612,
      "loss": 1.0086,
      "step": 1111
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0005752169720347156,
      "loss": 1.0074,
      "step": 1112
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0005747348119575699,
      "loss": 0.9321,
      "step": 1113
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.0005742526518804243,
      "loss": 0.9614,
      "step": 1114
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.0005737704918032787,
      "loss": 0.9291,
      "step": 1115
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.000573288331726133,
      "loss": 0.9071,
      "step": 1116
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.0005728061716489875,
      "loss": 1.0386,
      "step": 1117
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.0005723240115718419,
      "loss": 1.0354,
      "step": 1118
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.0005718418514946963,
      "loss": 1.0353,
      "step": 1119
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.0005713596914175506,
      "loss": 0.9196,
      "step": 1120
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.000570877531340405,
      "loss": 1.0131,
      "step": 1121
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.0005703953712632595,
      "loss": 0.8767,
      "step": 1122
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.0005699132111861139,
      "loss": 1.056,
      "step": 1123
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.0005694310511089682,
      "loss": 1.1097,
      "step": 1124
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.0005689488910318225,
      "loss": 0.9713,
      "step": 1125
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.0005684667309546769,
      "loss": 1.0573,
      "step": 1126
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.0005679845708775313,
      "loss": 0.9758,
      "step": 1127
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.0005675024108003858,
      "loss": 1.0519,
      "step": 1128
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.0005670202507232401,
      "loss": 0.9395,
      "step": 1129
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.0005665380906460945,
      "loss": 0.9174,
      "step": 1130
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.0005660559305689489,
      "loss": 0.9889,
      "step": 1131
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.0005655737704918033,
      "loss": 0.9806,
      "step": 1132
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.0005650916104146577,
      "loss": 1.041,
      "step": 1133
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.0005646094503375121,
      "loss": 0.8972,
      "step": 1134
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.0005641272902603665,
      "loss": 0.8555,
      "step": 1135
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.0005636451301832209,
      "loss": 0.8591,
      "step": 1136
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.0005631629701060752,
      "loss": 0.9729,
      "step": 1137
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.0005626808100289295,
      "loss": 1.0587,
      "step": 1138
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.0005621986499517841,
      "loss": 1.0039,
      "step": 1139
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.0005617164898746384,
      "loss": 1.0355,
      "step": 1140
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.0005612343297974928,
      "loss": 0.9825,
      "step": 1141
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.0005607521697203471,
      "loss": 1.0898,
      "step": 1142
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.0005602700096432015,
      "loss": 0.9924,
      "step": 1143
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.000559787849566056,
      "loss": 1.0022,
      "step": 1144
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.0005593056894889104,
      "loss": 1.0779,
      "step": 1145
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.0005588235294117647,
      "loss": 0.9344,
      "step": 1146
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.000558341369334619,
      "loss": 1.1594,
      "step": 1147
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.0005578592092574735,
      "loss": 0.9057,
      "step": 1148
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.0005573770491803278,
      "loss": 1.0681,
      "step": 1149
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.0005568948891031823,
      "loss": 1.1264,
      "step": 1150
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.0005564127290260366,
      "loss": 1.1019,
      "step": 1151
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.0005559305689488911,
      "loss": 1.0221,
      "step": 1152
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.0005554484088717454,
      "loss": 0.9301,
      "step": 1153
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.0005549662487945998,
      "loss": 0.9933,
      "step": 1154
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.0005544840887174542,
      "loss": 0.8889,
      "step": 1155
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.0005540019286403087,
      "loss": 1.032,
      "step": 1156
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.000553519768563163,
      "loss": 0.9405,
      "step": 1157
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.0005530376084860174,
      "loss": 0.9468,
      "step": 1158
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.0005525554484088717,
      "loss": 0.9357,
      "step": 1159
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.000552073288331726,
      "loss": 1.0304,
      "step": 1160
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.0005515911282545806,
      "loss": 1.0483,
      "step": 1161
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.000551108968177435,
      "loss": 0.9669,
      "step": 1162
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.0005506268081002893,
      "loss": 1.0284,
      "step": 1163
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.0005501446480231436,
      "loss": 0.9534,
      "step": 1164
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.0005496624879459981,
      "loss": 0.8571,
      "step": 1165
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.0005491803278688525,
      "loss": 0.9924,
      "step": 1166
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.0005486981677917069,
      "loss": 0.8303,
      "step": 1167
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.0005482160077145612,
      "loss": 1.0239,
      "step": 1168
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.0005477338476374157,
      "loss": 0.8395,
      "step": 1169
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.00054725168756027,
      "loss": 1.0095,
      "step": 1170
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.0005467695274831244,
      "loss": 1.014,
      "step": 1171
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.0005462873674059788,
      "loss": 0.9017,
      "step": 1172
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.0005458052073288333,
      "loss": 0.8648,
      "step": 1173
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.0005453230472516876,
      "loss": 0.9567,
      "step": 1174
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.0005448408871745419,
      "loss": 1.1438,
      "step": 1175
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.0005443587270973963,
      "loss": 0.8972,
      "step": 1176
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.0005438765670202508,
      "loss": 0.9985,
      "step": 1177
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.0005433944069431052,
      "loss": 0.9536,
      "step": 1178
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.0005429122468659595,
      "loss": 1.0338,
      "step": 1179
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.0005424300867888139,
      "loss": 0.9814,
      "step": 1180
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.0005419479267116682,
      "loss": 0.9249,
      "step": 1181
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.0005414657666345227,
      "loss": 0.921,
      "step": 1182
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.0005409836065573771,
      "loss": 0.8981,
      "step": 1183
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.0005405014464802315,
      "loss": 0.8922,
      "step": 1184
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.0005400192864030858,
      "loss": 0.9439,
      "step": 1185
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.0005395371263259402,
      "loss": 0.9955,
      "step": 1186
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.0005390549662487946,
      "loss": 0.7601,
      "step": 1187
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.0005385728061716489,
      "loss": 1.0319,
      "step": 1188
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.0005380906460945034,
      "loss": 1.0213,
      "step": 1189
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.0005376084860173578,
      "loss": 0.8637,
      "step": 1190
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.0005371263259402122,
      "loss": 0.9256,
      "step": 1191
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.0005366441658630665,
      "loss": 0.9083,
      "step": 1192
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.0005361620057859209,
      "loss": 1.1035,
      "step": 1193
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.0005356798457087754,
      "loss": 0.9677,
      "step": 1194
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.0005351976856316298,
      "loss": 0.9147,
      "step": 1195
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.0005347155255544841,
      "loss": 1.1104,
      "step": 1196
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.0005342333654773384,
      "loss": 0.968,
      "step": 1197
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.0005337512054001928,
      "loss": 0.9662,
      "step": 1198
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.0005332690453230472,
      "loss": 0.9425,
      "step": 1199
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.0005327868852459017,
      "loss": 0.9391,
      "step": 1200
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.000532304725168756,
      "loss": 0.9528,
      "step": 1201
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.0005318225650916104,
      "loss": 1.0133,
      "step": 1202
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.0005313404050144648,
      "loss": 0.89,
      "step": 1203
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.0005308582449373192,
      "loss": 0.9056,
      "step": 1204
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.0005303760848601736,
      "loss": 0.9938,
      "step": 1205
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.000529893924783028,
      "loss": 0.9624,
      "step": 1206
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.0005294117647058824,
      "loss": 1.0712,
      "step": 1207
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.0005289296046287368,
      "loss": 1.015,
      "step": 1208
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.0005284474445515911,
      "loss": 1.066,
      "step": 1209
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.0005279652844744454,
      "loss": 1.0174,
      "step": 1210
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.0005274831243973,
      "loss": 0.9826,
      "step": 1211
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.0005270009643201543,
      "loss": 0.9915,
      "step": 1212
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.0005265188042430087,
      "loss": 0.989,
      "step": 1213
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.000526036644165863,
      "loss": 0.909,
      "step": 1214
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.0005255544840887174,
      "loss": 0.9281,
      "step": 1215
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.0005250723240115719,
      "loss": 1.0249,
      "step": 1216
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.0005245901639344263,
      "loss": 0.9493,
      "step": 1217
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.0005241080038572806,
      "loss": 1.0201,
      "step": 1218
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.000523625843780135,
      "loss": 1.0639,
      "step": 1219
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.0005231436837029894,
      "loss": 0.9914,
      "step": 1220
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.0005226615236258438,
      "loss": 0.9108,
      "step": 1221
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.0005221793635486982,
      "loss": 1.0337,
      "step": 1222
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.0005216972034715525,
      "loss": 0.9492,
      "step": 1223
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.000521215043394407,
      "loss": 1.04,
      "step": 1224
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.0005207328833172613,
      "loss": 0.9908,
      "step": 1225
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.0005202507232401157,
      "loss": 1.0812,
      "step": 1226
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.0005197685631629701,
      "loss": 0.9687,
      "step": 1227
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.0005192864030858246,
      "loss": 1.0886,
      "step": 1228
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.0005188042430086789,
      "loss": 0.9216,
      "step": 1229
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.0005183220829315333,
      "loss": 0.914,
      "step": 1230
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.0005178399228543876,
      "loss": 0.842,
      "step": 1231
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.000517357762777242,
      "loss": 1.0328,
      "step": 1232
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.0005168756027000965,
      "loss": 0.9336,
      "step": 1233
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.0005163934426229509,
      "loss": 1.0816,
      "step": 1234
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.0005159112825458052,
      "loss": 0.9605,
      "step": 1235
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.0005154291224686595,
      "loss": 0.9555,
      "step": 1236
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.000514946962391514,
      "loss": 1.0028,
      "step": 1237
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.0005144648023143684,
      "loss": 0.9842,
      "step": 1238
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.0005139826422372228,
      "loss": 1.0479,
      "step": 1239
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.0005135004821600771,
      "loss": 0.9183,
      "step": 1240
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.0005130183220829316,
      "loss": 0.9841,
      "step": 1241
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.0005125361620057859,
      "loss": 1.0085,
      "step": 1242
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.0005120540019286403,
      "loss": 1.0675,
      "step": 1243
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.0005115718418514947,
      "loss": 1.0617,
      "step": 1244
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.0005110896817743492,
      "loss": 0.9793,
      "step": 1245
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.0005106075216972035,
      "loss": 0.8724,
      "step": 1246
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.0005101253616200578,
      "loss": 0.8673,
      "step": 1247
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.0005096432015429122,
      "loss": 1.0248,
      "step": 1248
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.0005091610414657667,
      "loss": 0.9833,
      "step": 1249
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.0005086788813886211,
      "loss": 0.9224,
      "step": 1250
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.0005081967213114754,
      "loss": 0.8802,
      "step": 1251
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.0005077145612343298,
      "loss": 0.9117,
      "step": 1252
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.0005072324011571841,
      "loss": 0.9472,
      "step": 1253
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.0005067502410800386,
      "loss": 0.9909,
      "step": 1254
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.000506268081002893,
      "loss": 0.9551,
      "step": 1255
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.0005057859209257474,
      "loss": 0.9631,
      "step": 1256
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.0005053037608486017,
      "loss": 0.9247,
      "step": 1257
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.0005048216007714562,
      "loss": 1.059,
      "step": 1258
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.0005043394406943105,
      "loss": 1.0804,
      "step": 1259
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.000503857280617165,
      "loss": 0.9388,
      "step": 1260
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.0005033751205400193,
      "loss": 1.0401,
      "step": 1261
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.0005028929604628737,
      "loss": 0.9007,
      "step": 1262
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.0005024108003857281,
      "loss": 1.0214,
      "step": 1263
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.0005019286403085824,
      "loss": 0.9779,
      "step": 1264
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.0005014464802314368,
      "loss": 1.0794,
      "step": 1265
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.0005009643201542913,
      "loss": 1.0648,
      "step": 1266
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.0005004821600771457,
      "loss": 1.1383,
      "step": 1267
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.0005,
      "loss": 1.0726,
      "step": 1268
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.0004995178399228544,
      "loss": 1.0285,
      "step": 1269
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.0004990356798457088,
      "loss": 1.0332,
      "step": 1270
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.0004985535197685631,
      "loss": 0.9413,
      "step": 1271
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.0004980713596914175,
      "loss": 0.9613,
      "step": 1272
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.0004975891996142719,
      "loss": 1.0611,
      "step": 1273
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.0004971070395371263,
      "loss": 0.8949,
      "step": 1274
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0004966248794599807,
      "loss": 1.0059,
      "step": 1275
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0004961427193828351,
      "loss": 0.8753,
      "step": 1276
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0004956605593056895,
      "loss": 0.9341,
      "step": 1277
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0004951783992285439,
      "loss": 0.9029,
      "step": 1278
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0004946962391513983,
      "loss": 0.9796,
      "step": 1279
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.0004942140790742527,
      "loss": 0.9852,
      "step": 1280
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.0004937319189971071,
      "loss": 0.852,
      "step": 1281
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.0004932497589199615,
      "loss": 1.0406,
      "step": 1282
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.0004927675988428158,
      "loss": 0.8662,
      "step": 1283
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.0004922854387656702,
      "loss": 0.9278,
      "step": 1284
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.0004918032786885246,
      "loss": 0.9799,
      "step": 1285
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.000491321118611379,
      "loss": 1.0611,
      "step": 1286
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.0004908389585342334,
      "loss": 0.8683,
      "step": 1287
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.0004903567984570877,
      "loss": 0.9552,
      "step": 1288
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.0004898746383799422,
      "loss": 1.0442,
      "step": 1289
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.0004893924783027965,
      "loss": 0.9775,
      "step": 1290
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.0004889103182256509,
      "loss": 0.9383,
      "step": 1291
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.0004884281581485053,
      "loss": 0.92,
      "step": 1292
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.0004879459980713597,
      "loss": 1.0197,
      "step": 1293
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.00048746383799421405,
      "loss": 0.9786,
      "step": 1294
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.0004869816779170685,
      "loss": 0.916,
      "step": 1295
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.00048649951783992284,
      "loss": 0.935,
      "step": 1296
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.0004860173577627773,
      "loss": 0.9921,
      "step": 1297
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.00048553519768563164,
      "loss": 0.9386,
      "step": 1298
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.00048505303760848603,
      "loss": 0.9243,
      "step": 1299
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.00048457087753134043,
      "loss": 0.9193,
      "step": 1300
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.0004840887174541948,
      "loss": 0.8393,
      "step": 1301
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.00048360655737704917,
      "loss": 1.0,
      "step": 1302
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.0004831243972999036,
      "loss": 0.9415,
      "step": 1303
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.00048264223722275796,
      "loss": 1.0144,
      "step": 1304
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.0004821600771456123,
      "loss": 0.9548,
      "step": 1305
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.00048167791706846676,
      "loss": 0.9531,
      "step": 1306
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.0004811957569913211,
      "loss": 0.8712,
      "step": 1307
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.00048071359691417555,
      "loss": 0.8262,
      "step": 1308
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.0004802314368370299,
      "loss": 0.956,
      "step": 1309
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.0004797492767598843,
      "loss": 0.9658,
      "step": 1310
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.0004792671166827387,
      "loss": 1.045,
      "step": 1311
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.0004787849566055931,
      "loss": 1.0566,
      "step": 1312
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.0004783027965284474,
      "loss": 0.8524,
      "step": 1313
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.0004778206364513019,
      "loss": 0.92,
      "step": 1314
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.0004773384763741562,
      "loss": 1.0407,
      "step": 1315
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.0004768563162970106,
      "loss": 0.9697,
      "step": 1316
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.000476374156219865,
      "loss": 0.9849,
      "step": 1317
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.0004758919961427194,
      "loss": 0.903,
      "step": 1318
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.00047540983606557375,
      "loss": 0.8907,
      "step": 1319
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.0004749276759884282,
      "loss": 0.871,
      "step": 1320
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.00047444551591128254,
      "loss": 0.9691,
      "step": 1321
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.000473963355834137,
      "loss": 1.0513,
      "step": 1322
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.00047348119575699133,
      "loss": 0.9342,
      "step": 1323
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.0004729990356798457,
      "loss": 0.9718,
      "step": 1324
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.00047251687560270013,
      "loss": 1.0151,
      "step": 1325
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.00047203471552555447,
      "loss": 1.1053,
      "step": 1326
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.00047155255544840887,
      "loss": 1.0666,
      "step": 1327
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.00047107039537126326,
      "loss": 0.8877,
      "step": 1328
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.00047058823529411766,
      "loss": 0.831,
      "step": 1329
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.000470106075216972,
      "loss": 0.9304,
      "step": 1330
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.00046962391513982645,
      "loss": 0.9637,
      "step": 1331
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.0004691417550626808,
      "loss": 0.948,
      "step": 1332
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.00046865959498553525,
      "loss": 0.9864,
      "step": 1333
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.0004681774349083896,
      "loss": 1.0203,
      "step": 1334
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.000467695274831244,
      "loss": 1.0412,
      "step": 1335
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.0004672131147540984,
      "loss": 1.0442,
      "step": 1336
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.0004667309546769528,
      "loss": 0.9515,
      "step": 1337
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.0004662487945998071,
      "loss": 0.7345,
      "step": 1338
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.00046576663452266157,
      "loss": 1.0671,
      "step": 1339
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.0004652844744455159,
      "loss": 1.0098,
      "step": 1340
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.00046480231436837026,
      "loss": 0.9811,
      "step": 1341
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.0004643201542912247,
      "loss": 1.0138,
      "step": 1342
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.00046383799421407905,
      "loss": 0.8894,
      "step": 1343
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.0004633558341369335,
      "loss": 0.8937,
      "step": 1344
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.00046287367405978784,
      "loss": 0.8322,
      "step": 1345
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.00046239151398264224,
      "loss": 0.9006,
      "step": 1346
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.00046190935390549664,
      "loss": 0.8823,
      "step": 1347
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.00046142719382835103,
      "loss": 0.9301,
      "step": 1348
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.0004609450337512054,
      "loss": 0.9967,
      "step": 1349
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.0004604628736740598,
      "loss": 1.0174,
      "step": 1350
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.00045998071359691417,
      "loss": 0.9052,
      "step": 1351
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.00045949855351976856,
      "loss": 1.0512,
      "step": 1352
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.00045901639344262296,
      "loss": 0.9812,
      "step": 1353
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.00045853423336547736,
      "loss": 1.0195,
      "step": 1354
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.00045805207328833175,
      "loss": 1.0946,
      "step": 1355
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.00045756991321118615,
      "loss": 0.9823,
      "step": 1356
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.0004570877531340405,
      "loss": 1.0726,
      "step": 1357
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.00045660559305689494,
      "loss": 1.0586,
      "step": 1358
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.0004561234329797493,
      "loss": 0.9247,
      "step": 1359
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.00045564127290260363,
      "loss": 0.9225,
      "step": 1360
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.0004551591128254581,
      "loss": 0.9841,
      "step": 1361
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.0004546769527483124,
      "loss": 0.9291,
      "step": 1362
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.0004541947926711668,
      "loss": 0.9129,
      "step": 1363
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.0004537126325940212,
      "loss": 0.9307,
      "step": 1364
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.0004532304725168756,
      "loss": 1.0433,
      "step": 1365
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.00045274831243973,
      "loss": 0.8967,
      "step": 1366
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.0004522661523625844,
      "loss": 0.847,
      "step": 1367
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.00045178399228543875,
      "loss": 0.9056,
      "step": 1368
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.0004513018322082932,
      "loss": 0.8807,
      "step": 1369
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.00045081967213114754,
      "loss": 0.9834,
      "step": 1370
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.00045033751205400194,
      "loss": 0.8766,
      "step": 1371
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.00044985535197685633,
      "loss": 0.9776,
      "step": 1372
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.00044937319189971073,
      "loss": 0.9242,
      "step": 1373
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.00044889103182256507,
      "loss": 1.0173,
      "step": 1374
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.0004484088717454195,
      "loss": 0.9418,
      "step": 1375
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.00044792671166827387,
      "loss": 1.0572,
      "step": 1376
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.0004474445515911283,
      "loss": 1.005,
      "step": 1377
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.00044696239151398266,
      "loss": 0.9228,
      "step": 1378
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.000446480231436837,
      "loss": 0.9003,
      "step": 1379
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.00044599807135969145,
      "loss": 1.0344,
      "step": 1380
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.0004455159112825458,
      "loss": 1.0159,
      "step": 1381
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.0004450337512054002,
      "loss": 1.0308,
      "step": 1382
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.0004445515911282546,
      "loss": 0.7446,
      "step": 1383
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.000444069431051109,
      "loss": 0.8941,
      "step": 1384
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.0004435872709739633,
      "loss": 0.8406,
      "step": 1385
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.0004431051108968178,
      "loss": 0.8742,
      "step": 1386
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.0004426229508196721,
      "loss": 1.0286,
      "step": 1387
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.00044214079074252657,
      "loss": 0.8941,
      "step": 1388
    },
    {
      "epoch": 3.01,
      "learning_rate": 0.0004416586306653809,
      "loss": 0.7878,
      "step": 1389
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.0004411764705882353,
      "loss": 0.9004,
      "step": 1390
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.0004406943105110897,
      "loss": 0.8154,
      "step": 1391
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.0004402121504339441,
      "loss": 1.0199,
      "step": 1392
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.00043972999035679845,
      "loss": 0.7595,
      "step": 1393
    },
    {
      "epoch": 3.02,
      "learning_rate": 0.0004392478302796529,
      "loss": 0.8975,
      "step": 1394
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.00043876567020250724,
      "loss": 1.0922,
      "step": 1395
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.0004382835101253616,
      "loss": 0.9197,
      "step": 1396
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.00043780135004821603,
      "loss": 0.803,
      "step": 1397
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.0004373191899710704,
      "loss": 0.9251,
      "step": 1398
    },
    {
      "epoch": 3.03,
      "learning_rate": 0.00043683702989392477,
      "loss": 0.9796,
      "step": 1399
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.00043635486981677917,
      "loss": 0.8906,
      "step": 1400
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.00043587270973963356,
      "loss": 0.8434,
      "step": 1401
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.00043539054966248796,
      "loss": 0.8724,
      "step": 1402
    },
    {
      "epoch": 3.04,
      "learning_rate": 0.00043490838958534236,
      "loss": 0.9333,
      "step": 1403
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.0004344262295081967,
      "loss": 0.9001,
      "step": 1404
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.00043394406943105115,
      "loss": 0.804,
      "step": 1405
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.0004334619093539055,
      "loss": 0.852,
      "step": 1406
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.0004329797492767599,
      "loss": 0.9238,
      "step": 1407
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.0004324975891996143,
      "loss": 0.8566,
      "step": 1408
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.0004320154291224687,
      "loss": 0.7931,
      "step": 1409
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.000431533269045323,
      "loss": 0.8464,
      "step": 1410
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.0004310511089681775,
      "loss": 0.9268,
      "step": 1411
    },
    {
      "epoch": 3.06,
      "learning_rate": 0.0004305689488910318,
      "loss": 0.9082,
      "step": 1412
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.00043008678881388627,
      "loss": 0.9429,
      "step": 1413
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.0004296046287367406,
      "loss": 0.7604,
      "step": 1414
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.00042912246865959495,
      "loss": 0.9001,
      "step": 1415
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.0004286403085824494,
      "loss": 0.9567,
      "step": 1416
    },
    {
      "epoch": 3.07,
      "learning_rate": 0.00042815814850530375,
      "loss": 0.8227,
      "step": 1417
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.00042767598842815814,
      "loss": 0.9793,
      "step": 1418
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.00042719382835101254,
      "loss": 0.7704,
      "step": 1419
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.00042671166827386694,
      "loss": 0.9272,
      "step": 1420
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.0004262295081967213,
      "loss": 0.8905,
      "step": 1421
    },
    {
      "epoch": 3.08,
      "learning_rate": 0.00042574734811957573,
      "loss": 0.8868,
      "step": 1422
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.00042526518804243007,
      "loss": 0.7985,
      "step": 1423
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.0004247830279652845,
      "loss": 0.8227,
      "step": 1424
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.00042430086788813886,
      "loss": 0.8169,
      "step": 1425
    },
    {
      "epoch": 3.09,
      "learning_rate": 0.00042381870781099326,
      "loss": 0.8142,
      "step": 1426
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.00042333654773384766,
      "loss": 0.8255,
      "step": 1427
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.00042285438765670205,
      "loss": 0.8424,
      "step": 1428
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.0004223722275795564,
      "loss": 0.7379,
      "step": 1429
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.00042189006750241085,
      "loss": 0.9512,
      "step": 1430
    },
    {
      "epoch": 3.1,
      "learning_rate": 0.0004214079074252652,
      "loss": 0.857,
      "step": 1431
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.00042092574734811953,
      "loss": 0.8577,
      "step": 1432
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.000420443587270974,
      "loss": 0.9192,
      "step": 1433
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.0004199614271938283,
      "loss": 0.8037,
      "step": 1434
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.0004194792671166828,
      "loss": 0.8406,
      "step": 1435
    },
    {
      "epoch": 3.11,
      "learning_rate": 0.0004189971070395371,
      "loss": 0.9495,
      "step": 1436
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.0004185149469623915,
      "loss": 0.909,
      "step": 1437
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.0004180327868852459,
      "loss": 0.8924,
      "step": 1438
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.0004175506268081003,
      "loss": 0.9588,
      "step": 1439
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.00041706846673095465,
      "loss": 0.817,
      "step": 1440
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.0004165863066538091,
      "loss": 0.8639,
      "step": 1441
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.00041610414657666344,
      "loss": 0.9895,
      "step": 1442
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.00041562198649951784,
      "loss": 0.7861,
      "step": 1443
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.00041513982642237224,
      "loss": 0.8467,
      "step": 1444
    },
    {
      "epoch": 3.13,
      "learning_rate": 0.00041465766634522663,
      "loss": 0.8104,
      "step": 1445
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.00041417550626808103,
      "loss": 0.9784,
      "step": 1446
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.00041369334619093543,
      "loss": 0.8465,
      "step": 1447
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.00041321118611378977,
      "loss": 0.8921,
      "step": 1448
    },
    {
      "epoch": 3.14,
      "learning_rate": 0.0004127290260366442,
      "loss": 0.8695,
      "step": 1449
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.00041224686595949856,
      "loss": 0.9208,
      "step": 1450
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.0004117647058823529,
      "loss": 0.999,
      "step": 1451
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.00041128254580520736,
      "loss": 0.8207,
      "step": 1452
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.0004108003857280617,
      "loss": 0.6965,
      "step": 1453
    },
    {
      "epoch": 3.15,
      "learning_rate": 0.0004103182256509161,
      "loss": 0.9031,
      "step": 1454
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.0004098360655737705,
      "loss": 0.8032,
      "step": 1455
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.0004093539054966249,
      "loss": 0.9504,
      "step": 1456
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.0004088717454194793,
      "loss": 0.7782,
      "step": 1457
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.0004083895853423337,
      "loss": 0.9538,
      "step": 1458
    },
    {
      "epoch": 3.16,
      "learning_rate": 0.000407907425265188,
      "loss": 0.8354,
      "step": 1459
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.0004074252651880425,
      "loss": 0.8588,
      "step": 1460
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.0004069431051108968,
      "loss": 1.0977,
      "step": 1461
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.0004064609450337512,
      "loss": 0.8327,
      "step": 1462
    },
    {
      "epoch": 3.17,
      "learning_rate": 0.0004059787849566056,
      "loss": 0.8326,
      "step": 1463
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.00040549662487946,
      "loss": 0.7981,
      "step": 1464
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.00040501446480231435,
      "loss": 0.8217,
      "step": 1465
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.0004045323047251688,
      "loss": 0.762,
      "step": 1466
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.00040405014464802314,
      "loss": 0.9322,
      "step": 1467
    },
    {
      "epoch": 3.18,
      "learning_rate": 0.0004035679845708776,
      "loss": 0.8409,
      "step": 1468
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.00040308582449373194,
      "loss": 0.9427,
      "step": 1469
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.0004026036644165863,
      "loss": 0.798,
      "step": 1470
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.00040212150433944073,
      "loss": 0.9165,
      "step": 1471
    },
    {
      "epoch": 3.19,
      "learning_rate": 0.00040163934426229507,
      "loss": 0.9678,
      "step": 1472
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.00040115718418514947,
      "loss": 0.9331,
      "step": 1473
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.00040067502410800386,
      "loss": 0.7589,
      "step": 1474
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.00040019286403085826,
      "loss": 0.8476,
      "step": 1475
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.0003997107039537126,
      "loss": 0.9439,
      "step": 1476
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.00039922854387656705,
      "loss": 1.0175,
      "step": 1477
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.0003987463837994214,
      "loss": 1.0038,
      "step": 1478
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.00039826422372227585,
      "loss": 0.8774,
      "step": 1479
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.0003977820636451302,
      "loss": 0.9041,
      "step": 1480
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.0003972999035679846,
      "loss": 0.8535,
      "step": 1481
    },
    {
      "epoch": 3.21,
      "learning_rate": 0.000396817743490839,
      "loss": 0.8572,
      "step": 1482
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.0003963355834136934,
      "loss": 0.8733,
      "step": 1483
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.0003958534233365477,
      "loss": 0.8872,
      "step": 1484
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.00039537126325940217,
      "loss": 0.8707,
      "step": 1485
    },
    {
      "epoch": 3.22,
      "learning_rate": 0.0003948891031822565,
      "loss": 0.8206,
      "step": 1486
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.00039440694310511086,
      "loss": 0.9875,
      "step": 1487
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.0003939247830279653,
      "loss": 0.9355,
      "step": 1488
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.00039344262295081965,
      "loss": 0.9686,
      "step": 1489
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.00039296046287367405,
      "loss": 0.7057,
      "step": 1490
    },
    {
      "epoch": 3.23,
      "learning_rate": 0.00039247830279652844,
      "loss": 0.954,
      "step": 1491
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.00039199614271938284,
      "loss": 0.8956,
      "step": 1492
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.00039151398264223724,
      "loss": 0.8629,
      "step": 1493
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.00039103182256509163,
      "loss": 0.8421,
      "step": 1494
    },
    {
      "epoch": 3.24,
      "learning_rate": 0.000390549662487946,
      "loss": 0.853,
      "step": 1495
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.0003900675024108004,
      "loss": 0.8055,
      "step": 1496
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.00038958534233365477,
      "loss": 1.0656,
      "step": 1497
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.00038910318225650917,
      "loss": 0.8249,
      "step": 1498
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.00038862102217936356,
      "loss": 0.8769,
      "step": 1499
    },
    {
      "epoch": 3.25,
      "learning_rate": 0.00038813886210221796,
      "loss": 0.8971,
      "step": 1500
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.0003876567020250723,
      "loss": 0.882,
      "step": 1501
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.00038717454194792675,
      "loss": 0.9527,
      "step": 1502
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.0003866923818707811,
      "loss": 0.9962,
      "step": 1503
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.00038621022179363554,
      "loss": 0.8898,
      "step": 1504
    },
    {
      "epoch": 3.26,
      "learning_rate": 0.0003857280617164899,
      "loss": 0.8662,
      "step": 1505
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.00038524590163934423,
      "loss": 0.8712,
      "step": 1506
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.0003847637415621987,
      "loss": 0.8045,
      "step": 1507
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.000384281581485053,
      "loss": 0.8792,
      "step": 1508
    },
    {
      "epoch": 3.27,
      "learning_rate": 0.0003837994214079074,
      "loss": 0.9626,
      "step": 1509
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.0003833172613307618,
      "loss": 0.7899,
      "step": 1510
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.0003828351012536162,
      "loss": 0.7877,
      "step": 1511
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.00038235294117647055,
      "loss": 0.8975,
      "step": 1512
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.000381870781099325,
      "loss": 0.8082,
      "step": 1513
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.00038138862102217935,
      "loss": 0.9951,
      "step": 1514
    },
    {
      "epoch": 3.29,
      "learning_rate": 0.0003809064609450338,
      "loss": 0.7547,
      "step": 1515
    },
    {
      "epoch": 3.29,
      "learning_rate": 0.00038042430086788814,
      "loss": 0.9331,
      "step": 1516
    },
    {
      "epoch": 3.29,
      "learning_rate": 0.00037994214079074254,
      "loss": 0.7631,
      "step": 1517
    },
    {
      "epoch": 3.29,
      "learning_rate": 0.00037945998071359693,
      "loss": 0.8667,
      "step": 1518
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.00037897782063645133,
      "loss": 0.8054,
      "step": 1519
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.0003784956605593057,
      "loss": 0.8748,
      "step": 1520
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.0003780135004821601,
      "loss": 0.8267,
      "step": 1521
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.00037753134040501447,
      "loss": 0.8467,
      "step": 1522
    },
    {
      "epoch": 3.3,
      "learning_rate": 0.0003770491803278688,
      "loss": 0.8764,
      "step": 1523
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.00037656702025072326,
      "loss": 1.0271,
      "step": 1524
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.0003760848601735776,
      "loss": 0.8188,
      "step": 1525
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.00037560270009643205,
      "loss": 0.8624,
      "step": 1526
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.0003751205400192864,
      "loss": 0.8116,
      "step": 1527
    },
    {
      "epoch": 3.31,
      "learning_rate": 0.0003746383799421408,
      "loss": 0.9458,
      "step": 1528
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.0003741562198649952,
      "loss": 0.8814,
      "step": 1529
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.0003736740597878496,
      "loss": 0.8803,
      "step": 1530
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.00037319189971070393,
      "loss": 0.827,
      "step": 1531
    },
    {
      "epoch": 3.32,
      "learning_rate": 0.0003727097396335584,
      "loss": 0.9284,
      "step": 1532
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.0003722275795564127,
      "loss": 0.9163,
      "step": 1533
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.0003717454194792671,
      "loss": 0.9394,
      "step": 1534
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.0003712632594021215,
      "loss": 0.8656,
      "step": 1535
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.0003707810993249759,
      "loss": 0.985,
      "step": 1536
    },
    {
      "epoch": 3.33,
      "learning_rate": 0.0003702989392478303,
      "loss": 0.8725,
      "step": 1537
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.0003698167791706847,
      "loss": 0.9634,
      "step": 1538
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.00036933461909353905,
      "loss": 0.8642,
      "step": 1539
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.0003688524590163935,
      "loss": 0.8638,
      "step": 1540
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.00036837029893924784,
      "loss": 0.7885,
      "step": 1541
    },
    {
      "epoch": 3.34,
      "learning_rate": 0.0003678881388621022,
      "loss": 0.9266,
      "step": 1542
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.00036740597878495663,
      "loss": 0.8487,
      "step": 1543
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.000366923818707811,
      "loss": 0.7787,
      "step": 1544
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.00036644165863066537,
      "loss": 1.0012,
      "step": 1545
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.00036595949855351977,
      "loss": 0.8679,
      "step": 1546
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.00036547733847637416,
      "loss": 0.8906,
      "step": 1547
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.00036499517839922856,
      "loss": 0.964,
      "step": 1548
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.00036451301832208296,
      "loss": 0.8165,
      "step": 1549
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.0003640308582449373,
      "loss": 0.9276,
      "step": 1550
    },
    {
      "epoch": 3.36,
      "learning_rate": 0.00036354869816779175,
      "loss": 0.9019,
      "step": 1551
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.0003630665380906461,
      "loss": 0.9128,
      "step": 1552
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.0003625843780135005,
      "loss": 0.8196,
      "step": 1553
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.0003621022179363549,
      "loss": 0.9557,
      "step": 1554
    },
    {
      "epoch": 3.37,
      "learning_rate": 0.0003616200578592093,
      "loss": 0.759,
      "step": 1555
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.0003611378977820636,
      "loss": 0.9558,
      "step": 1556
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.0003606557377049181,
      "loss": 0.8158,
      "step": 1557
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.0003601735776277724,
      "loss": 0.8371,
      "step": 1558
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.00035969141755062687,
      "loss": 0.7909,
      "step": 1559
    },
    {
      "epoch": 3.38,
      "learning_rate": 0.0003592092574734812,
      "loss": 0.8651,
      "step": 1560
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.00035872709739633555,
      "loss": 0.905,
      "step": 1561
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.00035824493731919,
      "loss": 0.9411,
      "step": 1562
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.00035776277724204435,
      "loss": 0.9567,
      "step": 1563
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.00035728061716489874,
      "loss": 0.8487,
      "step": 1564
    },
    {
      "epoch": 3.39,
      "learning_rate": 0.00035679845708775314,
      "loss": 0.799,
      "step": 1565
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.00035631629701060754,
      "loss": 0.893,
      "step": 1566
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.0003558341369334619,
      "loss": 0.9606,
      "step": 1567
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.00035535197685631633,
      "loss": 0.936,
      "step": 1568
    },
    {
      "epoch": 3.4,
      "learning_rate": 0.00035486981677917067,
      "loss": 0.9038,
      "step": 1569
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.0003543876567020251,
      "loss": 0.9096,
      "step": 1570
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.00035390549662487947,
      "loss": 0.821,
      "step": 1571
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.00035342333654773386,
      "loss": 0.8881,
      "step": 1572
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.00035294117647058826,
      "loss": 0.8721,
      "step": 1573
    },
    {
      "epoch": 3.41,
      "learning_rate": 0.00035245901639344266,
      "loss": 0.9323,
      "step": 1574
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.000351976856316297,
      "loss": 0.8595,
      "step": 1575
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.00035149469623915145,
      "loss": 0.9022,
      "step": 1576
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.0003510125361620058,
      "loss": 0.8254,
      "step": 1577
    },
    {
      "epoch": 3.42,
      "learning_rate": 0.00035053037608486013,
      "loss": 0.8754,
      "step": 1578
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.0003500482160077146,
      "loss": 0.9157,
      "step": 1579
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.0003495660559305689,
      "loss": 1.099,
      "step": 1580
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.0003490838958534233,
      "loss": 0.9303,
      "step": 1581
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.0003486017357762777,
      "loss": 0.8515,
      "step": 1582
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.0003481195756991321,
      "loss": 0.9447,
      "step": 1583
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.0003476374156219865,
      "loss": 0.8563,
      "step": 1584
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.0003471552555448409,
      "loss": 0.8088,
      "step": 1585
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.00034667309546769525,
      "loss": 0.9796,
      "step": 1586
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.0003461909353905497,
      "loss": 0.9525,
      "step": 1587
    },
    {
      "epoch": 3.44,
      "learning_rate": 0.00034570877531340404,
      "loss": 0.8035,
      "step": 1588
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.00034522661523625844,
      "loss": 0.8474,
      "step": 1589
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.00034474445515911284,
      "loss": 0.8824,
      "step": 1590
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.00034426229508196723,
      "loss": 0.9079,
      "step": 1591
    },
    {
      "epoch": 3.45,
      "learning_rate": 0.0003437801350048216,
      "loss": 0.8771,
      "step": 1592
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.00034329797492767603,
      "loss": 0.9113,
      "step": 1593
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.00034281581485053037,
      "loss": 0.839,
      "step": 1594
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.0003423336547733848,
      "loss": 0.801,
      "step": 1595
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.00034185149469623916,
      "loss": 0.8135,
      "step": 1596
    },
    {
      "epoch": 3.46,
      "learning_rate": 0.0003413693346190935,
      "loss": 0.8582,
      "step": 1597
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.00034088717454194796,
      "loss": 0.8085,
      "step": 1598
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.0003404050144648023,
      "loss": 0.8781,
      "step": 1599
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.0003399228543876567,
      "loss": 0.792,
      "step": 1600
    },
    {
      "epoch": 3.47,
      "learning_rate": 0.0003394406943105111,
      "loss": 0.9261,
      "step": 1601
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.0003389585342333655,
      "loss": 0.8855,
      "step": 1602
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.00033847637415621983,
      "loss": 0.7777,
      "step": 1603
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.0003379942140790743,
      "loss": 0.8552,
      "step": 1604
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.0003375120540019286,
      "loss": 0.8557,
      "step": 1605
    },
    {
      "epoch": 3.48,
      "learning_rate": 0.0003370298939247831,
      "loss": 0.8797,
      "step": 1606
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.0003365477338476374,
      "loss": 0.9462,
      "step": 1607
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.0003360655737704918,
      "loss": 0.8334,
      "step": 1608
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.0003355834136933462,
      "loss": 0.9565,
      "step": 1609
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.0003351012536162006,
      "loss": 0.8447,
      "step": 1610
    },
    {
      "epoch": 3.49,
      "learning_rate": 0.00033461909353905495,
      "loss": 0.9214,
      "step": 1611
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.0003341369334619094,
      "loss": 0.9246,
      "step": 1612
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.00033365477338476374,
      "loss": 0.8957,
      "step": 1613
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.0003331726133076181,
      "loss": 0.78,
      "step": 1614
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.00033269045323047254,
      "loss": 0.8351,
      "step": 1615
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.0003322082931533269,
      "loss": 0.8753,
      "step": 1616
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.00033172613307618133,
      "loss": 0.8437,
      "step": 1617
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.00033124397299903567,
      "loss": 0.8781,
      "step": 1618
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.00033076181292189007,
      "loss": 0.8671,
      "step": 1619
    },
    {
      "epoch": 3.51,
      "learning_rate": 0.00033027965284474446,
      "loss": 0.7735,
      "step": 1620
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.00032979749276759886,
      "loss": 0.9061,
      "step": 1621
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.0003293153326904532,
      "loss": 0.9296,
      "step": 1622
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.00032883317261330765,
      "loss": 1.0017,
      "step": 1623
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.000328351012536162,
      "loss": 0.8505,
      "step": 1624
    },
    {
      "epoch": 3.52,
      "learning_rate": 0.0003278688524590164,
      "loss": 0.9796,
      "step": 1625
    },
    {
      "epoch": 3.53,
      "learning_rate": 0.0003273866923818708,
      "loss": 0.901,
      "step": 1626
    },
    {
      "epoch": 3.53,
      "learning_rate": 0.0003269045323047252,
      "loss": 0.8953,
      "step": 1627
    },
    {
      "epoch": 3.53,
      "learning_rate": 0.0003264223722275796,
      "loss": 0.9097,
      "step": 1628
    },
    {
      "epoch": 3.53,
      "learning_rate": 0.000325940212150434,
      "loss": 0.8996,
      "step": 1629
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.0003254580520732883,
      "loss": 1.05,
      "step": 1630
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.00032497589199614277,
      "loss": 0.8152,
      "step": 1631
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.0003244937319189971,
      "loss": 0.9301,
      "step": 1632
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.00032401157184185146,
      "loss": 0.8695,
      "step": 1633
    },
    {
      "epoch": 3.54,
      "learning_rate": 0.0003235294117647059,
      "loss": 0.9344,
      "step": 1634
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.00032304725168756025,
      "loss": 0.9058,
      "step": 1635
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.00032256509161041465,
      "loss": 0.8563,
      "step": 1636
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.00032208293153326904,
      "loss": 0.7943,
      "step": 1637
    },
    {
      "epoch": 3.55,
      "learning_rate": 0.00032160077145612344,
      "loss": 0.8217,
      "step": 1638
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.00032111861137897784,
      "loss": 0.8531,
      "step": 1639
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.00032063645130183223,
      "loss": 0.8398,
      "step": 1640
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.0003201542912246866,
      "loss": 0.8811,
      "step": 1641
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.000319672131147541,
      "loss": 1.0014,
      "step": 1642
    },
    {
      "epoch": 3.56,
      "learning_rate": 0.00031918997107039537,
      "loss": 0.8297,
      "step": 1643
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.00031870781099324977,
      "loss": 0.84,
      "step": 1644
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.00031822565091610416,
      "loss": 0.9114,
      "step": 1645
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.00031774349083895856,
      "loss": 0.989,
      "step": 1646
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.0003172613307618129,
      "loss": 0.99,
      "step": 1647
    },
    {
      "epoch": 3.57,
      "learning_rate": 0.00031677917068466735,
      "loss": 0.9884,
      "step": 1648
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.0003162970106075217,
      "loss": 0.888,
      "step": 1649
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.00031581485053037615,
      "loss": 0.943,
      "step": 1650
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.0003153326904532305,
      "loss": 0.8453,
      "step": 1651
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.00031485053037608483,
      "loss": 0.9394,
      "step": 1652
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.0003143683702989393,
      "loss": 0.8546,
      "step": 1653
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.0003138862102217936,
      "loss": 0.8305,
      "step": 1654
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.000313404050144648,
      "loss": 0.8069,
      "step": 1655
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.0003129218900675024,
      "loss": 0.9603,
      "step": 1656
    },
    {
      "epoch": 3.59,
      "learning_rate": 0.0003124397299903568,
      "loss": 0.8952,
      "step": 1657
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.00031195756991321116,
      "loss": 0.8885,
      "step": 1658
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.0003114754098360656,
      "loss": 0.9074,
      "step": 1659
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.00031099324975891995,
      "loss": 0.8482,
      "step": 1660
    },
    {
      "epoch": 3.6,
      "learning_rate": 0.00031051108968177434,
      "loss": 0.8397,
      "step": 1661
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.00031002892960462874,
      "loss": 0.8354,
      "step": 1662
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.00030954676952748314,
      "loss": 0.9602,
      "step": 1663
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.00030906460945033753,
      "loss": 0.9546,
      "step": 1664
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.00030858244937319193,
      "loss": 0.8084,
      "step": 1665
    },
    {
      "epoch": 3.61,
      "learning_rate": 0.0003081002892960463,
      "loss": 0.8615,
      "step": 1666
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.0003076181292189007,
      "loss": 0.8941,
      "step": 1667
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.00030713596914175507,
      "loss": 0.9585,
      "step": 1668
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.0003066538090646094,
      "loss": 0.9009,
      "step": 1669
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.00030617164898746386,
      "loss": 0.8634,
      "step": 1670
    },
    {
      "epoch": 3.62,
      "learning_rate": 0.0003056894889103182,
      "loss": 0.9548,
      "step": 1671
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.0003052073288331726,
      "loss": 0.7621,
      "step": 1672
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.000304725168756027,
      "loss": 0.8495,
      "step": 1673
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.0003042430086788814,
      "loss": 0.8184,
      "step": 1674
    },
    {
      "epoch": 3.63,
      "learning_rate": 0.0003037608486017358,
      "loss": 0.874,
      "step": 1675
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.0003032786885245902,
      "loss": 1.017,
      "step": 1676
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.00030279652844744453,
      "loss": 0.8124,
      "step": 1677
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.000302314368370299,
      "loss": 0.7885,
      "step": 1678
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.0003018322082931533,
      "loss": 0.8463,
      "step": 1679
    },
    {
      "epoch": 3.64,
      "learning_rate": 0.0003013500482160077,
      "loss": 0.7851,
      "step": 1680
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.0003008678881388621,
      "loss": 0.8584,
      "step": 1681
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.0003003857280617165,
      "loss": 0.8535,
      "step": 1682
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.00029990356798457085,
      "loss": 0.8906,
      "step": 1683
    },
    {
      "epoch": 3.65,
      "learning_rate": 0.0002994214079074253,
      "loss": 0.958,
      "step": 1684
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.00029893924783027965,
      "loss": 0.7862,
      "step": 1685
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.0002984570877531341,
      "loss": 0.9282,
      "step": 1686
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.00029797492767598844,
      "loss": 0.8762,
      "step": 1687
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.0002974927675988428,
      "loss": 0.817,
      "step": 1688
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.00029701060752169723,
      "loss": 0.9283,
      "step": 1689
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.0002965284474445516,
      "loss": 0.9602,
      "step": 1690
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.00029604628736740597,
      "loss": 0.8077,
      "step": 1691
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.00029556412729026037,
      "loss": 0.9664,
      "step": 1692
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.00029508196721311476,
      "loss": 1.0203,
      "step": 1693
    },
    {
      "epoch": 3.67,
      "learning_rate": 0.0002945998071359691,
      "loss": 0.8657,
      "step": 1694
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.00029411764705882356,
      "loss": 0.9004,
      "step": 1695
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.0002936354869816779,
      "loss": 0.8223,
      "step": 1696
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.00029315332690453235,
      "loss": 0.8504,
      "step": 1697
    },
    {
      "epoch": 3.68,
      "learning_rate": 0.0002926711668273867,
      "loss": 0.8248,
      "step": 1698
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.0002921890067502411,
      "loss": 0.945,
      "step": 1699
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.0002917068466730955,
      "loss": 0.8245,
      "step": 1700
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.0002912246865959499,
      "loss": 0.8666,
      "step": 1701
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.0002907425265188042,
      "loss": 0.9223,
      "step": 1702
    },
    {
      "epoch": 3.69,
      "learning_rate": 0.0002902603664416587,
      "loss": 0.8321,
      "step": 1703
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.000289778206364513,
      "loss": 1.0283,
      "step": 1704
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.00028929604628736736,
      "loss": 0.9089,
      "step": 1705
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.0002888138862102218,
      "loss": 0.8113,
      "step": 1706
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.00028833172613307615,
      "loss": 0.8199,
      "step": 1707
    },
    {
      "epoch": 3.7,
      "learning_rate": 0.0002878495660559306,
      "loss": 0.8798,
      "step": 1708
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.00028736740597878495,
      "loss": 0.7261,
      "step": 1709
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.00028688524590163934,
      "loss": 0.9113,
      "step": 1710
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.00028640308582449374,
      "loss": 0.8186,
      "step": 1711
    },
    {
      "epoch": 3.71,
      "learning_rate": 0.00028592092574734814,
      "loss": 0.8041,
      "step": 1712
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.0002854387656702025,
      "loss": 1.0099,
      "step": 1713
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.00028495660559305693,
      "loss": 0.8724,
      "step": 1714
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.00028447444551591127,
      "loss": 0.8698,
      "step": 1715
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.00028399228543876567,
      "loss": 0.8834,
      "step": 1716
    },
    {
      "epoch": 3.72,
      "learning_rate": 0.00028351012536162007,
      "loss": 0.9318,
      "step": 1717
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.00028302796528447446,
      "loss": 0.9021,
      "step": 1718
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.00028254580520732886,
      "loss": 0.8417,
      "step": 1719
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.00028206364513018326,
      "loss": 0.8811,
      "step": 1720
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.0002815814850530376,
      "loss": 0.8093,
      "step": 1721
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.00028109932497589205,
      "loss": 0.7373,
      "step": 1722
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.0002806171648987464,
      "loss": 0.874,
      "step": 1723
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.00028013500482160073,
      "loss": 0.8178,
      "step": 1724
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.0002796528447444552,
      "loss": 0.8906,
      "step": 1725
    },
    {
      "epoch": 3.74,
      "learning_rate": 0.0002791706846673095,
      "loss": 0.8754,
      "step": 1726
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.0002786885245901639,
      "loss": 1.0046,
      "step": 1727
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.0002782063645130183,
      "loss": 0.9137,
      "step": 1728
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.0002777242044358727,
      "loss": 0.8651,
      "step": 1729
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.0002772420443587271,
      "loss": 0.8498,
      "step": 1730
    },
    {
      "epoch": 3.75,
      "learning_rate": 0.0002767598842815815,
      "loss": 0.9579,
      "step": 1731
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.00027627772420443585,
      "loss": 1.0091,
      "step": 1732
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.0002757955641272903,
      "loss": 0.8283,
      "step": 1733
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.00027531340405014465,
      "loss": 0.8397,
      "step": 1734
    },
    {
      "epoch": 3.76,
      "learning_rate": 0.00027483124397299904,
      "loss": 0.9184,
      "step": 1735
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.00027434908389585344,
      "loss": 0.9073,
      "step": 1736
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.00027386692381870783,
      "loss": 0.7508,
      "step": 1737
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.0002733847637415622,
      "loss": 0.8387,
      "step": 1738
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.00027290260366441663,
      "loss": 0.9038,
      "step": 1739
    },
    {
      "epoch": 3.77,
      "learning_rate": 0.00027242044358727097,
      "loss": 0.8608,
      "step": 1740
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.0002719382835101254,
      "loss": 0.9277,
      "step": 1741
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.00027145612343297976,
      "loss": 0.8506,
      "step": 1742
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.0002709739633558341,
      "loss": 0.8687,
      "step": 1743
    },
    {
      "epoch": 3.78,
      "learning_rate": 0.00027049180327868856,
      "loss": 0.9395,
      "step": 1744
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.0002700096432015429,
      "loss": 1.0388,
      "step": 1745
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.0002695274831243973,
      "loss": 0.8663,
      "step": 1746
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.0002690453230472517,
      "loss": 0.9129,
      "step": 1747
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.0002685631629701061,
      "loss": 0.9253,
      "step": 1748
    },
    {
      "epoch": 3.79,
      "learning_rate": 0.00026808100289296043,
      "loss": 0.8605,
      "step": 1749
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.0002675988428158149,
      "loss": 0.8009,
      "step": 1750
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.0002671166827386692,
      "loss": 0.9163,
      "step": 1751
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.0002666345226615236,
      "loss": 0.8132,
      "step": 1752
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.000266152362584378,
      "loss": 0.8655,
      "step": 1753
    },
    {
      "epoch": 3.8,
      "learning_rate": 0.0002656702025072324,
      "loss": 0.9644,
      "step": 1754
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.0002651880424300868,
      "loss": 0.779,
      "step": 1755
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.0002647058823529412,
      "loss": 0.9774,
      "step": 1756
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.00026422372227579555,
      "loss": 0.9619,
      "step": 1757
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.00026374156219865,
      "loss": 0.8917,
      "step": 1758
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.00026325940212150434,
      "loss": 0.9773,
      "step": 1759
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.0002627772420443587,
      "loss": 0.9799,
      "step": 1760
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.00026229508196721314,
      "loss": 0.9101,
      "step": 1761
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.0002618129218900675,
      "loss": 0.8683,
      "step": 1762
    },
    {
      "epoch": 3.82,
      "learning_rate": 0.0002613307618129219,
      "loss": 0.9535,
      "step": 1763
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.00026084860173577627,
      "loss": 1.0446,
      "step": 1764
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.00026036644165863067,
      "loss": 0.7432,
      "step": 1765
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.00025988428158148506,
      "loss": 1.0318,
      "step": 1766
    },
    {
      "epoch": 3.83,
      "learning_rate": 0.00025940212150433946,
      "loss": 0.8585,
      "step": 1767
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.0002589199614271938,
      "loss": 0.8443,
      "step": 1768
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.00025843780135004825,
      "loss": 0.8974,
      "step": 1769
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.0002579556412729026,
      "loss": 0.8171,
      "step": 1770
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.000257473481195757,
      "loss": 0.893,
      "step": 1771
    },
    {
      "epoch": 3.84,
      "learning_rate": 0.0002569913211186114,
      "loss": 0.8415,
      "step": 1772
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.0002565091610414658,
      "loss": 0.88,
      "step": 1773
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.00025602700096432013,
      "loss": 0.8536,
      "step": 1774
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.0002555448408871746,
      "loss": 0.9441,
      "step": 1775
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.0002550626808100289,
      "loss": 0.9543,
      "step": 1776
    },
    {
      "epoch": 3.85,
      "learning_rate": 0.0002545805207328834,
      "loss": 0.8418,
      "step": 1777
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.0002540983606557377,
      "loss": 0.8708,
      "step": 1778
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.00025361620057859206,
      "loss": 0.9238,
      "step": 1779
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.0002531340405014465,
      "loss": 0.8808,
      "step": 1780
    },
    {
      "epoch": 3.86,
      "learning_rate": 0.00025265188042430085,
      "loss": 0.8493,
      "step": 1781
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.00025216972034715525,
      "loss": 0.891,
      "step": 1782
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.00025168756027000964,
      "loss": 0.7865,
      "step": 1783
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.00025120540019286404,
      "loss": 0.8772,
      "step": 1784
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.0002507232401157184,
      "loss": 0.8593,
      "step": 1785
    },
    {
      "epoch": 3.87,
      "learning_rate": 0.00025024108003857283,
      "loss": 0.8653,
      "step": 1786
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.0002497589199614272,
      "loss": 0.9766,
      "step": 1787
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.0002492767598842816,
      "loss": 0.8837,
      "step": 1788
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.00024879459980713597,
      "loss": 0.7685,
      "step": 1789
    },
    {
      "epoch": 3.88,
      "learning_rate": 0.00024831243972999037,
      "loss": 0.8516,
      "step": 1790
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.00024783027965284476,
      "loss": 0.8294,
      "step": 1791
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.00024734811957569916,
      "loss": 0.8832,
      "step": 1792
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.00024686595949855356,
      "loss": 0.9028,
      "step": 1793
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.0002463837994214079,
      "loss": 0.853,
      "step": 1794
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.0002459016393442623,
      "loss": 0.8566,
      "step": 1795
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.0002454194792671167,
      "loss": 0.8238,
      "step": 1796
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.0002449373191899711,
      "loss": 0.8405,
      "step": 1797
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.00024445515911282543,
      "loss": 0.9499,
      "step": 1798
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.00024397299903567985,
      "loss": 0.9677,
      "step": 1799
    },
    {
      "epoch": 3.9,
      "learning_rate": 0.00024349083895853425,
      "loss": 0.7506,
      "step": 1800
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.00024300867888138865,
      "loss": 0.8977,
      "step": 1801
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.00024252651880424302,
      "loss": 0.9077,
      "step": 1802
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.0002420443587270974,
      "loss": 0.9151,
      "step": 1803
    },
    {
      "epoch": 3.91,
      "learning_rate": 0.0002415621986499518,
      "loss": 0.8948,
      "step": 1804
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.00024108003857280615,
      "loss": 0.86,
      "step": 1805
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.00024059787849566055,
      "loss": 0.9099,
      "step": 1806
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.00024011571841851495,
      "loss": 0.9638,
      "step": 1807
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.00023963355834136934,
      "loss": 0.8814,
      "step": 1808
    },
    {
      "epoch": 3.92,
      "learning_rate": 0.0002391513982642237,
      "loss": 0.8907,
      "step": 1809
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.0002386692381870781,
      "loss": 0.8267,
      "step": 1810
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.0002381870781099325,
      "loss": 0.9937,
      "step": 1811
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.00023770491803278687,
      "loss": 0.8856,
      "step": 1812
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.00023722275795564127,
      "loss": 0.8775,
      "step": 1813
    },
    {
      "epoch": 3.93,
      "learning_rate": 0.00023674059787849567,
      "loss": 0.8713,
      "step": 1814
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.00023625843780135006,
      "loss": 0.9249,
      "step": 1815
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.00023577627772420443,
      "loss": 0.807,
      "step": 1816
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.00023529411764705883,
      "loss": 0.856,
      "step": 1817
    },
    {
      "epoch": 3.94,
      "learning_rate": 0.00023481195756991323,
      "loss": 0.8709,
      "step": 1818
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.00023432979749276762,
      "loss": 0.747,
      "step": 1819
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.000233847637415622,
      "loss": 0.89,
      "step": 1820
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.0002333654773384764,
      "loss": 0.8795,
      "step": 1821
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.00023288331726133079,
      "loss": 1.0192,
      "step": 1822
    },
    {
      "epoch": 3.95,
      "learning_rate": 0.00023240115718418513,
      "loss": 0.8838,
      "step": 1823
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.00023191899710703952,
      "loss": 0.9025,
      "step": 1824
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.00023143683702989392,
      "loss": 0.8403,
      "step": 1825
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.00023095467695274832,
      "loss": 0.8617,
      "step": 1826
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.0002304725168756027,
      "loss": 0.9032,
      "step": 1827
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.00022999035679845708,
      "loss": 0.8768,
      "step": 1828
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.00022950819672131148,
      "loss": 0.9736,
      "step": 1829
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.00022902603664416588,
      "loss": 0.9179,
      "step": 1830
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.00022854387656702025,
      "loss": 0.8524,
      "step": 1831
    },
    {
      "epoch": 3.97,
      "learning_rate": 0.00022806171648987464,
      "loss": 0.8663,
      "step": 1832
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.00022757955641272904,
      "loss": 0.9152,
      "step": 1833
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.0002270973963355834,
      "loss": 0.8545,
      "step": 1834
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.0002266152362584378,
      "loss": 0.9174,
      "step": 1835
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.0002261330761812922,
      "loss": 0.9828,
      "step": 1836
    },
    {
      "epoch": 3.98,
      "learning_rate": 0.0002256509161041466,
      "loss": 0.8349,
      "step": 1837
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.00022516875602700097,
      "loss": 0.918,
      "step": 1838
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.00022468659594985537,
      "loss": 0.9067,
      "step": 1839
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.00022420443587270976,
      "loss": 0.7919,
      "step": 1840
    },
    {
      "epoch": 3.99,
      "learning_rate": 0.00022372227579556416,
      "loss": 0.8148,
      "step": 1841
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.0002232401157184185,
      "loss": 0.8127,
      "step": 1842
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.0002227579556412729,
      "loss": 0.8363,
      "step": 1843
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.0002222757955641273,
      "loss": 1.2856,
      "step": 1844
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.00022179363548698166,
      "loss": 0.8589,
      "step": 1845
    },
    {
      "epoch": 4.0,
      "learning_rate": 0.00022131147540983606,
      "loss": 0.7865,
      "step": 1846
    },
    {
      "epoch": 4.01,
      "learning_rate": 0.00022082931533269046,
      "loss": 0.8499,
      "step": 1847
    },
    {
      "epoch": 4.01,
      "learning_rate": 0.00022034715525554485,
      "loss": 0.8101,
      "step": 1848
    },
    {
      "epoch": 4.01,
      "learning_rate": 0.00021986499517839922,
      "loss": 0.8852,
      "step": 1849
    },
    {
      "epoch": 4.01,
      "learning_rate": 0.00021938283510125362,
      "loss": 0.7756,
      "step": 1850
    },
    {
      "epoch": 4.02,
      "learning_rate": 0.00021890067502410802,
      "loss": 0.7764,
      "step": 1851
    },
    {
      "epoch": 4.02,
      "learning_rate": 0.00021841851494696239,
      "loss": 0.7435,
      "step": 1852
    },
    {
      "epoch": 4.02,
      "learning_rate": 0.00021793635486981678,
      "loss": 0.664,
      "step": 1853
    },
    {
      "epoch": 4.02,
      "learning_rate": 0.00021745419479267118,
      "loss": 0.879,
      "step": 1854
    },
    {
      "epoch": 4.02,
      "learning_rate": 0.00021697203471552558,
      "loss": 0.7534,
      "step": 1855
    },
    {
      "epoch": 4.03,
      "learning_rate": 0.00021648987463837994,
      "loss": 0.7844,
      "step": 1856
    },
    {
      "epoch": 4.03,
      "learning_rate": 0.00021600771456123434,
      "loss": 0.8191,
      "step": 1857
    },
    {
      "epoch": 4.03,
      "learning_rate": 0.00021552555448408874,
      "loss": 0.782,
      "step": 1858
    },
    {
      "epoch": 4.03,
      "learning_rate": 0.00021504339440694313,
      "loss": 0.7653,
      "step": 1859
    },
    {
      "epoch": 4.03,
      "learning_rate": 0.00021456123432979748,
      "loss": 0.8135,
      "step": 1860
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.00021407907425265187,
      "loss": 0.8515,
      "step": 1861
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.00021359691417550627,
      "loss": 0.8516,
      "step": 1862
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.00021311475409836064,
      "loss": 0.9269,
      "step": 1863
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.00021263259402121504,
      "loss": 0.7671,
      "step": 1864
    },
    {
      "epoch": 4.05,
      "learning_rate": 0.00021215043394406943,
      "loss": 0.8224,
      "step": 1865
    },
    {
      "epoch": 4.05,
      "learning_rate": 0.00021166827386692383,
      "loss": 0.8779,
      "step": 1866
    },
    {
      "epoch": 4.05,
      "learning_rate": 0.0002111861137897782,
      "loss": 0.8162,
      "step": 1867
    },
    {
      "epoch": 4.05,
      "learning_rate": 0.0002107039537126326,
      "loss": 0.8165,
      "step": 1868
    },
    {
      "epoch": 4.05,
      "learning_rate": 0.000210221793635487,
      "loss": 0.8542,
      "step": 1869
    },
    {
      "epoch": 4.06,
      "learning_rate": 0.0002097396335583414,
      "loss": 0.887,
      "step": 1870
    },
    {
      "epoch": 4.06,
      "learning_rate": 0.00020925747348119576,
      "loss": 0.7457,
      "step": 1871
    },
    {
      "epoch": 4.06,
      "learning_rate": 0.00020877531340405015,
      "loss": 0.8787,
      "step": 1872
    },
    {
      "epoch": 4.06,
      "learning_rate": 0.00020829315332690455,
      "loss": 0.7193,
      "step": 1873
    },
    {
      "epoch": 4.07,
      "learning_rate": 0.00020781099324975892,
      "loss": 0.7718,
      "step": 1874
    },
    {
      "epoch": 4.07,
      "learning_rate": 0.00020732883317261332,
      "loss": 0.7418,
      "step": 1875
    },
    {
      "epoch": 4.07,
      "learning_rate": 0.00020684667309546771,
      "loss": 0.8261,
      "step": 1876
    },
    {
      "epoch": 4.07,
      "learning_rate": 0.0002063645130183221,
      "loss": 0.7744,
      "step": 1877
    },
    {
      "epoch": 4.07,
      "learning_rate": 0.00020588235294117645,
      "loss": 0.7356,
      "step": 1878
    },
    {
      "epoch": 4.08,
      "learning_rate": 0.00020540019286403085,
      "loss": 0.7348,
      "step": 1879
    },
    {
      "epoch": 4.08,
      "learning_rate": 0.00020491803278688525,
      "loss": 0.8877,
      "step": 1880
    },
    {
      "epoch": 4.08,
      "learning_rate": 0.00020443587270973964,
      "loss": 0.7639,
      "step": 1881
    },
    {
      "epoch": 4.08,
      "learning_rate": 0.000203953712632594,
      "loss": 0.9129,
      "step": 1882
    },
    {
      "epoch": 4.08,
      "learning_rate": 0.0002034715525554484,
      "loss": 0.8858,
      "step": 1883
    },
    {
      "epoch": 4.09,
      "learning_rate": 0.0002029893924783028,
      "loss": 0.7116,
      "step": 1884
    },
    {
      "epoch": 4.09,
      "learning_rate": 0.00020250723240115717,
      "loss": 0.7169,
      "step": 1885
    },
    {
      "epoch": 4.09,
      "learning_rate": 0.00020202507232401157,
      "loss": 0.8123,
      "step": 1886
    },
    {
      "epoch": 4.09,
      "learning_rate": 0.00020154291224686597,
      "loss": 0.8387,
      "step": 1887
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.00020106075216972036,
      "loss": 0.8706,
      "step": 1888
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.00020057859209257473,
      "loss": 0.8132,
      "step": 1889
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.00020009643201542913,
      "loss": 0.7746,
      "step": 1890
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.00019961427193828353,
      "loss": 0.8386,
      "step": 1891
    },
    {
      "epoch": 4.1,
      "learning_rate": 0.00019913211186113792,
      "loss": 0.7615,
      "step": 1892
    },
    {
      "epoch": 4.11,
      "learning_rate": 0.0001986499517839923,
      "loss": 0.8134,
      "step": 1893
    },
    {
      "epoch": 4.11,
      "learning_rate": 0.0001981677917068467,
      "loss": 0.8348,
      "step": 1894
    },
    {
      "epoch": 4.11,
      "learning_rate": 0.00019768563162970109,
      "loss": 0.744,
      "step": 1895
    },
    {
      "epoch": 4.11,
      "learning_rate": 0.00019720347155255543,
      "loss": 0.8233,
      "step": 1896
    },
    {
      "epoch": 4.11,
      "learning_rate": 0.00019672131147540983,
      "loss": 0.8216,
      "step": 1897
    },
    {
      "epoch": 4.12,
      "learning_rate": 0.00019623915139826422,
      "loss": 0.9165,
      "step": 1898
    },
    {
      "epoch": 4.12,
      "learning_rate": 0.00019575699132111862,
      "loss": 0.7884,
      "step": 1899
    },
    {
      "epoch": 4.12,
      "learning_rate": 0.000195274831243973,
      "loss": 0.7411,
      "step": 1900
    },
    {
      "epoch": 4.12,
      "learning_rate": 0.00019479267116682738,
      "loss": 0.7777,
      "step": 1901
    },
    {
      "epoch": 4.13,
      "learning_rate": 0.00019431051108968178,
      "loss": 0.8178,
      "step": 1902
    },
    {
      "epoch": 4.13,
      "learning_rate": 0.00019382835101253615,
      "loss": 0.7572,
      "step": 1903
    },
    {
      "epoch": 4.13,
      "learning_rate": 0.00019334619093539055,
      "loss": 0.7009,
      "step": 1904
    },
    {
      "epoch": 4.13,
      "learning_rate": 0.00019286403085824494,
      "loss": 0.8331,
      "step": 1905
    },
    {
      "epoch": 4.13,
      "learning_rate": 0.00019238187078109934,
      "loss": 0.7021,
      "step": 1906
    },
    {
      "epoch": 4.14,
      "learning_rate": 0.0001918997107039537,
      "loss": 0.7499,
      "step": 1907
    },
    {
      "epoch": 4.14,
      "learning_rate": 0.0001914175506268081,
      "loss": 0.7622,
      "step": 1908
    },
    {
      "epoch": 4.14,
      "learning_rate": 0.0001909353905496625,
      "loss": 0.8469,
      "step": 1909
    },
    {
      "epoch": 4.14,
      "learning_rate": 0.0001904532304725169,
      "loss": 0.8645,
      "step": 1910
    },
    {
      "epoch": 4.15,
      "learning_rate": 0.00018997107039537127,
      "loss": 0.6888,
      "step": 1911
    },
    {
      "epoch": 4.15,
      "learning_rate": 0.00018948891031822567,
      "loss": 0.6609,
      "step": 1912
    },
    {
      "epoch": 4.15,
      "learning_rate": 0.00018900675024108006,
      "loss": 0.7668,
      "step": 1913
    },
    {
      "epoch": 4.15,
      "learning_rate": 0.0001885245901639344,
      "loss": 0.8544,
      "step": 1914
    },
    {
      "epoch": 4.15,
      "learning_rate": 0.0001880424300867888,
      "loss": 0.8808,
      "step": 1915
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.0001875602700096432,
      "loss": 0.8223,
      "step": 1916
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.0001870781099324976,
      "loss": 0.8384,
      "step": 1917
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.00018659594985535196,
      "loss": 0.7535,
      "step": 1918
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.00018611378977820636,
      "loss": 0.8952,
      "step": 1919
    },
    {
      "epoch": 4.16,
      "learning_rate": 0.00018563162970106076,
      "loss": 0.8396,
      "step": 1920
    },
    {
      "epoch": 4.17,
      "learning_rate": 0.00018514946962391515,
      "loss": 0.708,
      "step": 1921
    },
    {
      "epoch": 4.17,
      "learning_rate": 0.00018466730954676952,
      "loss": 0.9293,
      "step": 1922
    },
    {
      "epoch": 4.17,
      "learning_rate": 0.00018418514946962392,
      "loss": 0.816,
      "step": 1923
    },
    {
      "epoch": 4.17,
      "learning_rate": 0.00018370298939247832,
      "loss": 0.7136,
      "step": 1924
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.00018322082931533269,
      "loss": 0.8686,
      "step": 1925
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.00018273866923818708,
      "loss": 0.7427,
      "step": 1926
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.00018225650916104148,
      "loss": 0.9576,
      "step": 1927
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.00018177434908389588,
      "loss": 0.7746,
      "step": 1928
    },
    {
      "epoch": 4.18,
      "learning_rate": 0.00018129218900675024,
      "loss": 0.7748,
      "step": 1929
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.00018081002892960464,
      "loss": 0.7754,
      "step": 1930
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.00018032786885245904,
      "loss": 0.6871,
      "step": 1931
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.00017984570877531343,
      "loss": 0.7364,
      "step": 1932
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.00017936354869816778,
      "loss": 0.944,
      "step": 1933
    },
    {
      "epoch": 4.2,
      "learning_rate": 0.00017888138862102217,
      "loss": 0.7748,
      "step": 1934
    },
    {
      "epoch": 4.2,
      "learning_rate": 0.00017839922854387657,
      "loss": 0.7956,
      "step": 1935
    },
    {
      "epoch": 4.2,
      "learning_rate": 0.00017791706846673094,
      "loss": 0.6768,
      "step": 1936
    },
    {
      "epoch": 4.2,
      "learning_rate": 0.00017743490838958534,
      "loss": 0.7989,
      "step": 1937
    },
    {
      "epoch": 4.2,
      "learning_rate": 0.00017695274831243973,
      "loss": 0.7052,
      "step": 1938
    },
    {
      "epoch": 4.21,
      "learning_rate": 0.00017647058823529413,
      "loss": 0.7847,
      "step": 1939
    },
    {
      "epoch": 4.21,
      "learning_rate": 0.0001759884281581485,
      "loss": 0.85,
      "step": 1940
    },
    {
      "epoch": 4.21,
      "learning_rate": 0.0001755062680810029,
      "loss": 0.817,
      "step": 1941
    },
    {
      "epoch": 4.21,
      "learning_rate": 0.0001750241080038573,
      "loss": 0.7627,
      "step": 1942
    },
    {
      "epoch": 4.21,
      "learning_rate": 0.00017454194792671166,
      "loss": 0.8502,
      "step": 1943
    },
    {
      "epoch": 4.22,
      "learning_rate": 0.00017405978784956606,
      "loss": 0.7658,
      "step": 1944
    },
    {
      "epoch": 4.22,
      "learning_rate": 0.00017357762777242045,
      "loss": 0.8612,
      "step": 1945
    },
    {
      "epoch": 4.22,
      "learning_rate": 0.00017309546769527485,
      "loss": 0.939,
      "step": 1946
    },
    {
      "epoch": 4.22,
      "learning_rate": 0.00017261330761812922,
      "loss": 0.8938,
      "step": 1947
    },
    {
      "epoch": 4.23,
      "learning_rate": 0.00017213114754098362,
      "loss": 0.781,
      "step": 1948
    },
    {
      "epoch": 4.23,
      "learning_rate": 0.00017164898746383801,
      "loss": 0.7468,
      "step": 1949
    },
    {
      "epoch": 4.23,
      "learning_rate": 0.0001711668273866924,
      "loss": 0.7853,
      "step": 1950
    },
    {
      "epoch": 4.23,
      "learning_rate": 0.00017068466730954675,
      "loss": 0.7451,
      "step": 1951
    },
    {
      "epoch": 4.23,
      "learning_rate": 0.00017020250723240115,
      "loss": 0.7623,
      "step": 1952
    },
    {
      "epoch": 4.24,
      "learning_rate": 0.00016972034715525555,
      "loss": 0.7807,
      "step": 1953
    },
    {
      "epoch": 4.24,
      "learning_rate": 0.00016923818707810992,
      "loss": 0.8396,
      "step": 1954
    },
    {
      "epoch": 4.24,
      "learning_rate": 0.0001687560270009643,
      "loss": 0.7166,
      "step": 1955
    },
    {
      "epoch": 4.24,
      "learning_rate": 0.0001682738669238187,
      "loss": 0.8077,
      "step": 1956
    },
    {
      "epoch": 4.25,
      "learning_rate": 0.0001677917068466731,
      "loss": 0.7627,
      "step": 1957
    },
    {
      "epoch": 4.25,
      "learning_rate": 0.00016730954676952747,
      "loss": 0.7743,
      "step": 1958
    },
    {
      "epoch": 4.25,
      "learning_rate": 0.00016682738669238187,
      "loss": 0.748,
      "step": 1959
    },
    {
      "epoch": 4.25,
      "learning_rate": 0.00016634522661523627,
      "loss": 0.855,
      "step": 1960
    },
    {
      "epoch": 4.25,
      "learning_rate": 0.00016586306653809066,
      "loss": 0.7798,
      "step": 1961
    },
    {
      "epoch": 4.26,
      "learning_rate": 0.00016538090646094503,
      "loss": 0.7567,
      "step": 1962
    },
    {
      "epoch": 4.26,
      "learning_rate": 0.00016489874638379943,
      "loss": 0.8986,
      "step": 1963
    },
    {
      "epoch": 4.26,
      "learning_rate": 0.00016441658630665383,
      "loss": 0.9349,
      "step": 1964
    },
    {
      "epoch": 4.26,
      "learning_rate": 0.0001639344262295082,
      "loss": 0.7909,
      "step": 1965
    },
    {
      "epoch": 4.26,
      "learning_rate": 0.0001634522661523626,
      "loss": 0.8181,
      "step": 1966
    },
    {
      "epoch": 4.27,
      "learning_rate": 0.000162970106075217,
      "loss": 0.7918,
      "step": 1967
    },
    {
      "epoch": 4.27,
      "learning_rate": 0.00016248794599807139,
      "loss": 0.8132,
      "step": 1968
    },
    {
      "epoch": 4.27,
      "learning_rate": 0.00016200578592092573,
      "loss": 0.8849,
      "step": 1969
    },
    {
      "epoch": 4.27,
      "learning_rate": 0.00016152362584378013,
      "loss": 0.7614,
      "step": 1970
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.00016104146576663452,
      "loss": 0.7654,
      "step": 1971
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.00016055930568948892,
      "loss": 0.6976,
      "step": 1972
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.0001600771456123433,
      "loss": 0.8919,
      "step": 1973
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.00015959498553519768,
      "loss": 0.7526,
      "step": 1974
    },
    {
      "epoch": 4.28,
      "learning_rate": 0.00015911282545805208,
      "loss": 0.6407,
      "step": 1975
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.00015863066538090645,
      "loss": 0.7827,
      "step": 1976
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.00015814850530376085,
      "loss": 0.7862,
      "step": 1977
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.00015766634522661524,
      "loss": 0.8461,
      "step": 1978
    },
    {
      "epoch": 4.29,
      "learning_rate": 0.00015718418514946964,
      "loss": 0.8856,
      "step": 1979
    },
    {
      "epoch": 4.3,
      "learning_rate": 0.000156702025072324,
      "loss": 0.8015,
      "step": 1980
    },
    {
      "epoch": 4.3,
      "learning_rate": 0.0001562198649951784,
      "loss": 0.7173,
      "step": 1981
    },
    {
      "epoch": 4.3,
      "learning_rate": 0.0001557377049180328,
      "loss": 0.7081,
      "step": 1982
    },
    {
      "epoch": 4.3,
      "learning_rate": 0.00015525554484088717,
      "loss": 0.8281,
      "step": 1983
    },
    {
      "epoch": 4.3,
      "learning_rate": 0.00015477338476374157,
      "loss": 0.8861,
      "step": 1984
    },
    {
      "epoch": 4.31,
      "learning_rate": 0.00015429122468659597,
      "loss": 0.8085,
      "step": 1985
    },
    {
      "epoch": 4.31,
      "learning_rate": 0.00015380906460945036,
      "loss": 1.0405,
      "step": 1986
    },
    {
      "epoch": 4.31,
      "learning_rate": 0.0001533269045323047,
      "loss": 0.7797,
      "step": 1987
    },
    {
      "epoch": 4.31,
      "learning_rate": 0.0001528447444551591,
      "loss": 0.9046,
      "step": 1988
    },
    {
      "epoch": 4.31,
      "learning_rate": 0.0001523625843780135,
      "loss": 0.7228,
      "step": 1989
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.0001518804243008679,
      "loss": 0.7772,
      "step": 1990
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.00015139826422372226,
      "loss": 0.8613,
      "step": 1991
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.00015091610414657666,
      "loss": 0.8357,
      "step": 1992
    },
    {
      "epoch": 4.32,
      "learning_rate": 0.00015043394406943106,
      "loss": 0.736,
      "step": 1993
    },
    {
      "epoch": 4.33,
      "learning_rate": 0.00014995178399228543,
      "loss": 0.6918,
      "step": 1994
    },
    {
      "epoch": 4.33,
      "learning_rate": 0.00014946962391513982,
      "loss": 0.7819,
      "step": 1995
    },
    {
      "epoch": 4.33,
      "learning_rate": 0.00014898746383799422,
      "loss": 0.7241,
      "step": 1996
    },
    {
      "epoch": 4.33,
      "learning_rate": 0.00014850530376084862,
      "loss": 0.8302,
      "step": 1997
    },
    {
      "epoch": 4.33,
      "learning_rate": 0.00014802314368370299,
      "loss": 0.8479,
      "step": 1998
    },
    {
      "epoch": 4.34,
      "learning_rate": 0.00014754098360655738,
      "loss": 0.7383,
      "step": 1999
    },
    {
      "epoch": 4.34,
      "learning_rate": 0.00014705882352941178,
      "loss": 0.7576,
      "step": 2000
    }
  ],
  "logging_steps": 1,
  "max_steps": 2305,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "total_flos": 1.0822118353875763e+18,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
