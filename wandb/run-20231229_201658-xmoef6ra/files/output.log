12/29/2023 20:16:59 - INFO - __main__ - ***** Running training *****
12/29/2023 20:16:59 - INFO - __main__ -   Num examples = 14732
12/29/2023 20:16:59 - INFO - __main__ -   Num Epochs = 5
12/29/2023 20:16:59 - INFO - __main__ -   Instantaneous batch size per device = 4
12/29/2023 20:16:59 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16
12/29/2023 20:16:59 - INFO - __main__ -   Gradient Accumulation steps = 4
12/29/2023 20:16:59 - INFO - __main__ -   Total optimization steps = 4605
  0%|                                                                                                                                             | 0/4605 [00:00<?, ?it/s]12/29/2023 20:16:59 - INFO - accelerate.accelerator - Loading states from ./exp_results/with_prompt_low_lr_linear_decay_5e-6/step_900
|- Resuming from checkpoint
Resumed from checkpoint: ./exp_results/with_prompt_low_lr_linear_decay_5e-6/step_900 path step_900
12/29/2023 20:17:27 - INFO - accelerate.checkpointing - All model weights loaded successfully
12/29/2023 20:17:36 - INFO - accelerate.checkpointing - All optimizer states loaded successfully
12/29/2023 20:17:36 - INFO - accelerate.checkpointing - All scheduler states loaded successfully
12/29/2023 20:17:36 - INFO - accelerate.checkpointing - All dataloader sampler states loaded successfully
12/29/2023 20:17:36 - INFO - accelerate.checkpointing - All random states loaded successfully
12/29/2023 20:17:36 - INFO - accelerate.accelerator - Loading in 0 custom states
Traceback (most recent call last):
  File "/home/cwtang/david_dynamo/train_gsm8k_llama.py", line 928, in <module>
    main()
  File "/home/cwtang/david_dynamo/train_gsm8k_llama.py", line 698, in main
    resume_step = int(training_difference.replace("step_", "")) * args.gradient_accumulation_steps
ValueError: invalid literal for int() with base 10: './exp_results/with_prompt_low_lr_linear_decay_5e-6/900'