2023-12-29 22:41:05,569 INFO    MainThread:39932 [wandb_setup.py:_flush():76] Current SDK version is 0.16.1
2023-12-29 22:41:05,569 INFO    MainThread:39932 [wandb_setup.py:_flush():76] Configure stats pid to 39932
2023-12-29 22:41:05,569 INFO    MainThread:39932 [wandb_setup.py:_flush():76] Loading settings from /home/cwtang/.config/wandb/settings
2023-12-29 22:41:05,569 INFO    MainThread:39932 [wandb_setup.py:_flush():76] Loading settings from /home/cwtang/david_dynamo/wandb/settings
2023-12-29 22:41:05,569 INFO    MainThread:39932 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2023-12-29 22:41:05,569 INFO    MainThread:39932 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2023-12-29 22:41:05,569 INFO    MainThread:39932 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'train_gsm8k_llama.py', 'program_abspath': '/home/cwtang/david_dynamo/train_gsm8k_llama.py', 'program': '/home/cwtang/david_dynamo/train_gsm8k_llama.py'}
2023-12-29 22:41:05,569 INFO    MainThread:39932 [wandb_init.py:_log_setup():524] Logging user logs to /home/cwtang/david_dynamo/wandb/run-20231229_224105-e0zozc5k/logs/debug.log
2023-12-29 22:41:05,569 INFO    MainThread:39932 [wandb_init.py:_log_setup():525] Logging internal logs to /home/cwtang/david_dynamo/wandb/run-20231229_224105-e0zozc5k/logs/debug-internal.log
2023-12-29 22:41:05,569 INFO    MainThread:39932 [wandb_init.py:init():564] calling init triggers
2023-12-29 22:41:05,569 INFO    MainThread:39932 [wandb_init.py:init():571] wandb.init called with sweep_config: {}
config: {}
2023-12-29 22:41:05,569 INFO    MainThread:39932 [wandb_init.py:init():614] starting backend
2023-12-29 22:41:05,569 INFO    MainThread:39932 [wandb_init.py:init():618] setting up manager
2023-12-29 22:41:05,570 INFO    MainThread:39932 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2023-12-29 22:41:05,570 INFO    MainThread:39932 [wandb_init.py:init():624] backend started and connected
2023-12-29 22:41:05,572 INFO    MainThread:39932 [wandb_init.py:init():716] updated telemetry
2023-12-29 22:41:05,574 INFO    MainThread:39932 [wandb_init.py:init():749] communicating run to backend with 90.0 second timeout
2023-12-29 22:41:05,796 INFO    MainThread:39932 [wandb_run.py:_on_init():2254] communicating current version
2023-12-29 22:41:05,890 INFO    MainThread:39932 [wandb_run.py:_on_init():2263] got version response 
2023-12-29 22:41:05,890 INFO    MainThread:39932 [wandb_init.py:init():800] starting run threads in backend
2023-12-29 22:41:05,950 INFO    MainThread:39932 [wandb_run.py:_console_start():2233] atexit reg
2023-12-29 22:41:05,950 INFO    MainThread:39932 [wandb_run.py:_redirect():2088] redirect: wrap_raw
2023-12-29 22:41:05,951 INFO    MainThread:39932 [wandb_run.py:_redirect():2153] Wrapping output streams.
2023-12-29 22:41:05,951 INFO    MainThread:39932 [wandb_run.py:_redirect():2178] Redirects installed.
2023-12-29 22:41:05,951 INFO    MainThread:39932 [wandb_init.py:init():841] run started, returning control to user process
2023-12-29 22:41:05,952 INFO    MainThread:39932 [wandb_run.py:_config_callback():1342] config_cb None None {'dataset_name': 'samsum', 'dataset_config_name': None, 'train_file': None, 'validation_file': None, 'validation_split_percentage': 5, 'model_name_or_path': 'LoftQ/Llama-2-13b-hf-4bit-64rank', 'config_name': None, 'tokenizer_name': None, 'use_slow_tokenizer': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 4, 'learning_rate': 0.0001, 'weight_decay': 0.1, 'num_train_epochs': 1, 'max_train_steps': 1842, 'gradient_accumulation_steps': 2, 'lr_scheduler_type': 'linear', 'num_warmup_steps': 100, 'output_dir': 'exp_results/no_prompt_lr1e-4_decay0.1', 'seed': 202, 'model_type': None, 'ignore_pad_token_for_loss': True, 'max_source_length': 100, 'max_target_length': 100, 'pad_to_max_length': True, 'preprocessing_num_workers': None, 'overwrite_cache': False, 'no_keep_linebreaks': False, 'push_to_hub': False, 'hub_model_id': None, 'hub_token': None, 'trust_remote_code': False, 'checkpointing_steps': '100', 'resume_from_checkpoint': 'exp_results/no_prompt_lr1e-4_decay0.1/step_800', 'with_tracking': True, 'report_to': 'wandb', 'low_cpu_mem_usage': False, 'temperature': 0.8, 'k': 40, 'p': 0.95, 'eval_only': True, 'eval_freq': 100, 'adapter_name_or_path': 'exp_results/no_prompt_lr1e-4_decay0.1/step_800'}
2023-12-29 22:41:50,144 INFO    MainThread:39932 [wandb_run.py:_finish():1962] finishing run davidchennn/clm_no_trainer/e0zozc5k
2023-12-29 22:41:50,144 INFO    MainThread:39932 [wandb_run.py:_atexit_cleanup():2202] got exitcode: 0
2023-12-29 22:41:50,145 INFO    MainThread:39932 [wandb_run.py:_restore():2185] restore
2023-12-29 22:41:50,145 INFO    MainThread:39932 [wandb_run.py:_restore():2191] restore done
2023-12-29 22:41:54,680 INFO    MainThread:39932 [wandb_run.py:_footer_history_summary_info():3837] rendering history
2023-12-29 22:41:54,681 INFO    MainThread:39932 [wandb_run.py:_footer_history_summary_info():3869] rendering summary
2023-12-29 22:41:54,683 INFO    MainThread:39932 [wandb_run.py:_footer_sync_info():3796] logging synced files
