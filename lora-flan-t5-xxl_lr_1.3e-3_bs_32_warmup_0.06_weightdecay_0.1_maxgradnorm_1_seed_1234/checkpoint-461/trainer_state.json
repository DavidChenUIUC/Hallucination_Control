{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 461,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "learning_rate": 9.35251798561151e-06,
      "loss": 1.1617,
      "step": 1
    },
    {
      "epoch": 0.0,
      "learning_rate": 1.870503597122302e-05,
      "loss": 1.1898,
      "step": 2
    },
    {
      "epoch": 0.01,
      "learning_rate": 2.805755395683453e-05,
      "loss": 1.3259,
      "step": 3
    },
    {
      "epoch": 0.01,
      "learning_rate": 3.741007194244604e-05,
      "loss": 1.2107,
      "step": 4
    },
    {
      "epoch": 0.01,
      "learning_rate": 4.676258992805755e-05,
      "loss": 1.2637,
      "step": 5
    },
    {
      "epoch": 0.01,
      "learning_rate": 5.611510791366906e-05,
      "loss": 1.149,
      "step": 6
    },
    {
      "epoch": 0.02,
      "learning_rate": 6.546762589928057e-05,
      "loss": 1.2068,
      "step": 7
    },
    {
      "epoch": 0.02,
      "learning_rate": 7.482014388489208e-05,
      "loss": 1.1701,
      "step": 8
    },
    {
      "epoch": 0.02,
      "learning_rate": 8.417266187050359e-05,
      "loss": 1.3814,
      "step": 9
    },
    {
      "epoch": 0.02,
      "learning_rate": 9.35251798561151e-05,
      "loss": 1.4568,
      "step": 10
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.00010287769784172661,
      "loss": 1.1471,
      "step": 11
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.00011223021582733813,
      "loss": 1.1348,
      "step": 12
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.00012158273381294963,
      "loss": 1.2778,
      "step": 13
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.00013093525179856113,
      "loss": 1.2329,
      "step": 14
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.00014028776978417264,
      "loss": 1.2166,
      "step": 15
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.00014964028776978417,
      "loss": 1.2747,
      "step": 16
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.00015899280575539567,
      "loss": 1.2973,
      "step": 17
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.00016834532374100718,
      "loss": 1.2217,
      "step": 18
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0001776978417266187,
      "loss": 1.1496,
      "step": 19
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0001870503597122302,
      "loss": 1.1204,
      "step": 20
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00019640287769784171,
      "loss": 1.1604,
      "step": 21
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00020575539568345322,
      "loss": 1.2234,
      "step": 22
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00021510791366906475,
      "loss": 1.1282,
      "step": 23
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00022446043165467625,
      "loss": 1.0501,
      "step": 24
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00023381294964028776,
      "loss": 1.0456,
      "step": 25
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.00024316546762589926,
      "loss": 0.9703,
      "step": 26
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0002525179856115108,
      "loss": 1.1527,
      "step": 27
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.00026187050359712227,
      "loss": 1.1257,
      "step": 28
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0002712230215827338,
      "loss": 1.1096,
      "step": 29
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0002805755395683453,
      "loss": 1.1936,
      "step": 30
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00028992805755395683,
      "loss": 1.1426,
      "step": 31
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00029928057553956834,
      "loss": 1.194,
      "step": 32
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00030863309352517984,
      "loss": 1.1779,
      "step": 33
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00031798561151079134,
      "loss": 1.0624,
      "step": 34
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00032733812949640285,
      "loss": 1.0933,
      "step": 35
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00033669064748201435,
      "loss": 1.222,
      "step": 36
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0003460431654676259,
      "loss": 1.117,
      "step": 37
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0003553956834532374,
      "loss": 1.1859,
      "step": 38
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00036474820143884886,
      "loss": 0.962,
      "step": 39
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0003741007194244604,
      "loss": 1.1717,
      "step": 40
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0003834532374100719,
      "loss": 1.122,
      "step": 41
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.00039280575539568343,
      "loss": 0.9946,
      "step": 42
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.000402158273381295,
      "loss": 1.0205,
      "step": 43
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00041151079136690644,
      "loss": 1.029,
      "step": 44
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00042086330935251794,
      "loss": 1.1928,
      "step": 45
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0004302158273381295,
      "loss": 1.0372,
      "step": 46
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.000439568345323741,
      "loss": 1.0884,
      "step": 47
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0004489208633093525,
      "loss": 1.1559,
      "step": 48
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.00045827338129496395,
      "loss": 0.9245,
      "step": 49
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0004676258992805755,
      "loss": 1.064,
      "step": 50
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.000476978417266187,
      "loss": 1.1556,
      "step": 51
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0004863309352517985,
      "loss": 1.1505,
      "step": 52
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0004956834532374101,
      "loss": 1.1104,
      "step": 53
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0005050359712230216,
      "loss": 0.941,
      "step": 54
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0005143884892086331,
      "loss": 0.9632,
      "step": 55
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0005237410071942445,
      "loss": 1.0334,
      "step": 56
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0005330935251798561,
      "loss": 1.1299,
      "step": 57
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0005424460431654677,
      "loss": 0.9005,
      "step": 58
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0005517985611510791,
      "loss": 1.1633,
      "step": 59
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0005611510791366905,
      "loss": 1.1158,
      "step": 60
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0005705035971223021,
      "loss": 1.1031,
      "step": 61
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0005798561151079137,
      "loss": 1.0237,
      "step": 62
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0005892086330935252,
      "loss": 1.1056,
      "step": 63
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0005985611510791367,
      "loss": 1.1476,
      "step": 64
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0006079136690647481,
      "loss": 1.0109,
      "step": 65
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0006172661870503597,
      "loss": 1.0698,
      "step": 66
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0006266187050359712,
      "loss": 1.1444,
      "step": 67
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0006359712230215827,
      "loss": 1.1027,
      "step": 68
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0006453237410071942,
      "loss": 1.1009,
      "step": 69
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0006546762589928057,
      "loss": 1.2475,
      "step": 70
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0006640287769784173,
      "loss": 1.1045,
      "step": 71
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0006733812949640287,
      "loss": 1.0582,
      "step": 72
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0006827338129496402,
      "loss": 1.013,
      "step": 73
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0006920863309352518,
      "loss": 1.1092,
      "step": 74
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0007014388489208633,
      "loss": 1.0785,
      "step": 75
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0007107913669064748,
      "loss": 1.0613,
      "step": 76
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0007201438848920863,
      "loss": 1.0127,
      "step": 77
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0007294964028776977,
      "loss": 0.9598,
      "step": 78
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0007388489208633094,
      "loss": 1.1395,
      "step": 79
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0007482014388489208,
      "loss": 1.1991,
      "step": 80
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0007575539568345324,
      "loss": 1.0609,
      "step": 81
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0007669064748201438,
      "loss": 1.148,
      "step": 82
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0007762589928057553,
      "loss": 1.0682,
      "step": 83
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0007856115107913669,
      "loss": 1.1187,
      "step": 84
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0007949640287769783,
      "loss": 1.2014,
      "step": 85
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00080431654676259,
      "loss": 0.9865,
      "step": 86
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0008136690647482014,
      "loss": 1.091,
      "step": 87
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0008230215827338129,
      "loss": 1.2124,
      "step": 88
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0008323741007194244,
      "loss": 1.0859,
      "step": 89
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0008417266187050359,
      "loss": 1.0628,
      "step": 90
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0008510791366906475,
      "loss": 1.0483,
      "step": 91
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.000860431654676259,
      "loss": 1.0506,
      "step": 92
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0008697841726618704,
      "loss": 1.1109,
      "step": 93
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.000879136690647482,
      "loss": 1.1309,
      "step": 94
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0008884892086330935,
      "loss": 1.0318,
      "step": 95
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.000897841726618705,
      "loss": 1.0856,
      "step": 96
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0009071942446043165,
      "loss": 1.0986,
      "step": 97
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0009165467625899279,
      "loss": 1.2011,
      "step": 98
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0009258992805755396,
      "loss": 1.1173,
      "step": 99
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.000935251798561151,
      "loss": 0.9711,
      "step": 100
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0009446043165467626,
      "loss": 1.1963,
      "step": 101
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.000953956834532374,
      "loss": 1.1418,
      "step": 102
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0009633093525179855,
      "loss": 1.1035,
      "step": 103
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.000972661870503597,
      "loss": 1.0508,
      "step": 104
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0009820143884892085,
      "loss": 1.2406,
      "step": 105
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0009913669064748202,
      "loss": 1.2676,
      "step": 106
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0010007194244604316,
      "loss": 1.0041,
      "step": 107
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0010100719424460433,
      "loss": 1.0683,
      "step": 108
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0010194244604316547,
      "loss": 0.96,
      "step": 109
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0010287769784172662,
      "loss": 1.1417,
      "step": 110
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0010381294964028776,
      "loss": 1.1725,
      "step": 111
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001047482014388489,
      "loss": 1.0339,
      "step": 112
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0010568345323741007,
      "loss": 1.1103,
      "step": 113
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0010661870503597122,
      "loss": 1.1636,
      "step": 114
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0010755395683453236,
      "loss": 1.2039,
      "step": 115
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0010848920863309353,
      "loss": 1.0297,
      "step": 116
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0010942446043165467,
      "loss": 0.9883,
      "step": 117
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0011035971223021582,
      "loss": 1.1299,
      "step": 118
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0011129496402877696,
      "loss": 1.0625,
      "step": 119
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.001122302158273381,
      "loss": 0.97,
      "step": 120
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0011316546762589928,
      "loss": 1.106,
      "step": 121
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0011410071942446042,
      "loss": 1.0613,
      "step": 122
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0011503597122302159,
      "loss": 1.0713,
      "step": 123
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0011597122302158273,
      "loss": 1.0497,
      "step": 124
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0011690647482014388,
      "loss": 1.0726,
      "step": 125
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0011784172661870504,
      "loss": 1.1702,
      "step": 126
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001187769784172662,
      "loss": 1.0556,
      "step": 127
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0011971223021582733,
      "loss": 1.1059,
      "step": 128
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0012064748201438848,
      "loss": 1.1422,
      "step": 129
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0012158273381294962,
      "loss": 1.1153,
      "step": 130
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001225179856115108,
      "loss": 1.0321,
      "step": 131
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0012345323741007194,
      "loss": 0.9796,
      "step": 132
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.001243884892086331,
      "loss": 1.0049,
      "step": 133
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0012532374100719425,
      "loss": 1.2594,
      "step": 134
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.001262589928057554,
      "loss": 1.0506,
      "step": 135
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0012719424460431654,
      "loss": 1.2034,
      "step": 136
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0012812949640287768,
      "loss": 1.0769,
      "step": 137
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0012906474820143885,
      "loss": 0.9549,
      "step": 138
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0013,
      "loss": 1.2036,
      "step": 139
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.001299399815327793,
      "loss": 1.0702,
      "step": 140
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0012987996306555864,
      "loss": 1.1891,
      "step": 141
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0012981994459833794,
      "loss": 1.2055,
      "step": 142
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0012975992613111725,
      "loss": 1.1347,
      "step": 143
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0012969990766389659,
      "loss": 1.149,
      "step": 144
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.001296398891966759,
      "loss": 0.9932,
      "step": 145
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.001295798707294552,
      "loss": 1.1006,
      "step": 146
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0012951985226223454,
      "loss": 1.0729,
      "step": 147
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0012945983379501385,
      "loss": 0.9918,
      "step": 148
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0012939981532779318,
      "loss": 1.0741,
      "step": 149
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0012933979686057249,
      "loss": 1.0282,
      "step": 150
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001292797783933518,
      "loss": 1.1867,
      "step": 151
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001292197599261311,
      "loss": 1.1903,
      "step": 152
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0012915974145891042,
      "loss": 1.2287,
      "step": 153
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0012909972299168975,
      "loss": 1.1473,
      "step": 154
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0012903970452446906,
      "loss": 1.2096,
      "step": 155
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0012897968605724837,
      "loss": 1.2171,
      "step": 156
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.001289196675900277,
      "loss": 1.025,
      "step": 157
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.00128859649122807,
      "loss": 1.2041,
      "step": 158
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0012879963065558632,
      "loss": 1.1285,
      "step": 159
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0012873961218836565,
      "loss": 1.0991,
      "step": 160
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0012867959372114496,
      "loss": 1.1859,
      "step": 161
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0012861957525392427,
      "loss": 1.4186,
      "step": 162
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.001285595567867036,
      "loss": 1.0389,
      "step": 163
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.001284995383194829,
      "loss": 1.1155,
      "step": 164
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0012843951985226222,
      "loss": 1.2565,
      "step": 165
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0012837950138504155,
      "loss": 1.1716,
      "step": 166
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0012831948291782086,
      "loss": 1.1576,
      "step": 167
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0012825946445060017,
      "loss": 1.2736,
      "step": 168
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.001281994459833795,
      "loss": 1.0187,
      "step": 169
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0012813942751615881,
      "loss": 1.1219,
      "step": 170
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0012807940904893814,
      "loss": 1.1098,
      "step": 171
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0012801939058171745,
      "loss": 1.1928,
      "step": 172
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0012795937211449676,
      "loss": 0.9699,
      "step": 173
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001278993536472761,
      "loss": 1.3202,
      "step": 174
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001278393351800554,
      "loss": 1.2311,
      "step": 175
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0012777931671283471,
      "loss": 0.9765,
      "step": 176
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0012771929824561402,
      "loss": 1.2321,
      "step": 177
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0012765927977839333,
      "loss": 1.1709,
      "step": 178
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0012759926131117266,
      "loss": 1.208,
      "step": 179
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0012753924284395197,
      "loss": 1.0949,
      "step": 180
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0012747922437673128,
      "loss": 1.1161,
      "step": 181
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0012741920590951061,
      "loss": 1.2859,
      "step": 182
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0012735918744228992,
      "loss": 1.13,
      "step": 183
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0012729916897506923,
      "loss": 1.0289,
      "step": 184
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0012723915050784856,
      "loss": 1.1045,
      "step": 185
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0012717913204062787,
      "loss": 1.1493,
      "step": 186
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0012711911357340718,
      "loss": 1.0119,
      "step": 187
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0012705909510618652,
      "loss": 1.1736,
      "step": 188
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0012699907663896583,
      "loss": 1.0891,
      "step": 189
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0012693905817174516,
      "loss": 1.1558,
      "step": 190
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0012687903970452447,
      "loss": 1.1756,
      "step": 191
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0012681902123730378,
      "loss": 1.2697,
      "step": 192
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.001267590027700831,
      "loss": 1.1133,
      "step": 193
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0012669898430286242,
      "loss": 1.0344,
      "step": 194
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0012663896583564173,
      "loss": 1.0475,
      "step": 195
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0012657894736842106,
      "loss": 1.1299,
      "step": 196
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0012651892890120037,
      "loss": 1.2234,
      "step": 197
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0012645891043397968,
      "loss": 1.223,
      "step": 198
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.00126398891966759,
      "loss": 1.0936,
      "step": 199
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0012633887349953832,
      "loss": 1.2684,
      "step": 200
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0012627885503231763,
      "loss": 1.2257,
      "step": 201
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0012621883656509694,
      "loss": 1.0475,
      "step": 202
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0012615881809787625,
      "loss": 1.1738,
      "step": 203
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0012609879963065558,
      "loss": 1.195,
      "step": 204
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0012603878116343489,
      "loss": 1.2046,
      "step": 205
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.001259787626962142,
      "loss": 1.1327,
      "step": 206
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0012591874422899353,
      "loss": 1.078,
      "step": 207
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0012585872576177284,
      "loss": 1.1013,
      "step": 208
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0012579870729455217,
      "loss": 1.165,
      "step": 209
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0012573868882733148,
      "loss": 1.0454,
      "step": 210
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.001256786703601108,
      "loss": 1.0444,
      "step": 211
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0012561865189289012,
      "loss": 1.2352,
      "step": 212
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0012555863342566943,
      "loss": 1.1794,
      "step": 213
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0012549861495844874,
      "loss": 1.3649,
      "step": 214
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0012543859649122807,
      "loss": 1.1408,
      "step": 215
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0012537857802400738,
      "loss": 1.1899,
      "step": 216
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001253185595567867,
      "loss": 1.2234,
      "step": 217
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0012525854108956602,
      "loss": 1.1675,
      "step": 218
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0012519852262234533,
      "loss": 1.0834,
      "step": 219
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0012513850415512464,
      "loss": 1.2582,
      "step": 220
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0012507848568790397,
      "loss": 1.0384,
      "step": 221
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0012501846722068328,
      "loss": 1.1682,
      "step": 222
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001249584487534626,
      "loss": 1.1419,
      "step": 223
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0012489843028624192,
      "loss": 1.0909,
      "step": 224
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0012483841181902123,
      "loss": 1.0248,
      "step": 225
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0012477839335180054,
      "loss": 1.235,
      "step": 226
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0012471837488457988,
      "loss": 1.0166,
      "step": 227
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0012465835641735919,
      "loss": 1.0308,
      "step": 228
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001245983379501385,
      "loss": 1.1164,
      "step": 229
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001245383194829178,
      "loss": 1.277,
      "step": 230
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0012447830101569714,
      "loss": 1.2334,
      "step": 231
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0012441828254847645,
      "loss": 1.1953,
      "step": 232
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0012435826408125576,
      "loss": 1.1771,
      "step": 233
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0012429824561403509,
      "loss": 1.1461,
      "step": 234
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001242382271468144,
      "loss": 1.2284,
      "step": 235
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001241782086795937,
      "loss": 1.1795,
      "step": 236
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0012411819021237304,
      "loss": 1.1077,
      "step": 237
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0012405817174515235,
      "loss": 1.2034,
      "step": 238
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0012399815327793166,
      "loss": 1.1398,
      "step": 239
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0012393813481071099,
      "loss": 1.1431,
      "step": 240
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.001238781163434903,
      "loss": 1.0613,
      "step": 241
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.001238180978762696,
      "loss": 1.1703,
      "step": 242
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0012375807940904894,
      "loss": 1.2643,
      "step": 243
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0012369806094182825,
      "loss": 1.117,
      "step": 244
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0012363804247460756,
      "loss": 1.2319,
      "step": 245
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001235780240073869,
      "loss": 1.3612,
      "step": 246
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.001235180055401662,
      "loss": 1.1784,
      "step": 247
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0012345798707294553,
      "loss": 1.2135,
      "step": 248
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0012339796860572484,
      "loss": 1.2236,
      "step": 249
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0012333795013850415,
      "loss": 0.9652,
      "step": 250
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0012327793167128348,
      "loss": 1.1314,
      "step": 251
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001232179132040628,
      "loss": 1.14,
      "step": 252
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001231578947368421,
      "loss": 1.1554,
      "step": 253
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001230978762696214,
      "loss": 1.115,
      "step": 254
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0012303785780240072,
      "loss": 1.3273,
      "step": 255
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0012297783933518005,
      "loss": 1.053,
      "step": 256
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0012291782086795936,
      "loss": 1.007,
      "step": 257
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0012285780240073867,
      "loss": 1.0124,
      "step": 258
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00122797783933518,
      "loss": 1.1531,
      "step": 259
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0012273776546629731,
      "loss": 1.1695,
      "step": 260
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0012267774699907662,
      "loss": 1.1992,
      "step": 261
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0012261772853185595,
      "loss": 1.1775,
      "step": 262
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0012255771006463526,
      "loss": 1.1634,
      "step": 263
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0012249769159741457,
      "loss": 1.1114,
      "step": 264
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001224376731301939,
      "loss": 1.1144,
      "step": 265
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0012237765466297321,
      "loss": 1.079,
      "step": 266
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0012231763619575254,
      "loss": 1.0368,
      "step": 267
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0012225761772853185,
      "loss": 1.2004,
      "step": 268
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0012219759926131116,
      "loss": 1.2174,
      "step": 269
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.001221375807940905,
      "loss": 1.1251,
      "step": 270
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.001220775623268698,
      "loss": 1.2277,
      "step": 271
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0012201754385964911,
      "loss": 1.315,
      "step": 272
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0012195752539242845,
      "loss": 1.1199,
      "step": 273
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0012189750692520776,
      "loss": 1.1988,
      "step": 274
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0012183748845798707,
      "loss": 1.2042,
      "step": 275
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001217774699907664,
      "loss": 1.0932,
      "step": 276
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001217174515235457,
      "loss": 1.2307,
      "step": 277
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0012165743305632502,
      "loss": 1.3008,
      "step": 278
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0012159741458910433,
      "loss": 1.2368,
      "step": 279
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0012153739612188364,
      "loss": 1.0918,
      "step": 280
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0012147737765466297,
      "loss": 1.2661,
      "step": 281
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0012141735918744228,
      "loss": 1.0637,
      "step": 282
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0012135734072022159,
      "loss": 1.1527,
      "step": 283
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0012129732225300092,
      "loss": 1.237,
      "step": 284
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0012123730378578023,
      "loss": 1.2957,
      "step": 285
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0012117728531855956,
      "loss": 1.1416,
      "step": 286
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0012111726685133887,
      "loss": 1.2746,
      "step": 287
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0012105724838411818,
      "loss": 1.1758,
      "step": 288
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.001209972299168975,
      "loss": 1.1194,
      "step": 289
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0012093721144967682,
      "loss": 1.2158,
      "step": 290
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0012087719298245613,
      "loss": 1.1331,
      "step": 291
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0012081717451523546,
      "loss": 1.247,
      "step": 292
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0012075715604801477,
      "loss": 0.9578,
      "step": 293
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0012069713758079408,
      "loss": 1.0113,
      "step": 294
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0012063711911357341,
      "loss": 1.0545,
      "step": 295
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0012057710064635272,
      "loss": 1.2253,
      "step": 296
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0012051708217913203,
      "loss": 1.2403,
      "step": 297
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0012045706371191136,
      "loss": 1.1281,
      "step": 298
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0012039704524469067,
      "loss": 1.1615,
      "step": 299
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0012033702677746998,
      "loss": 1.2905,
      "step": 300
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0012027700831024931,
      "loss": 1.2748,
      "step": 301
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0012021698984302862,
      "loss": 1.0944,
      "step": 302
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0012015697137580793,
      "loss": 1.1062,
      "step": 303
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0012009695290858724,
      "loss": 1.0824,
      "step": 304
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0012003693444136657,
      "loss": 1.2062,
      "step": 305
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0011997691597414588,
      "loss": 1.2599,
      "step": 306
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.001199168975069252,
      "loss": 1.2949,
      "step": 307
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0011985687903970452,
      "loss": 1.1586,
      "step": 308
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0011979686057248383,
      "loss": 1.1871,
      "step": 309
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0011973684210526314,
      "loss": 1.1544,
      "step": 310
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0011967682363804247,
      "loss": 1.158,
      "step": 311
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0011961680517082178,
      "loss": 1.2425,
      "step": 312
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.001195567867036011,
      "loss": 1.1424,
      "step": 313
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0011949676823638043,
      "loss": 1.1432,
      "step": 314
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0011943674976915974,
      "loss": 1.1143,
      "step": 315
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0011937673130193904,
      "loss": 1.0563,
      "step": 316
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0011931671283471838,
      "loss": 1.1382,
      "step": 317
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0011925669436749769,
      "loss": 1.1714,
      "step": 318
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00119196675900277,
      "loss": 1.0569,
      "step": 319
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0011913665743305633,
      "loss": 1.232,
      "step": 320
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0011907663896583564,
      "loss": 1.1046,
      "step": 321
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0011901662049861495,
      "loss": 1.2025,
      "step": 322
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0011895660203139428,
      "loss": 1.1316,
      "step": 323
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0011889658356417359,
      "loss": 1.08,
      "step": 324
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0011883656509695292,
      "loss": 1.1962,
      "step": 325
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0011877654662973223,
      "loss": 1.093,
      "step": 326
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0011871652816251154,
      "loss": 1.1397,
      "step": 327
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0011865650969529085,
      "loss": 0.9596,
      "step": 328
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0011859649122807016,
      "loss": 1.1483,
      "step": 329
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0011853647276084949,
      "loss": 1.0534,
      "step": 330
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.001184764542936288,
      "loss": 1.1016,
      "step": 331
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.001184164358264081,
      "loss": 1.2302,
      "step": 332
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0011835641735918744,
      "loss": 1.2133,
      "step": 333
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0011829639889196675,
      "loss": 1.1269,
      "step": 334
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0011823638042474606,
      "loss": 1.1641,
      "step": 335
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001181763619575254,
      "loss": 1.0845,
      "step": 336
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001181163434903047,
      "loss": 1.1047,
      "step": 337
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00118056325023084,
      "loss": 1.232,
      "step": 338
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0011799630655586334,
      "loss": 1.196,
      "step": 339
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0011793628808864265,
      "loss": 1.1077,
      "step": 340
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0011787626962142196,
      "loss": 1.1426,
      "step": 341
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.001178162511542013,
      "loss": 1.1683,
      "step": 342
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.001177562326869806,
      "loss": 0.9995,
      "step": 343
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0011769621421975993,
      "loss": 1.0885,
      "step": 344
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0011763619575253924,
      "loss": 1.0927,
      "step": 345
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0011757617728531855,
      "loss": 1.182,
      "step": 346
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0011751615881809788,
      "loss": 1.1456,
      "step": 347
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.001174561403508772,
      "loss": 1.2535,
      "step": 348
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001173961218836565,
      "loss": 1.2176,
      "step": 349
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0011733610341643583,
      "loss": 1.1901,
      "step": 350
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0011727608494921514,
      "loss": 1.1409,
      "step": 351
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0011721606648199445,
      "loss": 1.1208,
      "step": 352
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0011715604801477379,
      "loss": 1.1412,
      "step": 353
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0011709602954755307,
      "loss": 1.2627,
      "step": 354
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001170360110803324,
      "loss": 1.1702,
      "step": 355
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0011697599261311171,
      "loss": 1.0219,
      "step": 356
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0011691597414589102,
      "loss": 1.0785,
      "step": 357
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0011685595567867036,
      "loss": 1.1997,
      "step": 358
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0011679593721144966,
      "loss": 1.2562,
      "step": 359
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0011673591874422897,
      "loss": 1.15,
      "step": 360
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001166759002770083,
      "loss": 1.0871,
      "step": 361
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0011661588180978762,
      "loss": 1.1359,
      "step": 362
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0011655586334256695,
      "loss": 0.9968,
      "step": 363
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0011649584487534626,
      "loss": 1.1672,
      "step": 364
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0011643582640812557,
      "loss": 1.1391,
      "step": 365
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001163758079409049,
      "loss": 1.2439,
      "step": 366
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001163157894736842,
      "loss": 1.0967,
      "step": 367
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0011625577100646352,
      "loss": 1.332,
      "step": 368
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0011619575253924285,
      "loss": 1.2318,
      "step": 369
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0011613573407202216,
      "loss": 1.0062,
      "step": 370
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0011607571560480147,
      "loss": 1.2245,
      "step": 371
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001160156971375808,
      "loss": 1.005,
      "step": 372
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001159556786703601,
      "loss": 1.075,
      "step": 373
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0011589566020313942,
      "loss": 1.1729,
      "step": 374
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0011583564173591875,
      "loss": 1.0454,
      "step": 375
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0011577562326869806,
      "loss": 1.3027,
      "step": 376
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0011571560480147737,
      "loss": 1.152,
      "step": 377
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.001156555863342567,
      "loss": 1.0066,
      "step": 378
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0011559556786703599,
      "loss": 0.9589,
      "step": 379
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0011553554939981532,
      "loss": 1.1316,
      "step": 380
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0011547553093259463,
      "loss": 1.0092,
      "step": 381
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0011541551246537396,
      "loss": 1.0527,
      "step": 382
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0011535549399815327,
      "loss": 0.9516,
      "step": 383
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0011529547553093258,
      "loss": 1.1484,
      "step": 384
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0011523545706371191,
      "loss": 1.1536,
      "step": 385
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0011517543859649122,
      "loss": 1.271,
      "step": 386
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0011511542012927053,
      "loss": 1.18,
      "step": 387
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0011505540166204986,
      "loss": 1.1021,
      "step": 388
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0011499538319482917,
      "loss": 0.9804,
      "step": 389
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0011493536472760848,
      "loss": 1.1876,
      "step": 390
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0011487534626038781,
      "loss": 1.0686,
      "step": 391
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0011481532779316712,
      "loss": 1.1569,
      "step": 392
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0011475530932594643,
      "loss": 1.067,
      "step": 393
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0011469529085872576,
      "loss": 1.2509,
      "step": 394
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0011463527239150507,
      "loss": 1.0336,
      "step": 395
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0011457525392428438,
      "loss": 1.1889,
      "step": 396
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0011451523545706371,
      "loss": 1.1227,
      "step": 397
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0011445521698984302,
      "loss": 1.2669,
      "step": 398
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0011439519852262233,
      "loss": 1.1268,
      "step": 399
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0011433518005540167,
      "loss": 1.2895,
      "step": 400
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0011427516158818098,
      "loss": 1.156,
      "step": 401
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.001142151431209603,
      "loss": 1.2279,
      "step": 402
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0011415512465373962,
      "loss": 1.2044,
      "step": 403
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0011409510618651893,
      "loss": 0.9976,
      "step": 404
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0011403508771929824,
      "loss": 1.0961,
      "step": 405
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0011397506925207755,
      "loss": 1.0584,
      "step": 406
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0011391505078485688,
      "loss": 1.0221,
      "step": 407
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0011385503231763619,
      "loss": 1.1594,
      "step": 408
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.001137950138504155,
      "loss": 0.987,
      "step": 409
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0011373499538319483,
      "loss": 1.2697,
      "step": 410
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0011367497691597414,
      "loss": 1.1378,
      "step": 411
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0011361495844875345,
      "loss": 1.204,
      "step": 412
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0011355493998153278,
      "loss": 1.1196,
      "step": 413
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0011349492151431209,
      "loss": 1.2048,
      "step": 414
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.001134349030470914,
      "loss": 1.2899,
      "step": 415
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0011337488457987073,
      "loss": 1.0167,
      "step": 416
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0011331486611265004,
      "loss": 1.2774,
      "step": 417
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011325484764542935,
      "loss": 1.2585,
      "step": 418
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011319482917820868,
      "loss": 1.0397,
      "step": 419
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00113134810710988,
      "loss": 1.0102,
      "step": 420
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011307479224376732,
      "loss": 1.0858,
      "step": 421
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011301477377654663,
      "loss": 1.2069,
      "step": 422
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011295475530932594,
      "loss": 1.0057,
      "step": 423
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011289473684210527,
      "loss": 1.1286,
      "step": 424
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011283471837488458,
      "loss": 1.1245,
      "step": 425
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001127746999076639,
      "loss": 1.264,
      "step": 426
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011271468144044322,
      "loss": 1.1137,
      "step": 427
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011265466297322253,
      "loss": 0.9998,
      "step": 428
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011259464450600184,
      "loss": 1.1359,
      "step": 429
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011253462603878115,
      "loss": 1.0911,
      "step": 430
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011247460757156046,
      "loss": 1.2212,
      "step": 431
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.001124145891043398,
      "loss": 1.211,
      "step": 432
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.001123545706371191,
      "loss": 1.2091,
      "step": 433
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011229455216989841,
      "loss": 1.2108,
      "step": 434
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011223453370267774,
      "loss": 1.1985,
      "step": 435
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011217451523545705,
      "loss": 1.0779,
      "step": 436
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011211449676823636,
      "loss": 1.1247,
      "step": 437
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.001120544783010157,
      "loss": 1.017,
      "step": 438
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00111994459833795,
      "loss": 1.1368,
      "step": 439
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011193444136657434,
      "loss": 1.1291,
      "step": 440
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011187442289935364,
      "loss": 1.1203,
      "step": 441
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011181440443213295,
      "loss": 1.0176,
      "step": 442
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011175438596491229,
      "loss": 1.1104,
      "step": 443
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.001116943674976916,
      "loss": 1.0757,
      "step": 444
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.001116343490304709,
      "loss": 1.0614,
      "step": 445
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011157433056325024,
      "loss": 1.1382,
      "step": 446
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011151431209602955,
      "loss": 1.1724,
      "step": 447
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011145429362880886,
      "loss": 1.0037,
      "step": 448
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011139427516158819,
      "loss": 1.2535,
      "step": 449
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.001113342566943675,
      "loss": 1.0388,
      "step": 450
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.001112742382271468,
      "loss": 1.1391,
      "step": 451
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0011121421975992614,
      "loss": 1.1561,
      "step": 452
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0011115420129270545,
      "loss": 1.1392,
      "step": 453
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0011109418282548476,
      "loss": 1.0341,
      "step": 454
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0011103416435826407,
      "loss": 1.1371,
      "step": 455
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0011097414589104338,
      "loss": 1.0508,
      "step": 456
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.001109141274238227,
      "loss": 1.2498,
      "step": 457
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0011085410895660202,
      "loss": 1.0712,
      "step": 458
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0011079409048938135,
      "loss": 1.2022,
      "step": 459
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0011073407202216066,
      "loss": 1.0812,
      "step": 460
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0011067405355493997,
      "loss": 1.1283,
      "step": 461
    }
  ],
  "logging_steps": 1,
  "max_steps": 2305,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "total_flos": 2.4942341612843827e+17,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
