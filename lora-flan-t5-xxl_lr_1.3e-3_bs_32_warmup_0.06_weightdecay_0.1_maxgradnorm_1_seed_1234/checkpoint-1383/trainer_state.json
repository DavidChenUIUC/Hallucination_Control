{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 1383,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "learning_rate": 9.35251798561151e-06,
      "loss": 1.1617,
      "step": 1
    },
    {
      "epoch": 0.0,
      "learning_rate": 1.870503597122302e-05,
      "loss": 1.1898,
      "step": 2
    },
    {
      "epoch": 0.01,
      "learning_rate": 2.805755395683453e-05,
      "loss": 1.3259,
      "step": 3
    },
    {
      "epoch": 0.01,
      "learning_rate": 3.741007194244604e-05,
      "loss": 1.2107,
      "step": 4
    },
    {
      "epoch": 0.01,
      "learning_rate": 4.676258992805755e-05,
      "loss": 1.2637,
      "step": 5
    },
    {
      "epoch": 0.01,
      "learning_rate": 5.611510791366906e-05,
      "loss": 1.149,
      "step": 6
    },
    {
      "epoch": 0.02,
      "learning_rate": 6.546762589928057e-05,
      "loss": 1.2068,
      "step": 7
    },
    {
      "epoch": 0.02,
      "learning_rate": 7.482014388489208e-05,
      "loss": 1.1701,
      "step": 8
    },
    {
      "epoch": 0.02,
      "learning_rate": 8.417266187050359e-05,
      "loss": 1.3814,
      "step": 9
    },
    {
      "epoch": 0.02,
      "learning_rate": 9.35251798561151e-05,
      "loss": 1.4568,
      "step": 10
    },
    {
      "epoch": 0.02,
      "learning_rate": 0.00010287769784172661,
      "loss": 1.1471,
      "step": 11
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.00011223021582733813,
      "loss": 1.1348,
      "step": 12
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.00012158273381294963,
      "loss": 1.2778,
      "step": 13
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.00013093525179856113,
      "loss": 1.2329,
      "step": 14
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.00014028776978417264,
      "loss": 1.2166,
      "step": 15
    },
    {
      "epoch": 0.03,
      "learning_rate": 0.00014964028776978417,
      "loss": 1.2747,
      "step": 16
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.00015899280575539567,
      "loss": 1.2973,
      "step": 17
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.00016834532374100718,
      "loss": 1.2217,
      "step": 18
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0001776978417266187,
      "loss": 1.1496,
      "step": 19
    },
    {
      "epoch": 0.04,
      "learning_rate": 0.0001870503597122302,
      "loss": 1.1204,
      "step": 20
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00019640287769784171,
      "loss": 1.1604,
      "step": 21
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00020575539568345322,
      "loss": 1.2234,
      "step": 22
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00021510791366906475,
      "loss": 1.1282,
      "step": 23
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00022446043165467625,
      "loss": 1.0501,
      "step": 24
    },
    {
      "epoch": 0.05,
      "learning_rate": 0.00023381294964028776,
      "loss": 1.0456,
      "step": 25
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.00024316546762589926,
      "loss": 0.9703,
      "step": 26
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0002525179856115108,
      "loss": 1.1527,
      "step": 27
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.00026187050359712227,
      "loss": 1.1257,
      "step": 28
    },
    {
      "epoch": 0.06,
      "learning_rate": 0.0002712230215827338,
      "loss": 1.1096,
      "step": 29
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.0002805755395683453,
      "loss": 1.1936,
      "step": 30
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00028992805755395683,
      "loss": 1.1426,
      "step": 31
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00029928057553956834,
      "loss": 1.194,
      "step": 32
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00030863309352517984,
      "loss": 1.1779,
      "step": 33
    },
    {
      "epoch": 0.07,
      "learning_rate": 0.00031798561151079134,
      "loss": 1.0624,
      "step": 34
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00032733812949640285,
      "loss": 1.0933,
      "step": 35
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00033669064748201435,
      "loss": 1.222,
      "step": 36
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0003460431654676259,
      "loss": 1.117,
      "step": 37
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0003553956834532374,
      "loss": 1.1859,
      "step": 38
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.00036474820143884886,
      "loss": 0.962,
      "step": 39
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0003741007194244604,
      "loss": 1.1717,
      "step": 40
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.0003834532374100719,
      "loss": 1.122,
      "step": 41
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.00039280575539568343,
      "loss": 0.9946,
      "step": 42
    },
    {
      "epoch": 0.09,
      "learning_rate": 0.000402158273381295,
      "loss": 1.0205,
      "step": 43
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00041151079136690644,
      "loss": 1.029,
      "step": 44
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.00042086330935251794,
      "loss": 1.1928,
      "step": 45
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0004302158273381295,
      "loss": 1.0372,
      "step": 46
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.000439568345323741,
      "loss": 1.0884,
      "step": 47
    },
    {
      "epoch": 0.1,
      "learning_rate": 0.0004489208633093525,
      "loss": 1.1559,
      "step": 48
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.00045827338129496395,
      "loss": 0.9245,
      "step": 49
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0004676258992805755,
      "loss": 1.064,
      "step": 50
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.000476978417266187,
      "loss": 1.1556,
      "step": 51
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0004863309352517985,
      "loss": 1.1505,
      "step": 52
    },
    {
      "epoch": 0.11,
      "learning_rate": 0.0004956834532374101,
      "loss": 1.1104,
      "step": 53
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0005050359712230216,
      "loss": 0.941,
      "step": 54
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0005143884892086331,
      "loss": 0.9632,
      "step": 55
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0005237410071942445,
      "loss": 1.0334,
      "step": 56
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.0005330935251798561,
      "loss": 1.1299,
      "step": 57
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0005424460431654677,
      "loss": 0.9005,
      "step": 58
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0005517985611510791,
      "loss": 1.1633,
      "step": 59
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0005611510791366905,
      "loss": 1.1158,
      "step": 60
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0005705035971223021,
      "loss": 1.1031,
      "step": 61
    },
    {
      "epoch": 0.13,
      "learning_rate": 0.0005798561151079137,
      "loss": 1.0237,
      "step": 62
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0005892086330935252,
      "loss": 1.1056,
      "step": 63
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0005985611510791367,
      "loss": 1.1476,
      "step": 64
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0006079136690647481,
      "loss": 1.0109,
      "step": 65
    },
    {
      "epoch": 0.14,
      "learning_rate": 0.0006172661870503597,
      "loss": 1.0698,
      "step": 66
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0006266187050359712,
      "loss": 1.1444,
      "step": 67
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0006359712230215827,
      "loss": 1.1027,
      "step": 68
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0006453237410071942,
      "loss": 1.1009,
      "step": 69
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0006546762589928057,
      "loss": 1.2475,
      "step": 70
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.0006640287769784173,
      "loss": 1.1045,
      "step": 71
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0006733812949640287,
      "loss": 1.0582,
      "step": 72
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0006827338129496402,
      "loss": 1.013,
      "step": 73
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0006920863309352518,
      "loss": 1.1092,
      "step": 74
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0007014388489208633,
      "loss": 1.0785,
      "step": 75
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.0007107913669064748,
      "loss": 1.0613,
      "step": 76
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0007201438848920863,
      "loss": 1.0127,
      "step": 77
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0007294964028776977,
      "loss": 0.9598,
      "step": 78
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0007388489208633094,
      "loss": 1.1395,
      "step": 79
    },
    {
      "epoch": 0.17,
      "learning_rate": 0.0007482014388489208,
      "loss": 1.1991,
      "step": 80
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0007575539568345324,
      "loss": 1.0609,
      "step": 81
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0007669064748201438,
      "loss": 1.148,
      "step": 82
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0007762589928057553,
      "loss": 1.0682,
      "step": 83
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0007856115107913669,
      "loss": 1.1187,
      "step": 84
    },
    {
      "epoch": 0.18,
      "learning_rate": 0.0007949640287769783,
      "loss": 1.2014,
      "step": 85
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.00080431654676259,
      "loss": 0.9865,
      "step": 86
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0008136690647482014,
      "loss": 1.091,
      "step": 87
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0008230215827338129,
      "loss": 1.2124,
      "step": 88
    },
    {
      "epoch": 0.19,
      "learning_rate": 0.0008323741007194244,
      "loss": 1.0859,
      "step": 89
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0008417266187050359,
      "loss": 1.0628,
      "step": 90
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0008510791366906475,
      "loss": 1.0483,
      "step": 91
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.000860431654676259,
      "loss": 1.0506,
      "step": 92
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0008697841726618704,
      "loss": 1.1109,
      "step": 93
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.000879136690647482,
      "loss": 1.1309,
      "step": 94
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0008884892086330935,
      "loss": 1.0318,
      "step": 95
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.000897841726618705,
      "loss": 1.0856,
      "step": 96
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0009071942446043165,
      "loss": 1.0986,
      "step": 97
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0009165467625899279,
      "loss": 1.2011,
      "step": 98
    },
    {
      "epoch": 0.21,
      "learning_rate": 0.0009258992805755396,
      "loss": 1.1173,
      "step": 99
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.000935251798561151,
      "loss": 0.9711,
      "step": 100
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0009446043165467626,
      "loss": 1.1963,
      "step": 101
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.000953956834532374,
      "loss": 1.1418,
      "step": 102
    },
    {
      "epoch": 0.22,
      "learning_rate": 0.0009633093525179855,
      "loss": 1.1035,
      "step": 103
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.000972661870503597,
      "loss": 1.0508,
      "step": 104
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0009820143884892085,
      "loss": 1.2406,
      "step": 105
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0009913669064748202,
      "loss": 1.2676,
      "step": 106
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0010007194244604316,
      "loss": 1.0041,
      "step": 107
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.0010100719424460433,
      "loss": 1.0683,
      "step": 108
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0010194244604316547,
      "loss": 0.96,
      "step": 109
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0010287769784172662,
      "loss": 1.1417,
      "step": 110
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.0010381294964028776,
      "loss": 1.1725,
      "step": 111
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.001047482014388489,
      "loss": 1.0339,
      "step": 112
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0010568345323741007,
      "loss": 1.1103,
      "step": 113
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0010661870503597122,
      "loss": 1.1636,
      "step": 114
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0010755395683453236,
      "loss": 1.2039,
      "step": 115
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0010848920863309353,
      "loss": 1.0297,
      "step": 116
    },
    {
      "epoch": 0.25,
      "learning_rate": 0.0010942446043165467,
      "loss": 0.9883,
      "step": 117
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0011035971223021582,
      "loss": 1.1299,
      "step": 118
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0011129496402877696,
      "loss": 1.0625,
      "step": 119
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.001122302158273381,
      "loss": 0.97,
      "step": 120
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0011316546762589928,
      "loss": 1.106,
      "step": 121
    },
    {
      "epoch": 0.26,
      "learning_rate": 0.0011410071942446042,
      "loss": 1.0613,
      "step": 122
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0011503597122302159,
      "loss": 1.0713,
      "step": 123
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0011597122302158273,
      "loss": 1.0497,
      "step": 124
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0011690647482014388,
      "loss": 1.0726,
      "step": 125
    },
    {
      "epoch": 0.27,
      "learning_rate": 0.0011784172661870504,
      "loss": 1.1702,
      "step": 126
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001187769784172662,
      "loss": 1.0556,
      "step": 127
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0011971223021582733,
      "loss": 1.1059,
      "step": 128
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0012064748201438848,
      "loss": 1.1422,
      "step": 129
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.0012158273381294962,
      "loss": 1.1153,
      "step": 130
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.001225179856115108,
      "loss": 1.0321,
      "step": 131
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0012345323741007194,
      "loss": 0.9796,
      "step": 132
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.001243884892086331,
      "loss": 1.0049,
      "step": 133
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.0012532374100719425,
      "loss": 1.2594,
      "step": 134
    },
    {
      "epoch": 0.29,
      "learning_rate": 0.001262589928057554,
      "loss": 1.0506,
      "step": 135
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0012719424460431654,
      "loss": 1.2034,
      "step": 136
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0012812949640287768,
      "loss": 1.0769,
      "step": 137
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0012906474820143885,
      "loss": 0.9549,
      "step": 138
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.0013,
      "loss": 1.2036,
      "step": 139
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.001299399815327793,
      "loss": 1.0702,
      "step": 140
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0012987996306555864,
      "loss": 1.1891,
      "step": 141
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0012981994459833794,
      "loss": 1.2055,
      "step": 142
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0012975992613111725,
      "loss": 1.1347,
      "step": 143
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.0012969990766389659,
      "loss": 1.149,
      "step": 144
    },
    {
      "epoch": 0.31,
      "learning_rate": 0.001296398891966759,
      "loss": 0.9932,
      "step": 145
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.001295798707294552,
      "loss": 1.1006,
      "step": 146
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0012951985226223454,
      "loss": 1.0729,
      "step": 147
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0012945983379501385,
      "loss": 0.9918,
      "step": 148
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.0012939981532779318,
      "loss": 1.0741,
      "step": 149
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0012933979686057249,
      "loss": 1.0282,
      "step": 150
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001292797783933518,
      "loss": 1.1867,
      "step": 151
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.001292197599261311,
      "loss": 1.1903,
      "step": 152
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0012915974145891042,
      "loss": 1.2287,
      "step": 153
    },
    {
      "epoch": 0.33,
      "learning_rate": 0.0012909972299168975,
      "loss": 1.1473,
      "step": 154
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0012903970452446906,
      "loss": 1.2096,
      "step": 155
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0012897968605724837,
      "loss": 1.2171,
      "step": 156
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.001289196675900277,
      "loss": 1.025,
      "step": 157
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.00128859649122807,
      "loss": 1.2041,
      "step": 158
    },
    {
      "epoch": 0.34,
      "learning_rate": 0.0012879963065558632,
      "loss": 1.1285,
      "step": 159
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0012873961218836565,
      "loss": 1.0991,
      "step": 160
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0012867959372114496,
      "loss": 1.1859,
      "step": 161
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.0012861957525392427,
      "loss": 1.4186,
      "step": 162
    },
    {
      "epoch": 0.35,
      "learning_rate": 0.001285595567867036,
      "loss": 1.0389,
      "step": 163
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.001284995383194829,
      "loss": 1.1155,
      "step": 164
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0012843951985226222,
      "loss": 1.2565,
      "step": 165
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0012837950138504155,
      "loss": 1.1716,
      "step": 166
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0012831948291782086,
      "loss": 1.1576,
      "step": 167
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.0012825946445060017,
      "loss": 1.2736,
      "step": 168
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.001281994459833795,
      "loss": 1.0187,
      "step": 169
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0012813942751615881,
      "loss": 1.1219,
      "step": 170
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0012807940904893814,
      "loss": 1.1098,
      "step": 171
    },
    {
      "epoch": 0.37,
      "learning_rate": 0.0012801939058171745,
      "loss": 1.1928,
      "step": 172
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0012795937211449676,
      "loss": 0.9699,
      "step": 173
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001278993536472761,
      "loss": 1.3202,
      "step": 174
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.001278393351800554,
      "loss": 1.2311,
      "step": 175
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0012777931671283471,
      "loss": 0.9765,
      "step": 176
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0012771929824561402,
      "loss": 1.2321,
      "step": 177
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0012765927977839333,
      "loss": 1.1709,
      "step": 178
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0012759926131117266,
      "loss": 1.208,
      "step": 179
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0012753924284395197,
      "loss": 1.0949,
      "step": 180
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0012747922437673128,
      "loss": 1.1161,
      "step": 181
    },
    {
      "epoch": 0.39,
      "learning_rate": 0.0012741920590951061,
      "loss": 1.2859,
      "step": 182
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0012735918744228992,
      "loss": 1.13,
      "step": 183
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0012729916897506923,
      "loss": 1.0289,
      "step": 184
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0012723915050784856,
      "loss": 1.1045,
      "step": 185
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.0012717913204062787,
      "loss": 1.1493,
      "step": 186
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0012711911357340718,
      "loss": 1.0119,
      "step": 187
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0012705909510618652,
      "loss": 1.1736,
      "step": 188
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0012699907663896583,
      "loss": 1.0891,
      "step": 189
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0012693905817174516,
      "loss": 1.1558,
      "step": 190
    },
    {
      "epoch": 0.41,
      "learning_rate": 0.0012687903970452447,
      "loss": 1.1756,
      "step": 191
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0012681902123730378,
      "loss": 1.2697,
      "step": 192
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.001267590027700831,
      "loss": 1.1133,
      "step": 193
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0012669898430286242,
      "loss": 1.0344,
      "step": 194
    },
    {
      "epoch": 0.42,
      "learning_rate": 0.0012663896583564173,
      "loss": 1.0475,
      "step": 195
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0012657894736842106,
      "loss": 1.1299,
      "step": 196
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0012651892890120037,
      "loss": 1.2234,
      "step": 197
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0012645891043397968,
      "loss": 1.223,
      "step": 198
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.00126398891966759,
      "loss": 1.0936,
      "step": 199
    },
    {
      "epoch": 0.43,
      "learning_rate": 0.0012633887349953832,
      "loss": 1.2684,
      "step": 200
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0012627885503231763,
      "loss": 1.2257,
      "step": 201
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0012621883656509694,
      "loss": 1.0475,
      "step": 202
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0012615881809787625,
      "loss": 1.1738,
      "step": 203
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0012609879963065558,
      "loss": 1.195,
      "step": 204
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.0012603878116343489,
      "loss": 1.2046,
      "step": 205
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.001259787626962142,
      "loss": 1.1327,
      "step": 206
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0012591874422899353,
      "loss": 1.078,
      "step": 207
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0012585872576177284,
      "loss": 1.1013,
      "step": 208
    },
    {
      "epoch": 0.45,
      "learning_rate": 0.0012579870729455217,
      "loss": 1.165,
      "step": 209
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0012573868882733148,
      "loss": 1.0454,
      "step": 210
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.001256786703601108,
      "loss": 1.0444,
      "step": 211
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0012561865189289012,
      "loss": 1.2352,
      "step": 212
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0012555863342566943,
      "loss": 1.1794,
      "step": 213
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.0012549861495844874,
      "loss": 1.3649,
      "step": 214
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0012543859649122807,
      "loss": 1.1408,
      "step": 215
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0012537857802400738,
      "loss": 1.1899,
      "step": 216
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.001253185595567867,
      "loss": 1.2234,
      "step": 217
    },
    {
      "epoch": 0.47,
      "learning_rate": 0.0012525854108956602,
      "loss": 1.1675,
      "step": 218
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0012519852262234533,
      "loss": 1.0834,
      "step": 219
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0012513850415512464,
      "loss": 1.2582,
      "step": 220
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0012507848568790397,
      "loss": 1.0384,
      "step": 221
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.0012501846722068328,
      "loss": 1.1682,
      "step": 222
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.001249584487534626,
      "loss": 1.1419,
      "step": 223
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0012489843028624192,
      "loss": 1.0909,
      "step": 224
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0012483841181902123,
      "loss": 1.0248,
      "step": 225
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0012477839335180054,
      "loss": 1.235,
      "step": 226
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0012471837488457988,
      "loss": 1.0166,
      "step": 227
    },
    {
      "epoch": 0.49,
      "learning_rate": 0.0012465835641735919,
      "loss": 1.0308,
      "step": 228
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001245983379501385,
      "loss": 1.1164,
      "step": 229
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.001245383194829178,
      "loss": 1.277,
      "step": 230
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0012447830101569714,
      "loss": 1.2334,
      "step": 231
    },
    {
      "epoch": 0.5,
      "learning_rate": 0.0012441828254847645,
      "loss": 1.1953,
      "step": 232
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0012435826408125576,
      "loss": 1.1771,
      "step": 233
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0012429824561403509,
      "loss": 1.1461,
      "step": 234
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001242382271468144,
      "loss": 1.2284,
      "step": 235
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.001241782086795937,
      "loss": 1.1795,
      "step": 236
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.0012411819021237304,
      "loss": 1.1077,
      "step": 237
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0012405817174515235,
      "loss": 1.2034,
      "step": 238
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0012399815327793166,
      "loss": 1.1398,
      "step": 239
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.0012393813481071099,
      "loss": 1.1431,
      "step": 240
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.001238781163434903,
      "loss": 1.0613,
      "step": 241
    },
    {
      "epoch": 0.52,
      "learning_rate": 0.001238180978762696,
      "loss": 1.1703,
      "step": 242
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0012375807940904894,
      "loss": 1.2643,
      "step": 243
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0012369806094182825,
      "loss": 1.117,
      "step": 244
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.0012363804247460756,
      "loss": 1.2319,
      "step": 245
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.001235780240073869,
      "loss": 1.3612,
      "step": 246
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.001235180055401662,
      "loss": 1.1784,
      "step": 247
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0012345798707294553,
      "loss": 1.2135,
      "step": 248
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0012339796860572484,
      "loss": 1.2236,
      "step": 249
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0012333795013850415,
      "loss": 0.9652,
      "step": 250
    },
    {
      "epoch": 0.54,
      "learning_rate": 0.0012327793167128348,
      "loss": 1.1314,
      "step": 251
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001232179132040628,
      "loss": 1.14,
      "step": 252
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001231578947368421,
      "loss": 1.1554,
      "step": 253
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.001230978762696214,
      "loss": 1.115,
      "step": 254
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.0012303785780240072,
      "loss": 1.3273,
      "step": 255
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0012297783933518005,
      "loss": 1.053,
      "step": 256
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0012291782086795936,
      "loss": 1.007,
      "step": 257
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0012285780240073867,
      "loss": 1.0124,
      "step": 258
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.00122797783933518,
      "loss": 1.1531,
      "step": 259
    },
    {
      "epoch": 0.56,
      "learning_rate": 0.0012273776546629731,
      "loss": 1.1695,
      "step": 260
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0012267774699907662,
      "loss": 1.1992,
      "step": 261
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0012261772853185595,
      "loss": 1.1775,
      "step": 262
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0012255771006463526,
      "loss": 1.1634,
      "step": 263
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.0012249769159741457,
      "loss": 1.1114,
      "step": 264
    },
    {
      "epoch": 0.57,
      "learning_rate": 0.001224376731301939,
      "loss": 1.1144,
      "step": 265
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0012237765466297321,
      "loss": 1.079,
      "step": 266
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0012231763619575254,
      "loss": 1.0368,
      "step": 267
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0012225761772853185,
      "loss": 1.2004,
      "step": 268
    },
    {
      "epoch": 0.58,
      "learning_rate": 0.0012219759926131116,
      "loss": 1.2174,
      "step": 269
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.001221375807940905,
      "loss": 1.1251,
      "step": 270
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.001220775623268698,
      "loss": 1.2277,
      "step": 271
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0012201754385964911,
      "loss": 1.315,
      "step": 272
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0012195752539242845,
      "loss": 1.1199,
      "step": 273
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.0012189750692520776,
      "loss": 1.1988,
      "step": 274
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0012183748845798707,
      "loss": 1.2042,
      "step": 275
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001217774699907664,
      "loss": 1.0932,
      "step": 276
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.001217174515235457,
      "loss": 1.2307,
      "step": 277
    },
    {
      "epoch": 0.6,
      "learning_rate": 0.0012165743305632502,
      "loss": 1.3008,
      "step": 278
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0012159741458910433,
      "loss": 1.2368,
      "step": 279
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0012153739612188364,
      "loss": 1.0918,
      "step": 280
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0012147737765466297,
      "loss": 1.2661,
      "step": 281
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0012141735918744228,
      "loss": 1.0637,
      "step": 282
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.0012135734072022159,
      "loss": 1.1527,
      "step": 283
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0012129732225300092,
      "loss": 1.237,
      "step": 284
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0012123730378578023,
      "loss": 1.2957,
      "step": 285
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0012117728531855956,
      "loss": 1.1416,
      "step": 286
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0012111726685133887,
      "loss": 1.2746,
      "step": 287
    },
    {
      "epoch": 0.62,
      "learning_rate": 0.0012105724838411818,
      "loss": 1.1758,
      "step": 288
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.001209972299168975,
      "loss": 1.1194,
      "step": 289
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0012093721144967682,
      "loss": 1.2158,
      "step": 290
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0012087719298245613,
      "loss": 1.1331,
      "step": 291
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.0012081717451523546,
      "loss": 1.247,
      "step": 292
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0012075715604801477,
      "loss": 0.9578,
      "step": 293
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0012069713758079408,
      "loss": 1.0113,
      "step": 294
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0012063711911357341,
      "loss": 1.0545,
      "step": 295
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0012057710064635272,
      "loss": 1.2253,
      "step": 296
    },
    {
      "epoch": 0.64,
      "learning_rate": 0.0012051708217913203,
      "loss": 1.2403,
      "step": 297
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0012045706371191136,
      "loss": 1.1281,
      "step": 298
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0012039704524469067,
      "loss": 1.1615,
      "step": 299
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0012033702677746998,
      "loss": 1.2905,
      "step": 300
    },
    {
      "epoch": 0.65,
      "learning_rate": 0.0012027700831024931,
      "loss": 1.2748,
      "step": 301
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0012021698984302862,
      "loss": 1.0944,
      "step": 302
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0012015697137580793,
      "loss": 1.1062,
      "step": 303
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0012009695290858724,
      "loss": 1.0824,
      "step": 304
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0012003693444136657,
      "loss": 1.2062,
      "step": 305
    },
    {
      "epoch": 0.66,
      "learning_rate": 0.0011997691597414588,
      "loss": 1.2599,
      "step": 306
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.001199168975069252,
      "loss": 1.2949,
      "step": 307
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0011985687903970452,
      "loss": 1.1586,
      "step": 308
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0011979686057248383,
      "loss": 1.1871,
      "step": 309
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0011973684210526314,
      "loss": 1.1544,
      "step": 310
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.0011967682363804247,
      "loss": 1.158,
      "step": 311
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0011961680517082178,
      "loss": 1.2425,
      "step": 312
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.001195567867036011,
      "loss": 1.1424,
      "step": 313
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0011949676823638043,
      "loss": 1.1432,
      "step": 314
    },
    {
      "epoch": 0.68,
      "learning_rate": 0.0011943674976915974,
      "loss": 1.1143,
      "step": 315
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0011937673130193904,
      "loss": 1.0563,
      "step": 316
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0011931671283471838,
      "loss": 1.1382,
      "step": 317
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0011925669436749769,
      "loss": 1.1714,
      "step": 318
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00119196675900277,
      "loss": 1.0569,
      "step": 319
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.0011913665743305633,
      "loss": 1.232,
      "step": 320
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0011907663896583564,
      "loss": 1.1046,
      "step": 321
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0011901662049861495,
      "loss": 1.2025,
      "step": 322
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0011895660203139428,
      "loss": 1.1316,
      "step": 323
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0011889658356417359,
      "loss": 1.08,
      "step": 324
    },
    {
      "epoch": 0.7,
      "learning_rate": 0.0011883656509695292,
      "loss": 1.1962,
      "step": 325
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0011877654662973223,
      "loss": 1.093,
      "step": 326
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0011871652816251154,
      "loss": 1.1397,
      "step": 327
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0011865650969529085,
      "loss": 0.9596,
      "step": 328
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.0011859649122807016,
      "loss": 1.1483,
      "step": 329
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0011853647276084949,
      "loss": 1.0534,
      "step": 330
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.001184764542936288,
      "loss": 1.1016,
      "step": 331
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.001184164358264081,
      "loss": 1.2302,
      "step": 332
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0011835641735918744,
      "loss": 1.2133,
      "step": 333
    },
    {
      "epoch": 0.72,
      "learning_rate": 0.0011829639889196675,
      "loss": 1.1269,
      "step": 334
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.0011823638042474606,
      "loss": 1.1641,
      "step": 335
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001181763619575254,
      "loss": 1.0845,
      "step": 336
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.001181163434903047,
      "loss": 1.1047,
      "step": 337
    },
    {
      "epoch": 0.73,
      "learning_rate": 0.00118056325023084,
      "loss": 1.232,
      "step": 338
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0011799630655586334,
      "loss": 1.196,
      "step": 339
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0011793628808864265,
      "loss": 1.1077,
      "step": 340
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.0011787626962142196,
      "loss": 1.1426,
      "step": 341
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.001178162511542013,
      "loss": 1.1683,
      "step": 342
    },
    {
      "epoch": 0.74,
      "learning_rate": 0.001177562326869806,
      "loss": 0.9995,
      "step": 343
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0011769621421975993,
      "loss": 1.0885,
      "step": 344
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0011763619575253924,
      "loss": 1.0927,
      "step": 345
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0011757617728531855,
      "loss": 1.182,
      "step": 346
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.0011751615881809788,
      "loss": 1.1456,
      "step": 347
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.001174561403508772,
      "loss": 1.2535,
      "step": 348
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.001173961218836565,
      "loss": 1.2176,
      "step": 349
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0011733610341643583,
      "loss": 1.1901,
      "step": 350
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0011727608494921514,
      "loss": 1.1409,
      "step": 351
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0011721606648199445,
      "loss": 1.1208,
      "step": 352
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0011715604801477379,
      "loss": 1.1412,
      "step": 353
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0011709602954755307,
      "loss": 1.2627,
      "step": 354
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.001170360110803324,
      "loss": 1.1702,
      "step": 355
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0011697599261311171,
      "loss": 1.0219,
      "step": 356
    },
    {
      "epoch": 0.77,
      "learning_rate": 0.0011691597414589102,
      "loss": 1.0785,
      "step": 357
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0011685595567867036,
      "loss": 1.1997,
      "step": 358
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0011679593721144966,
      "loss": 1.2562,
      "step": 359
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.0011673591874422897,
      "loss": 1.15,
      "step": 360
    },
    {
      "epoch": 0.78,
      "learning_rate": 0.001166759002770083,
      "loss": 1.0871,
      "step": 361
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0011661588180978762,
      "loss": 1.1359,
      "step": 362
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0011655586334256695,
      "loss": 0.9968,
      "step": 363
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0011649584487534626,
      "loss": 1.1672,
      "step": 364
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.0011643582640812557,
      "loss": 1.1391,
      "step": 365
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.001163758079409049,
      "loss": 1.2439,
      "step": 366
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.001163157894736842,
      "loss": 1.0967,
      "step": 367
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0011625577100646352,
      "loss": 1.332,
      "step": 368
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0011619575253924285,
      "loss": 1.2318,
      "step": 369
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0011613573407202216,
      "loss": 1.0062,
      "step": 370
    },
    {
      "epoch": 0.8,
      "learning_rate": 0.0011607571560480147,
      "loss": 1.2245,
      "step": 371
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001160156971375808,
      "loss": 1.005,
      "step": 372
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.001159556786703601,
      "loss": 1.075,
      "step": 373
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0011589566020313942,
      "loss": 1.1729,
      "step": 374
    },
    {
      "epoch": 0.81,
      "learning_rate": 0.0011583564173591875,
      "loss": 1.0454,
      "step": 375
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0011577562326869806,
      "loss": 1.3027,
      "step": 376
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0011571560480147737,
      "loss": 1.152,
      "step": 377
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.001156555863342567,
      "loss": 1.0066,
      "step": 378
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0011559556786703599,
      "loss": 0.9589,
      "step": 379
    },
    {
      "epoch": 0.82,
      "learning_rate": 0.0011553554939981532,
      "loss": 1.1316,
      "step": 380
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0011547553093259463,
      "loss": 1.0092,
      "step": 381
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0011541551246537396,
      "loss": 1.0527,
      "step": 382
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0011535549399815327,
      "loss": 0.9516,
      "step": 383
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.0011529547553093258,
      "loss": 1.1484,
      "step": 384
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0011523545706371191,
      "loss": 1.1536,
      "step": 385
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0011517543859649122,
      "loss": 1.271,
      "step": 386
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0011511542012927053,
      "loss": 1.18,
      "step": 387
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0011505540166204986,
      "loss": 1.1021,
      "step": 388
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.0011499538319482917,
      "loss": 0.9804,
      "step": 389
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0011493536472760848,
      "loss": 1.1876,
      "step": 390
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0011487534626038781,
      "loss": 1.0686,
      "step": 391
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0011481532779316712,
      "loss": 1.1569,
      "step": 392
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0011475530932594643,
      "loss": 1.067,
      "step": 393
    },
    {
      "epoch": 0.85,
      "learning_rate": 0.0011469529085872576,
      "loss": 1.2509,
      "step": 394
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0011463527239150507,
      "loss": 1.0336,
      "step": 395
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0011457525392428438,
      "loss": 1.1889,
      "step": 396
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0011451523545706371,
      "loss": 1.1227,
      "step": 397
    },
    {
      "epoch": 0.86,
      "learning_rate": 0.0011445521698984302,
      "loss": 1.2669,
      "step": 398
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0011439519852262233,
      "loss": 1.1268,
      "step": 399
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0011433518005540167,
      "loss": 1.2895,
      "step": 400
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0011427516158818098,
      "loss": 1.156,
      "step": 401
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.001142151431209603,
      "loss": 1.2279,
      "step": 402
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.0011415512465373962,
      "loss": 1.2044,
      "step": 403
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0011409510618651893,
      "loss": 0.9976,
      "step": 404
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0011403508771929824,
      "loss": 1.0961,
      "step": 405
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0011397506925207755,
      "loss": 1.0584,
      "step": 406
    },
    {
      "epoch": 0.88,
      "learning_rate": 0.0011391505078485688,
      "loss": 1.0221,
      "step": 407
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0011385503231763619,
      "loss": 1.1594,
      "step": 408
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.001137950138504155,
      "loss": 0.987,
      "step": 409
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0011373499538319483,
      "loss": 1.2697,
      "step": 410
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0011367497691597414,
      "loss": 1.1378,
      "step": 411
    },
    {
      "epoch": 0.89,
      "learning_rate": 0.0011361495844875345,
      "loss": 1.204,
      "step": 412
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0011355493998153278,
      "loss": 1.1196,
      "step": 413
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0011349492151431209,
      "loss": 1.2048,
      "step": 414
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.001134349030470914,
      "loss": 1.2899,
      "step": 415
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0011337488457987073,
      "loss": 1.0167,
      "step": 416
    },
    {
      "epoch": 0.9,
      "learning_rate": 0.0011331486611265004,
      "loss": 1.2774,
      "step": 417
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011325484764542935,
      "loss": 1.2585,
      "step": 418
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011319482917820868,
      "loss": 1.0397,
      "step": 419
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00113134810710988,
      "loss": 1.0102,
      "step": 420
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.0011307479224376732,
      "loss": 1.0858,
      "step": 421
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011301477377654663,
      "loss": 1.2069,
      "step": 422
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011295475530932594,
      "loss": 1.0057,
      "step": 423
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011289473684210527,
      "loss": 1.1286,
      "step": 424
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.0011283471837488458,
      "loss": 1.1245,
      "step": 425
    },
    {
      "epoch": 0.92,
      "learning_rate": 0.001127746999076639,
      "loss": 1.264,
      "step": 426
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011271468144044322,
      "loss": 1.1137,
      "step": 427
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011265466297322253,
      "loss": 0.9998,
      "step": 428
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011259464450600184,
      "loss": 1.1359,
      "step": 429
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011253462603878115,
      "loss": 1.0911,
      "step": 430
    },
    {
      "epoch": 0.93,
      "learning_rate": 0.0011247460757156046,
      "loss": 1.2212,
      "step": 431
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.001124145891043398,
      "loss": 1.211,
      "step": 432
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.001123545706371191,
      "loss": 1.2091,
      "step": 433
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011229455216989841,
      "loss": 1.2108,
      "step": 434
    },
    {
      "epoch": 0.94,
      "learning_rate": 0.0011223453370267774,
      "loss": 1.1985,
      "step": 435
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011217451523545705,
      "loss": 1.0779,
      "step": 436
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011211449676823636,
      "loss": 1.1247,
      "step": 437
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.001120544783010157,
      "loss": 1.017,
      "step": 438
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00111994459833795,
      "loss": 1.1368,
      "step": 439
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.0011193444136657434,
      "loss": 1.1291,
      "step": 440
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011187442289935364,
      "loss": 1.1203,
      "step": 441
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011181440443213295,
      "loss": 1.0176,
      "step": 442
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0011175438596491229,
      "loss": 1.1104,
      "step": 443
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.001116943674976916,
      "loss": 1.0757,
      "step": 444
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.001116343490304709,
      "loss": 1.0614,
      "step": 445
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011157433056325024,
      "loss": 1.1382,
      "step": 446
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011151431209602955,
      "loss": 1.1724,
      "step": 447
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011145429362880886,
      "loss": 1.0037,
      "step": 448
    },
    {
      "epoch": 0.97,
      "learning_rate": 0.0011139427516158819,
      "loss": 1.2535,
      "step": 449
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.001113342566943675,
      "loss": 1.0388,
      "step": 450
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.001112742382271468,
      "loss": 1.1391,
      "step": 451
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0011121421975992614,
      "loss": 1.1561,
      "step": 452
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0011115420129270545,
      "loss": 1.1392,
      "step": 453
    },
    {
      "epoch": 0.98,
      "learning_rate": 0.0011109418282548476,
      "loss": 1.0341,
      "step": 454
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0011103416435826407,
      "loss": 1.1371,
      "step": 455
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0011097414589104338,
      "loss": 1.0508,
      "step": 456
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.001109141274238227,
      "loss": 1.2498,
      "step": 457
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.0011085410895660202,
      "loss": 1.0712,
      "step": 458
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0011079409048938135,
      "loss": 1.2022,
      "step": 459
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0011073407202216066,
      "loss": 1.0812,
      "step": 460
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.0011067405355493997,
      "loss": 1.1283,
      "step": 461
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.001106140350877193,
      "loss": 1.1037,
      "step": 462
    },
    {
      "epoch": 1.0,
      "learning_rate": 0.001105540166204986,
      "loss": 0.9957,
      "step": 463
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0011049399815327792,
      "loss": 1.03,
      "step": 464
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0011043397968605725,
      "loss": 1.075,
      "step": 465
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0011037396121883656,
      "loss": 1.1496,
      "step": 466
    },
    {
      "epoch": 1.01,
      "learning_rate": 0.0011031394275161587,
      "loss": 1.1339,
      "step": 467
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.001102539242843952,
      "loss": 1.1911,
      "step": 468
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0011019390581717451,
      "loss": 1.2329,
      "step": 469
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0011013388734995382,
      "loss": 0.9935,
      "step": 470
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0011007386888273315,
      "loss": 1.1093,
      "step": 471
    },
    {
      "epoch": 1.02,
      "learning_rate": 0.0011001385041551246,
      "loss": 1.191,
      "step": 472
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010995383194829177,
      "loss": 1.0819,
      "step": 473
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.001098938134810711,
      "loss": 1.087,
      "step": 474
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010983379501385041,
      "loss": 1.0345,
      "step": 475
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010977377654662972,
      "loss": 1.2097,
      "step": 476
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.0010971375807940905,
      "loss": 0.9988,
      "step": 477
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0010965373961218836,
      "loss": 0.9919,
      "step": 478
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.001095937211449677,
      "loss": 1.0965,
      "step": 479
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0010953370267774698,
      "loss": 0.995,
      "step": 480
    },
    {
      "epoch": 1.04,
      "learning_rate": 0.0010947368421052631,
      "loss": 1.3269,
      "step": 481
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0010941366574330562,
      "loss": 0.9912,
      "step": 482
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0010935364727608493,
      "loss": 1.121,
      "step": 483
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0010929362880886426,
      "loss": 1.0004,
      "step": 484
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0010923361034164357,
      "loss": 1.2057,
      "step": 485
    },
    {
      "epoch": 1.05,
      "learning_rate": 0.0010917359187442288,
      "loss": 0.9967,
      "step": 486
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0010911357340720222,
      "loss": 1.0161,
      "step": 487
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0010905355493998153,
      "loss": 1.1293,
      "step": 488
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0010899353647276084,
      "loss": 0.9395,
      "step": 489
    },
    {
      "epoch": 1.06,
      "learning_rate": 0.0010893351800554017,
      "loss": 1.0353,
      "step": 490
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0010887349953831948,
      "loss": 1.0134,
      "step": 491
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0010881348107109879,
      "loss": 1.0417,
      "step": 492
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0010875346260387812,
      "loss": 1.007,
      "step": 493
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0010869344413665743,
      "loss": 1.192,
      "step": 494
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.0010863342566943674,
      "loss": 1.0469,
      "step": 495
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0010857340720221607,
      "loss": 1.0272,
      "step": 496
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0010851338873499538,
      "loss": 1.0308,
      "step": 497
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.001084533702677747,
      "loss": 1.0092,
      "step": 498
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0010839335180055402,
      "loss": 1.1336,
      "step": 499
    },
    {
      "epoch": 1.08,
      "learning_rate": 0.0010833333333333333,
      "loss": 1.0585,
      "step": 500
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0010827331486611266,
      "loss": 1.0661,
      "step": 501
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0010821329639889197,
      "loss": 1.1189,
      "step": 502
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.0010815327793167128,
      "loss": 1.1398,
      "step": 503
    },
    {
      "epoch": 1.09,
      "learning_rate": 0.001080932594644506,
      "loss": 1.0668,
      "step": 504
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.001080332409972299,
      "loss": 1.0481,
      "step": 505
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0010797322253000923,
      "loss": 1.0989,
      "step": 506
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0010791320406278854,
      "loss": 0.9214,
      "step": 507
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0010785318559556785,
      "loss": 1.1024,
      "step": 508
    },
    {
      "epoch": 1.1,
      "learning_rate": 0.0010779316712834718,
      "loss": 0.9561,
      "step": 509
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.001077331486611265,
      "loss": 1.0804,
      "step": 510
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.001076731301939058,
      "loss": 1.1631,
      "step": 511
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0010761311172668513,
      "loss": 1.2255,
      "step": 512
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0010755309325946444,
      "loss": 1.061,
      "step": 513
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.0010749307479224375,
      "loss": 1.0709,
      "step": 514
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0010743305632502308,
      "loss": 0.9468,
      "step": 515
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.001073730378578024,
      "loss": 1.0035,
      "step": 516
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0010731301939058172,
      "loss": 1.0798,
      "step": 517
    },
    {
      "epoch": 1.12,
      "learning_rate": 0.0010725300092336103,
      "loss": 0.9981,
      "step": 518
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0010719298245614034,
      "loss": 1.1342,
      "step": 519
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0010713296398891967,
      "loss": 1.092,
      "step": 520
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0010707294552169898,
      "loss": 0.9948,
      "step": 521
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.001070129270544783,
      "loss": 1.2027,
      "step": 522
    },
    {
      "epoch": 1.13,
      "learning_rate": 0.0010695290858725762,
      "loss": 1.152,
      "step": 523
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0010689289012003693,
      "loss": 1.1333,
      "step": 524
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0010683287165281624,
      "loss": 1.1318,
      "step": 525
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0010677285318559558,
      "loss": 1.0027,
      "step": 526
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0010671283471837489,
      "loss": 1.166,
      "step": 527
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.001066528162511542,
      "loss": 0.9263,
      "step": 528
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0010659279778393353,
      "loss": 1.1172,
      "step": 529
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0010653277931671281,
      "loss": 1.2085,
      "step": 530
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0010647276084949215,
      "loss": 0.9616,
      "step": 531
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.0010641274238227146,
      "loss": 1.0333,
      "step": 532
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0010635272391505076,
      "loss": 1.0146,
      "step": 533
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.001062927054478301,
      "loss": 1.1233,
      "step": 534
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.001062326869806094,
      "loss": 1.2255,
      "step": 535
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0010617266851338874,
      "loss": 1.0559,
      "step": 536
    },
    {
      "epoch": 1.16,
      "learning_rate": 0.0010611265004616805,
      "loss": 1.0354,
      "step": 537
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0010605263157894736,
      "loss": 1.1484,
      "step": 538
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.0010599261311172669,
      "loss": 0.8835,
      "step": 539
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.00105932594644506,
      "loss": 1.0298,
      "step": 540
    },
    {
      "epoch": 1.17,
      "learning_rate": 0.001058725761772853,
      "loss": 1.1269,
      "step": 541
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0010581255771006464,
      "loss": 1.0368,
      "step": 542
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0010575253924284395,
      "loss": 1.0476,
      "step": 543
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.0010569252077562326,
      "loss": 1.0145,
      "step": 544
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.001056325023084026,
      "loss": 1.1885,
      "step": 545
    },
    {
      "epoch": 1.18,
      "learning_rate": 0.001055724838411819,
      "loss": 1.2006,
      "step": 546
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.001055124653739612,
      "loss": 0.9447,
      "step": 547
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0010545244690674054,
      "loss": 1.1562,
      "step": 548
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0010539242843951985,
      "loss": 1.084,
      "step": 549
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.0010533240997229916,
      "loss": 0.9986,
      "step": 550
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.001052723915050785,
      "loss": 1.1558,
      "step": 551
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.001052123730378578,
      "loss": 1.199,
      "step": 552
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.001051523545706371,
      "loss": 0.9681,
      "step": 553
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0010509233610341644,
      "loss": 1.017,
      "step": 554
    },
    {
      "epoch": 1.2,
      "learning_rate": 0.0010503231763619575,
      "loss": 1.1307,
      "step": 555
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0010497229916897506,
      "loss": 1.0862,
      "step": 556
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0010491228070175437,
      "loss": 1.0184,
      "step": 557
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.001048522622345337,
      "loss": 1.0868,
      "step": 558
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0010479224376731301,
      "loss": 1.0905,
      "step": 559
    },
    {
      "epoch": 1.21,
      "learning_rate": 0.0010473222530009232,
      "loss": 1.1714,
      "step": 560
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0010467220683287165,
      "loss": 0.8481,
      "step": 561
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0010461218836565096,
      "loss": 0.9214,
      "step": 562
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.0010455216989843027,
      "loss": 1.051,
      "step": 563
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.001044921514312096,
      "loss": 1.0658,
      "step": 564
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0010443213296398891,
      "loss": 1.0188,
      "step": 565
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0010437211449676822,
      "loss": 0.9773,
      "step": 566
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0010431209602954755,
      "loss": 1.1339,
      "step": 567
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0010425207756232686,
      "loss": 1.0847,
      "step": 568
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.0010419205909510617,
      "loss": 1.0914,
      "step": 569
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.001041320406278855,
      "loss": 1.0835,
      "step": 570
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0010407202216066481,
      "loss": 1.263,
      "step": 571
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0010401200369344412,
      "loss": 1.1236,
      "step": 572
    },
    {
      "epoch": 1.24,
      "learning_rate": 0.0010395198522622346,
      "loss": 1.0399,
      "step": 573
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0010389196675900277,
      "loss": 1.1565,
      "step": 574
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.001038319482917821,
      "loss": 1.0793,
      "step": 575
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.001037719298245614,
      "loss": 1.0818,
      "step": 576
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0010371191135734072,
      "loss": 1.0082,
      "step": 577
    },
    {
      "epoch": 1.25,
      "learning_rate": 0.0010365189289012005,
      "loss": 1.0587,
      "step": 578
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0010359187442289936,
      "loss": 0.9881,
      "step": 579
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0010353185595567867,
      "loss": 1.0818,
      "step": 580
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0010347183748845798,
      "loss": 1.0235,
      "step": 581
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0010341181902123729,
      "loss": 1.0305,
      "step": 582
    },
    {
      "epoch": 1.26,
      "learning_rate": 0.0010335180055401662,
      "loss": 1.0364,
      "step": 583
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0010329178208679593,
      "loss": 0.9642,
      "step": 584
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0010323176361957524,
      "loss": 1.2092,
      "step": 585
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0010317174515235457,
      "loss": 1.048,
      "step": 586
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.0010311172668513388,
      "loss": 1.1596,
      "step": 587
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0010305170821791319,
      "loss": 1.0409,
      "step": 588
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0010299168975069252,
      "loss": 1.1615,
      "step": 589
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0010293167128347183,
      "loss": 1.1843,
      "step": 590
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0010287165281625114,
      "loss": 1.1453,
      "step": 591
    },
    {
      "epoch": 1.28,
      "learning_rate": 0.0010281163434903047,
      "loss": 1.1134,
      "step": 592
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0010275161588180978,
      "loss": 1.0361,
      "step": 593
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0010269159741458911,
      "loss": 0.9988,
      "step": 594
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0010263157894736842,
      "loss": 1.0626,
      "step": 595
    },
    {
      "epoch": 1.29,
      "learning_rate": 0.0010257156048014773,
      "loss": 1.1254,
      "step": 596
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0010251154201292706,
      "loss": 1.1026,
      "step": 597
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0010245152354570637,
      "loss": 1.0552,
      "step": 598
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0010239150507848568,
      "loss": 0.9412,
      "step": 599
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0010233148661126501,
      "loss": 1.1704,
      "step": 600
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.0010227146814404432,
      "loss": 1.1084,
      "step": 601
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0010221144967682363,
      "loss": 1.1079,
      "step": 602
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0010215143120960296,
      "loss": 0.9412,
      "step": 603
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0010209141274238227,
      "loss": 0.978,
      "step": 604
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.0010203139427516158,
      "loss": 1.0657,
      "step": 605
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.001019713758079409,
      "loss": 1.1728,
      "step": 606
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.001019113573407202,
      "loss": 1.1925,
      "step": 607
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0010185133887349953,
      "loss": 1.0371,
      "step": 608
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0010179132040627884,
      "loss": 1.1108,
      "step": 609
    },
    {
      "epoch": 1.32,
      "learning_rate": 0.0010173130193905815,
      "loss": 0.9411,
      "step": 610
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0010167128347183748,
      "loss": 1.0334,
      "step": 611
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.001016112650046168,
      "loss": 1.0656,
      "step": 612
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0010155124653739613,
      "loss": 1.0283,
      "step": 613
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0010149122807017544,
      "loss": 1.0283,
      "step": 614
    },
    {
      "epoch": 1.33,
      "learning_rate": 0.0010143120960295474,
      "loss": 1.1721,
      "step": 615
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0010137119113573408,
      "loss": 1.1035,
      "step": 616
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0010131117266851339,
      "loss": 1.0123,
      "step": 617
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.001012511542012927,
      "loss": 1.2537,
      "step": 618
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0010119113573407203,
      "loss": 1.0387,
      "step": 619
    },
    {
      "epoch": 1.34,
      "learning_rate": 0.0010113111726685134,
      "loss": 1.0582,
      "step": 620
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0010107109879963065,
      "loss": 1.0426,
      "step": 621
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0010101108033240998,
      "loss": 1.0843,
      "step": 622
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.0010095106186518929,
      "loss": 1.0468,
      "step": 623
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.001008910433979686,
      "loss": 1.0962,
      "step": 624
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0010083102493074793,
      "loss": 1.0201,
      "step": 625
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0010077100646352724,
      "loss": 1.0446,
      "step": 626
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0010071098799630655,
      "loss": 1.0886,
      "step": 627
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0010065096952908588,
      "loss": 1.2546,
      "step": 628
    },
    {
      "epoch": 1.36,
      "learning_rate": 0.0010059095106186519,
      "loss": 1.0144,
      "step": 629
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.001005309325946445,
      "loss": 1.0085,
      "step": 630
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.001004709141274238,
      "loss": 1.2072,
      "step": 631
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0010041089566020312,
      "loss": 1.022,
      "step": 632
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.0010035087719298245,
      "loss": 1.0803,
      "step": 633
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0010029085872576176,
      "loss": 1.0215,
      "step": 634
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.001002308402585411,
      "loss": 1.0482,
      "step": 635
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.001001708217913204,
      "loss": 1.0423,
      "step": 636
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.001001108033240997,
      "loss": 1.1393,
      "step": 637
    },
    {
      "epoch": 1.38,
      "learning_rate": 0.0010005078485687904,
      "loss": 1.1546,
      "step": 638
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0009999076638965835,
      "loss": 1.0915,
      "step": 639
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0009993074792243766,
      "loss": 1.02,
      "step": 640
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00099870729455217,
      "loss": 1.1268,
      "step": 641
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.000998107109879963,
      "loss": 1.1249,
      "step": 642
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.0009975069252077561,
      "loss": 1.0851,
      "step": 643
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0009969067405355494,
      "loss": 1.1927,
      "step": 644
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0009963065558633425,
      "loss": 1.0541,
      "step": 645
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.0009957063711911356,
      "loss": 1.1134,
      "step": 646
    },
    {
      "epoch": 1.4,
      "learning_rate": 0.000995106186518929,
      "loss": 1.1196,
      "step": 647
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.000994506001846722,
      "loss": 1.2002,
      "step": 648
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0009939058171745151,
      "loss": 1.0914,
      "step": 649
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0009933056325023084,
      "loss": 1.0945,
      "step": 650
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0009927054478301015,
      "loss": 1.2664,
      "step": 651
    },
    {
      "epoch": 1.41,
      "learning_rate": 0.0009921052631578949,
      "loss": 0.9803,
      "step": 652
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.000991505078485688,
      "loss": 1.0177,
      "step": 653
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.000990904893813481,
      "loss": 1.0521,
      "step": 654
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0009903047091412744,
      "loss": 1.1006,
      "step": 655
    },
    {
      "epoch": 1.42,
      "learning_rate": 0.0009897045244690672,
      "loss": 1.0895,
      "step": 656
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0009891043397968606,
      "loss": 1.0741,
      "step": 657
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0009885041551246536,
      "loss": 0.9718,
      "step": 658
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0009879039704524467,
      "loss": 0.8912,
      "step": 659
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00098730378578024,
      "loss": 1.0614,
      "step": 660
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.0009867036011080332,
      "loss": 1.0371,
      "step": 661
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0009861034164358263,
      "loss": 1.1949,
      "step": 662
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0009855032317636196,
      "loss": 1.1327,
      "step": 663
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0009849030470914127,
      "loss": 1.0809,
      "step": 664
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0009843028624192058,
      "loss": 1.1167,
      "step": 665
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.000983702677746999,
      "loss": 1.0615,
      "step": 666
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0009831024930747922,
      "loss": 1.1781,
      "step": 667
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0009825023084025853,
      "loss": 1.1211,
      "step": 668
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0009819021237303786,
      "loss": 1.028,
      "step": 669
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.0009813019390581717,
      "loss": 1.1123,
      "step": 670
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.000980701754385965,
      "loss": 1.1046,
      "step": 671
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.000980101569713758,
      "loss": 0.9339,
      "step": 672
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0009795013850415512,
      "loss": 1.0105,
      "step": 673
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0009789012003693445,
      "loss": 1.1798,
      "step": 674
    },
    {
      "epoch": 1.46,
      "learning_rate": 0.0009783010156971376,
      "loss": 1.0102,
      "step": 675
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0009777008310249307,
      "loss": 0.9023,
      "step": 676
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.000977100646352724,
      "loss": 1.0961,
      "step": 677
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0009765004616805171,
      "loss": 0.9893,
      "step": 678
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.0009759002770083103,
      "loss": 0.9424,
      "step": 679
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0009753000923361034,
      "loss": 1.1628,
      "step": 680
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0009746999076638965,
      "loss": 1.0491,
      "step": 681
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0009740997229916896,
      "loss": 1.1533,
      "step": 682
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.0009734995383194828,
      "loss": 1.1107,
      "step": 683
    },
    {
      "epoch": 1.48,
      "learning_rate": 0.000972899353647276,
      "loss": 1.145,
      "step": 684
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0009722991689750691,
      "loss": 1.2299,
      "step": 685
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0009716989843028623,
      "loss": 1.1456,
      "step": 686
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0009710987996306555,
      "loss": 1.1598,
      "step": 687
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0009704986149584487,
      "loss": 1.0413,
      "step": 688
    },
    {
      "epoch": 1.49,
      "learning_rate": 0.0009698984302862418,
      "loss": 1.0697,
      "step": 689
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.000969298245614035,
      "loss": 0.9177,
      "step": 690
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0009686980609418282,
      "loss": 1.0121,
      "step": 691
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0009680978762696213,
      "loss": 1.1824,
      "step": 692
    },
    {
      "epoch": 1.5,
      "learning_rate": 0.0009674976915974145,
      "loss": 1.0099,
      "step": 693
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0009668975069252077,
      "loss": 1.0229,
      "step": 694
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0009662973222530008,
      "loss": 0.9982,
      "step": 695
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.000965697137580794,
      "loss": 1.0402,
      "step": 696
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0009650969529085872,
      "loss": 1.0811,
      "step": 697
    },
    {
      "epoch": 1.51,
      "learning_rate": 0.0009644967682363805,
      "loss": 1.1065,
      "step": 698
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0009638965835641735,
      "loss": 1.0858,
      "step": 699
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0009632963988919668,
      "loss": 1.1723,
      "step": 700
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.00096269621421976,
      "loss": 1.183,
      "step": 701
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0009620960295475531,
      "loss": 1.2041,
      "step": 702
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0009614958448753463,
      "loss": 0.9157,
      "step": 703
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0009608956602031395,
      "loss": 1.156,
      "step": 704
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0009602954755309327,
      "loss": 1.0028,
      "step": 705
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0009596952908587257,
      "loss": 1.0718,
      "step": 706
    },
    {
      "epoch": 1.53,
      "learning_rate": 0.0009590951061865189,
      "loss": 1.1726,
      "step": 707
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.000958494921514312,
      "loss": 1.2698,
      "step": 708
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0009578947368421052,
      "loss": 1.1866,
      "step": 709
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0009572945521698984,
      "loss": 1.1415,
      "step": 710
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0009566943674976915,
      "loss": 1.1113,
      "step": 711
    },
    {
      "epoch": 1.54,
      "learning_rate": 0.0009560941828254847,
      "loss": 1.0495,
      "step": 712
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0009554939981532779,
      "loss": 1.085,
      "step": 713
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.000954893813481071,
      "loss": 0.9858,
      "step": 714
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0009542936288088642,
      "loss": 1.0817,
      "step": 715
    },
    {
      "epoch": 1.55,
      "learning_rate": 0.0009536934441366574,
      "loss": 0.9081,
      "step": 716
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0009530932594644506,
      "loss": 1.0233,
      "step": 717
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0009524930747922437,
      "loss": 1.0025,
      "step": 718
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0009518928901200369,
      "loss": 1.1237,
      "step": 719
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0009512927054478301,
      "loss": 1.0712,
      "step": 720
    },
    {
      "epoch": 1.56,
      "learning_rate": 0.0009506925207756232,
      "loss": 1.2032,
      "step": 721
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0009500923361034164,
      "loss": 1.2202,
      "step": 722
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0009494921514312096,
      "loss": 1.0629,
      "step": 723
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0009488919667590027,
      "loss": 0.9655,
      "step": 724
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0009482917820867959,
      "loss": 1.1196,
      "step": 725
    },
    {
      "epoch": 1.57,
      "learning_rate": 0.0009476915974145891,
      "loss": 1.1698,
      "step": 726
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0009470914127423823,
      "loss": 1.0179,
      "step": 727
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0009464912280701754,
      "loss": 1.1831,
      "step": 728
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0009458910433979686,
      "loss": 0.9125,
      "step": 729
    },
    {
      "epoch": 1.58,
      "learning_rate": 0.0009452908587257618,
      "loss": 1.1862,
      "step": 730
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0009446906740535548,
      "loss": 0.9528,
      "step": 731
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.000944090489381348,
      "loss": 1.0142,
      "step": 732
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0009434903047091411,
      "loss": 1.0828,
      "step": 733
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0009428901200369343,
      "loss": 0.9993,
      "step": 734
    },
    {
      "epoch": 1.59,
      "learning_rate": 0.0009422899353647275,
      "loss": 1.1903,
      "step": 735
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0009416897506925207,
      "loss": 0.9312,
      "step": 736
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0009410895660203138,
      "loss": 1.0846,
      "step": 737
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.000940489381348107,
      "loss": 1.108,
      "step": 738
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.0009398891966759002,
      "loss": 1.1111,
      "step": 739
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0009392890120036933,
      "loss": 0.9966,
      "step": 740
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0009386888273314865,
      "loss": 1.3014,
      "step": 741
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0009380886426592798,
      "loss": 1.1219,
      "step": 742
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.0009374884579870728,
      "loss": 0.9474,
      "step": 743
    },
    {
      "epoch": 1.61,
      "learning_rate": 0.000936888273314866,
      "loss": 1.1,
      "step": 744
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0009362880886426593,
      "loss": 1.0178,
      "step": 745
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0009356879039704525,
      "loss": 1.0937,
      "step": 746
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0009350877192982456,
      "loss": 1.0961,
      "step": 747
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.0009344875346260388,
      "loss": 0.9355,
      "step": 748
    },
    {
      "epoch": 1.62,
      "learning_rate": 0.000933887349953832,
      "loss": 1.0381,
      "step": 749
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0009332871652816251,
      "loss": 1.1457,
      "step": 750
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0009326869806094183,
      "loss": 1.0916,
      "step": 751
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0009320867959372115,
      "loss": 1.0963,
      "step": 752
    },
    {
      "epoch": 1.63,
      "learning_rate": 0.0009314866112650046,
      "loss": 1.1688,
      "step": 753
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0009308864265927978,
      "loss": 1.1304,
      "step": 754
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.000930286241920591,
      "loss": 1.1407,
      "step": 755
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0009296860572483842,
      "loss": 1.1216,
      "step": 756
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0009290858725761772,
      "loss": 0.9037,
      "step": 757
    },
    {
      "epoch": 1.64,
      "learning_rate": 0.0009284856879039704,
      "loss": 1.0246,
      "step": 758
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0009278855032317635,
      "loss": 1.1488,
      "step": 759
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0009272853185595567,
      "loss": 1.1123,
      "step": 760
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.0009266851338873499,
      "loss": 1.0038,
      "step": 761
    },
    {
      "epoch": 1.65,
      "learning_rate": 0.000926084949215143,
      "loss": 1.0675,
      "step": 762
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0009254847645429362,
      "loss": 1.0653,
      "step": 763
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0009248845798707294,
      "loss": 0.9859,
      "step": 764
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0009242843951985226,
      "loss": 1.1143,
      "step": 765
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0009236842105263157,
      "loss": 1.2199,
      "step": 766
    },
    {
      "epoch": 1.66,
      "learning_rate": 0.0009230840258541089,
      "loss": 0.9578,
      "step": 767
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0009224838411819021,
      "loss": 0.9571,
      "step": 768
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0009218836565096952,
      "loss": 1.0283,
      "step": 769
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0009212834718374884,
      "loss": 1.1654,
      "step": 770
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0009206832871652816,
      "loss": 1.0443,
      "step": 771
    },
    {
      "epoch": 1.67,
      "learning_rate": 0.0009200831024930747,
      "loss": 1.0008,
      "step": 772
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0009194829178208679,
      "loss": 1.1272,
      "step": 773
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0009188827331486611,
      "loss": 1.0975,
      "step": 774
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0009182825484764543,
      "loss": 1.1889,
      "step": 775
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.0009176823638042474,
      "loss": 1.0031,
      "step": 776
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0009170821791320406,
      "loss": 1.0731,
      "step": 777
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0009164819944598338,
      "loss": 1.1166,
      "step": 778
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0009158818097876269,
      "loss": 1.0951,
      "step": 779
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0009152816251154201,
      "loss": 1.0046,
      "step": 780
    },
    {
      "epoch": 1.69,
      "learning_rate": 0.0009146814404432133,
      "loss": 1.0445,
      "step": 781
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0009140812557710063,
      "loss": 0.9706,
      "step": 782
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0009134810710987995,
      "loss": 1.1068,
      "step": 783
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0009128808864265927,
      "loss": 1.0,
      "step": 784
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.0009122807017543858,
      "loss": 1.0893,
      "step": 785
    },
    {
      "epoch": 1.7,
      "learning_rate": 0.000911680517082179,
      "loss": 1.0294,
      "step": 786
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0009110803324099723,
      "loss": 1.0594,
      "step": 787
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0009104801477377654,
      "loss": 1.1443,
      "step": 788
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0009098799630655586,
      "loss": 1.0168,
      "step": 789
    },
    {
      "epoch": 1.71,
      "learning_rate": 0.0009092797783933518,
      "loss": 1.0264,
      "step": 790
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0009086795937211449,
      "loss": 0.9914,
      "step": 791
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0009080794090489381,
      "loss": 1.0688,
      "step": 792
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0009074792243767313,
      "loss": 1.089,
      "step": 793
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0009068790397045245,
      "loss": 1.1391,
      "step": 794
    },
    {
      "epoch": 1.72,
      "learning_rate": 0.0009062788550323176,
      "loss": 1.1047,
      "step": 795
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.0009056786703601108,
      "loss": 0.9661,
      "step": 796
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.000905078485687904,
      "loss": 0.9448,
      "step": 797
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.0009044783010156971,
      "loss": 1.1775,
      "step": 798
    },
    {
      "epoch": 1.73,
      "learning_rate": 0.0009038781163434903,
      "loss": 0.9447,
      "step": 799
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0009032779316712835,
      "loss": 1.0164,
      "step": 800
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0009026777469990766,
      "loss": 1.1508,
      "step": 801
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0009020775623268698,
      "loss": 1.0476,
      "step": 802
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.000901477377654663,
      "loss": 1.0509,
      "step": 803
    },
    {
      "epoch": 1.74,
      "learning_rate": 0.0009008771929824562,
      "loss": 1.0162,
      "step": 804
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.0009002770083102493,
      "loss": 1.1386,
      "step": 805
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.0008996768236380425,
      "loss": 1.0461,
      "step": 806
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.0008990766389658355,
      "loss": 0.935,
      "step": 807
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.0008984764542936287,
      "loss": 1.1572,
      "step": 808
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.0008978762696214219,
      "loss": 1.1288,
      "step": 809
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.000897276084949215,
      "loss": 1.156,
      "step": 810
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.0008966759002770082,
      "loss": 1.2008,
      "step": 811
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.0008960757156048014,
      "loss": 0.9681,
      "step": 812
    },
    {
      "epoch": 1.76,
      "learning_rate": 0.0008954755309325946,
      "loss": 1.2116,
      "step": 813
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0008948753462603877,
      "loss": 1.0812,
      "step": 814
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0008942751615881809,
      "loss": 1.008,
      "step": 815
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0008936749769159741,
      "loss": 1.0836,
      "step": 816
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0008930747922437672,
      "loss": 0.9962,
      "step": 817
    },
    {
      "epoch": 1.77,
      "learning_rate": 0.0008924746075715604,
      "loss": 1.0262,
      "step": 818
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.0008918744228993536,
      "loss": 1.1526,
      "step": 819
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.0008912742382271467,
      "loss": 1.1874,
      "step": 820
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.0008906740535549399,
      "loss": 1.1011,
      "step": 821
    },
    {
      "epoch": 1.78,
      "learning_rate": 0.0008900738688827331,
      "loss": 0.9325,
      "step": 822
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.0008894736842105263,
      "loss": 0.9236,
      "step": 823
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.0008888734995383194,
      "loss": 0.9949,
      "step": 824
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.0008882733148661126,
      "loss": 1.1294,
      "step": 825
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.0008876731301939059,
      "loss": 1.0386,
      "step": 826
    },
    {
      "epoch": 1.79,
      "learning_rate": 0.000887072945521699,
      "loss": 1.0573,
      "step": 827
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0008864727608494922,
      "loss": 1.042,
      "step": 828
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0008858725761772854,
      "loss": 1.0655,
      "step": 829
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0008852723915050785,
      "loss": 1.054,
      "step": 830
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0008846722068328717,
      "loss": 1.0497,
      "step": 831
    },
    {
      "epoch": 1.8,
      "learning_rate": 0.0008840720221606648,
      "loss": 1.12,
      "step": 832
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.0008834718374884579,
      "loss": 1.0001,
      "step": 833
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.0008828716528162511,
      "loss": 1.0624,
      "step": 834
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.0008822714681440443,
      "loss": 1.0886,
      "step": 835
    },
    {
      "epoch": 1.81,
      "learning_rate": 0.0008816712834718374,
      "loss": 1.1967,
      "step": 836
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0008810710987996306,
      "loss": 1.0558,
      "step": 837
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0008804709141274238,
      "loss": 1.1034,
      "step": 838
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0008798707294552169,
      "loss": 0.9702,
      "step": 839
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0008792705447830101,
      "loss": 1.2631,
      "step": 840
    },
    {
      "epoch": 1.82,
      "learning_rate": 0.0008786703601108033,
      "loss": 0.9292,
      "step": 841
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.0008780701754385965,
      "loss": 1.1166,
      "step": 842
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.0008774699907663896,
      "loss": 1.0575,
      "step": 843
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.0008768698060941828,
      "loss": 1.0581,
      "step": 844
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.000876269621421976,
      "loss": 1.044,
      "step": 845
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.0008756694367497691,
      "loss": 1.2165,
      "step": 846
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.0008750692520775623,
      "loss": 0.9662,
      "step": 847
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.0008744690674053555,
      "loss": 1.242,
      "step": 848
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.0008738688827331486,
      "loss": 1.0826,
      "step": 849
    },
    {
      "epoch": 1.84,
      "learning_rate": 0.0008732686980609418,
      "loss": 1.0209,
      "step": 850
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.000872668513388735,
      "loss": 1.0678,
      "step": 851
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.0008720683287165282,
      "loss": 0.9507,
      "step": 852
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.0008714681440443213,
      "loss": 1.0391,
      "step": 853
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.0008708679593721145,
      "loss": 1.0381,
      "step": 854
    },
    {
      "epoch": 1.85,
      "learning_rate": 0.0008702677746999077,
      "loss": 1.0636,
      "step": 855
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.0008696675900277008,
      "loss": 1.032,
      "step": 856
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.0008690674053554939,
      "loss": 0.9937,
      "step": 857
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.000868467220683287,
      "loss": 1.0492,
      "step": 858
    },
    {
      "epoch": 1.86,
      "learning_rate": 0.0008678670360110802,
      "loss": 1.1252,
      "step": 859
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.0008672668513388734,
      "loss": 1.0609,
      "step": 860
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.0008666666666666666,
      "loss": 1.0678,
      "step": 861
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.0008660664819944597,
      "loss": 1.2025,
      "step": 862
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.0008654662973222529,
      "loss": 1.0674,
      "step": 863
    },
    {
      "epoch": 1.87,
      "learning_rate": 0.0008648661126500461,
      "loss": 0.9287,
      "step": 864
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.0008642659279778392,
      "loss": 1.1167,
      "step": 865
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.0008636657433056324,
      "loss": 1.1042,
      "step": 866
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.0008630655586334256,
      "loss": 1.0442,
      "step": 867
    },
    {
      "epoch": 1.88,
      "learning_rate": 0.0008624653739612187,
      "loss": 1.146,
      "step": 868
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0008618651892890119,
      "loss": 0.9958,
      "step": 869
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0008612650046168051,
      "loss": 0.9599,
      "step": 870
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0008606648199445984,
      "loss": 1.0139,
      "step": 871
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0008600646352723915,
      "loss": 1.1865,
      "step": 872
    },
    {
      "epoch": 1.89,
      "learning_rate": 0.0008594644506001847,
      "loss": 1.0737,
      "step": 873
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.0008588642659279779,
      "loss": 1.086,
      "step": 874
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.000858264081255771,
      "loss": 0.9961,
      "step": 875
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.0008576638965835642,
      "loss": 1.0723,
      "step": 876
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.0008570637119113574,
      "loss": 1.0554,
      "step": 877
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.0008564635272391505,
      "loss": 1.0708,
      "step": 878
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.0008558633425669437,
      "loss": 1.1493,
      "step": 879
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.0008552631578947369,
      "loss": 1.0939,
      "step": 880
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.0008546629732225301,
      "loss": 1.0401,
      "step": 881
    },
    {
      "epoch": 1.91,
      "learning_rate": 0.0008540627885503231,
      "loss": 1.0862,
      "step": 882
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.0008534626038781163,
      "loss": 1.0201,
      "step": 883
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.0008528624192059094,
      "loss": 1.0461,
      "step": 884
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.0008522622345337026,
      "loss": 0.9888,
      "step": 885
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.0008516620498614958,
      "loss": 1.1051,
      "step": 886
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.0008510618651892889,
      "loss": 1.197,
      "step": 887
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.0008504616805170821,
      "loss": 0.9213,
      "step": 888
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.0008498614958448753,
      "loss": 1.1168,
      "step": 889
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.0008492613111726685,
      "loss": 1.1858,
      "step": 890
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.0008486611265004616,
      "loss": 1.1703,
      "step": 891
    },
    {
      "epoch": 1.93,
      "learning_rate": 0.0008480609418282548,
      "loss": 1.1359,
      "step": 892
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.000847460757156048,
      "loss": 1.1323,
      "step": 893
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.0008468605724838411,
      "loss": 0.9606,
      "step": 894
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.0008462603878116343,
      "loss": 1.0612,
      "step": 895
    },
    {
      "epoch": 1.94,
      "learning_rate": 0.0008456602031394275,
      "loss": 1.192,
      "step": 896
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.0008450600184672206,
      "loss": 1.1213,
      "step": 897
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.0008444598337950138,
      "loss": 1.097,
      "step": 898
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.000843859649122807,
      "loss": 0.91,
      "step": 899
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.0008432594644506002,
      "loss": 1.0578,
      "step": 900
    },
    {
      "epoch": 1.95,
      "learning_rate": 0.0008426592797783933,
      "loss": 1.057,
      "step": 901
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.0008420590951061865,
      "loss": 0.897,
      "step": 902
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.0008414589104339797,
      "loss": 1.0318,
      "step": 903
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.0008408587257617728,
      "loss": 1.1139,
      "step": 904
    },
    {
      "epoch": 1.96,
      "learning_rate": 0.000840258541089566,
      "loss": 1.0512,
      "step": 905
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.0008396583564173592,
      "loss": 1.1101,
      "step": 906
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.0008390581717451523,
      "loss": 1.1366,
      "step": 907
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.0008384579870729454,
      "loss": 1.0021,
      "step": 908
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.0008378578024007386,
      "loss": 1.1724,
      "step": 909
    },
    {
      "epoch": 1.97,
      "learning_rate": 0.0008372576177285317,
      "loss": 1.0564,
      "step": 910
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.0008366574330563249,
      "loss": 1.0909,
      "step": 911
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.0008360572483841181,
      "loss": 0.9611,
      "step": 912
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.0008354570637119112,
      "loss": 0.9772,
      "step": 913
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.0008348568790397044,
      "loss": 1.076,
      "step": 914
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.0008342566943674977,
      "loss": 1.0603,
      "step": 915
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.0008336565096952907,
      "loss": 0.9737,
      "step": 916
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.000833056325023084,
      "loss": 1.0675,
      "step": 917
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.0008324561403508772,
      "loss": 0.9726,
      "step": 918
    },
    {
      "epoch": 1.99,
      "learning_rate": 0.0008318559556786704,
      "loss": 1.0786,
      "step": 919
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.0008312557710064635,
      "loss": 0.9824,
      "step": 920
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.0008306555863342567,
      "loss": 1.0579,
      "step": 921
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.0008300554016620499,
      "loss": 1.158,
      "step": 922
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.000829455216989843,
      "loss": 0.9963,
      "step": 923
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.0008288550323176362,
      "loss": 0.7508,
      "step": 924
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.0008282548476454294,
      "loss": 0.9486,
      "step": 925
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.0008276546629732225,
      "loss": 0.9986,
      "step": 926
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.0008270544783010157,
      "loss": 0.9568,
      "step": 927
    },
    {
      "epoch": 2.01,
      "learning_rate": 0.0008264542936288089,
      "loss": 0.9445,
      "step": 928
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.0008258541089566021,
      "loss": 0.8467,
      "step": 929
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.0008252539242843952,
      "loss": 1.0289,
      "step": 930
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.0008246537396121884,
      "loss": 1.0311,
      "step": 931
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.0008240535549399816,
      "loss": 0.9304,
      "step": 932
    },
    {
      "epoch": 2.02,
      "learning_rate": 0.0008234533702677746,
      "loss": 0.9533,
      "step": 933
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.0008228531855955678,
      "loss": 0.9241,
      "step": 934
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.0008222530009233609,
      "loss": 0.8255,
      "step": 935
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.0008216528162511541,
      "loss": 1.1944,
      "step": 936
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.0008210526315789473,
      "loss": 1.0081,
      "step": 937
    },
    {
      "epoch": 2.03,
      "learning_rate": 0.0008204524469067405,
      "loss": 0.9311,
      "step": 938
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.0008198522622345336,
      "loss": 1.0252,
      "step": 939
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.0008192520775623268,
      "loss": 1.0081,
      "step": 940
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.00081865189289012,
      "loss": 1.0006,
      "step": 941
    },
    {
      "epoch": 2.04,
      "learning_rate": 0.0008180517082179131,
      "loss": 0.9578,
      "step": 942
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.0008174515235457063,
      "loss": 0.9424,
      "step": 943
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.0008168513388734995,
      "loss": 1.0133,
      "step": 944
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.0008162511542012926,
      "loss": 1.0034,
      "step": 945
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.0008156509695290858,
      "loss": 0.8016,
      "step": 946
    },
    {
      "epoch": 2.05,
      "learning_rate": 0.000815050784856879,
      "loss": 0.9171,
      "step": 947
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.0008144506001846722,
      "loss": 0.8954,
      "step": 948
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.0008138504155124653,
      "loss": 0.9585,
      "step": 949
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.0008132502308402585,
      "loss": 0.9381,
      "step": 950
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.0008126500461680517,
      "loss": 0.9481,
      "step": 951
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.0008120498614958448,
      "loss": 0.8607,
      "step": 952
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.000811449676823638,
      "loss": 1.092,
      "step": 953
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.0008108494921514313,
      "loss": 0.9812,
      "step": 954
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.0008102493074792243,
      "loss": 0.939,
      "step": 955
    },
    {
      "epoch": 2.07,
      "learning_rate": 0.0008096491228070176,
      "loss": 0.9371,
      "step": 956
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0008090489381348108,
      "loss": 1.1218,
      "step": 957
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0008084487534626037,
      "loss": 1.0414,
      "step": 958
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.000807848568790397,
      "loss": 0.9187,
      "step": 959
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0008072483841181902,
      "loss": 0.9817,
      "step": 960
    },
    {
      "epoch": 2.08,
      "learning_rate": 0.0008066481994459833,
      "loss": 1.0007,
      "step": 961
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.0008060480147737765,
      "loss": 0.9587,
      "step": 962
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.0008054478301015697,
      "loss": 0.9096,
      "step": 963
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.0008048476454293628,
      "loss": 0.9934,
      "step": 964
    },
    {
      "epoch": 2.09,
      "learning_rate": 0.000804247460757156,
      "loss": 1.0029,
      "step": 965
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.0008036472760849492,
      "loss": 1.0144,
      "step": 966
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.0008030470914127424,
      "loss": 0.9835,
      "step": 967
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.0008024469067405355,
      "loss": 0.9276,
      "step": 968
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.0008018467220683287,
      "loss": 0.9912,
      "step": 969
    },
    {
      "epoch": 2.1,
      "learning_rate": 0.0008012465373961219,
      "loss": 0.9937,
      "step": 970
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.000800646352723915,
      "loss": 1.0415,
      "step": 971
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0008000461680517082,
      "loss": 0.8448,
      "step": 972
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0007994459833795014,
      "loss": 1.1153,
      "step": 973
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0007988457987072945,
      "loss": 1.0438,
      "step": 974
    },
    {
      "epoch": 2.11,
      "learning_rate": 0.0007982456140350877,
      "loss": 0.9682,
      "step": 975
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.0007976454293628809,
      "loss": 0.8685,
      "step": 976
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.0007970452446906741,
      "loss": 0.9057,
      "step": 977
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.0007964450600184672,
      "loss": 0.9005,
      "step": 978
    },
    {
      "epoch": 2.12,
      "learning_rate": 0.0007958448753462604,
      "loss": 0.9277,
      "step": 979
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.0007952446906740536,
      "loss": 0.9058,
      "step": 980
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.0007946445060018467,
      "loss": 0.8771,
      "step": 981
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.0007940443213296399,
      "loss": 0.9965,
      "step": 982
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.0007934441366574329,
      "loss": 0.9289,
      "step": 983
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.0007928439519852261,
      "loss": 0.996,
      "step": 984
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.0007922437673130193,
      "loss": 0.9883,
      "step": 985
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.0007916435826408125,
      "loss": 0.9361,
      "step": 986
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.0007910433979686056,
      "loss": 0.9492,
      "step": 987
    },
    {
      "epoch": 2.14,
      "learning_rate": 0.0007904432132963988,
      "loss": 1.0921,
      "step": 988
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.000789843028624192,
      "loss": 0.9976,
      "step": 989
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.0007892428439519851,
      "loss": 0.8639,
      "step": 990
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.0007886426592797783,
      "loss": 0.9779,
      "step": 991
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.0007880424746075715,
      "loss": 0.9971,
      "step": 992
    },
    {
      "epoch": 2.15,
      "learning_rate": 0.0007874422899353646,
      "loss": 0.8783,
      "step": 993
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.0007868421052631578,
      "loss": 0.7934,
      "step": 994
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.000786241920590951,
      "loss": 0.9167,
      "step": 995
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.0007856417359187442,
      "loss": 0.837,
      "step": 996
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.0007850415512465373,
      "loss": 1.0662,
      "step": 997
    },
    {
      "epoch": 2.16,
      "learning_rate": 0.0007844413665743305,
      "loss": 0.9225,
      "step": 998
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0007838411819021238,
      "loss": 1.0712,
      "step": 999
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0007832409972299169,
      "loss": 0.9958,
      "step": 1000
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0007826408125577101,
      "loss": 1.0251,
      "step": 1001
    },
    {
      "epoch": 2.17,
      "learning_rate": 0.0007820406278855033,
      "loss": 0.9936,
      "step": 1002
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.0007814404432132964,
      "loss": 1.1393,
      "step": 1003
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.0007808402585410896,
      "loss": 1.1524,
      "step": 1004
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.0007802400738688828,
      "loss": 1.122,
      "step": 1005
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.000779639889196676,
      "loss": 0.8966,
      "step": 1006
    },
    {
      "epoch": 2.18,
      "learning_rate": 0.0007790397045244691,
      "loss": 0.9056,
      "step": 1007
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.0007784395198522622,
      "loss": 1.0357,
      "step": 1008
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.0007778393351800553,
      "loss": 0.9603,
      "step": 1009
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.0007772391505078485,
      "loss": 0.9585,
      "step": 1010
    },
    {
      "epoch": 2.19,
      "learning_rate": 0.0007766389658356417,
      "loss": 0.955,
      "step": 1011
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.0007760387811634348,
      "loss": 1.0739,
      "step": 1012
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.000775438596491228,
      "loss": 0.8638,
      "step": 1013
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.0007748384118190212,
      "loss": 0.8705,
      "step": 1014
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.0007742382271468144,
      "loss": 0.9351,
      "step": 1015
    },
    {
      "epoch": 2.2,
      "learning_rate": 0.0007736380424746075,
      "loss": 1.1371,
      "step": 1016
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.0007730378578024007,
      "loss": 1.0232,
      "step": 1017
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.0007724376731301939,
      "loss": 1.0247,
      "step": 1018
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.000771837488457987,
      "loss": 0.9797,
      "step": 1019
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.0007712373037857802,
      "loss": 0.9941,
      "step": 1020
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.0007706371191135734,
      "loss": 0.99,
      "step": 1021
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.0007700369344413665,
      "loss": 1.0458,
      "step": 1022
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.0007694367497691597,
      "loss": 0.8002,
      "step": 1023
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.0007688365650969529,
      "loss": 1.192,
      "step": 1024
    },
    {
      "epoch": 2.22,
      "learning_rate": 0.0007682363804247461,
      "loss": 0.9495,
      "step": 1025
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.0007676361957525392,
      "loss": 0.9394,
      "step": 1026
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.0007670360110803324,
      "loss": 0.9419,
      "step": 1027
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.0007664358264081256,
      "loss": 0.9135,
      "step": 1028
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.0007658356417359187,
      "loss": 0.8477,
      "step": 1029
    },
    {
      "epoch": 2.23,
      "learning_rate": 0.0007652354570637119,
      "loss": 1.0059,
      "step": 1030
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.0007646352723915051,
      "loss": 0.9484,
      "step": 1031
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.0007640350877192982,
      "loss": 0.9473,
      "step": 1032
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.0007634349030470914,
      "loss": 1.031,
      "step": 1033
    },
    {
      "epoch": 2.24,
      "learning_rate": 0.0007628347183748845,
      "loss": 1.0257,
      "step": 1034
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.0007622345337026776,
      "loss": 0.9298,
      "step": 1035
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.0007616343490304708,
      "loss": 0.9813,
      "step": 1036
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.000761034164358264,
      "loss": 0.9305,
      "step": 1037
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.0007604339796860571,
      "loss": 0.9214,
      "step": 1038
    },
    {
      "epoch": 2.25,
      "learning_rate": 0.0007598337950138503,
      "loss": 0.9265,
      "step": 1039
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.0007592336103416435,
      "loss": 0.946,
      "step": 1040
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.0007586334256694366,
      "loss": 0.8938,
      "step": 1041
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.0007580332409972298,
      "loss": 0.9454,
      "step": 1042
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.000757433056325023,
      "loss": 0.9856,
      "step": 1043
    },
    {
      "epoch": 2.26,
      "learning_rate": 0.0007568328716528163,
      "loss": 0.9403,
      "step": 1044
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.0007562326869806094,
      "loss": 1.0083,
      "step": 1045
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.0007556325023084026,
      "loss": 0.9037,
      "step": 1046
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.0007550323176361958,
      "loss": 1.0189,
      "step": 1047
    },
    {
      "epoch": 2.27,
      "learning_rate": 0.0007544321329639889,
      "loss": 1.0353,
      "step": 1048
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.0007538319482917821,
      "loss": 1.0278,
      "step": 1049
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.0007532317636195753,
      "loss": 1.0314,
      "step": 1050
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.0007526315789473684,
      "loss": 0.9156,
      "step": 1051
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.0007520313942751616,
      "loss": 0.8838,
      "step": 1052
    },
    {
      "epoch": 2.28,
      "learning_rate": 0.0007514312096029548,
      "loss": 0.8392,
      "step": 1053
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.000750831024930748,
      "loss": 0.8811,
      "step": 1054
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.0007502308402585411,
      "loss": 0.8755,
      "step": 1055
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.0007496306555863343,
      "loss": 0.8713,
      "step": 1056
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.0007490304709141275,
      "loss": 0.9487,
      "step": 1057
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.0007484302862419206,
      "loss": 0.8542,
      "step": 1058
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.0007478301015697137,
      "loss": 1.1308,
      "step": 1059
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.0007472299168975068,
      "loss": 0.937,
      "step": 1060
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.0007466297322253,
      "loss": 1.0014,
      "step": 1061
    },
    {
      "epoch": 2.3,
      "learning_rate": 0.0007460295475530932,
      "loss": 1.0054,
      "step": 1062
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.0007454293628808864,
      "loss": 1.1065,
      "step": 1063
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.0007448291782086795,
      "loss": 0.954,
      "step": 1064
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.0007442289935364727,
      "loss": 0.9607,
      "step": 1065
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.0007436288088642659,
      "loss": 0.9333,
      "step": 1066
    },
    {
      "epoch": 2.31,
      "learning_rate": 0.000743028624192059,
      "loss": 1.0454,
      "step": 1067
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.0007424284395198522,
      "loss": 0.9508,
      "step": 1068
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.0007418282548476454,
      "loss": 0.9622,
      "step": 1069
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.0007412280701754385,
      "loss": 1.0246,
      "step": 1070
    },
    {
      "epoch": 2.32,
      "learning_rate": 0.0007406278855032317,
      "loss": 1.0814,
      "step": 1071
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.0007400277008310249,
      "loss": 1.0235,
      "step": 1072
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.0007394275161588181,
      "loss": 0.9403,
      "step": 1073
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.0007388273314866112,
      "loss": 0.9503,
      "step": 1074
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.0007382271468144044,
      "loss": 1.0587,
      "step": 1075
    },
    {
      "epoch": 2.33,
      "learning_rate": 0.0007376269621421976,
      "loss": 0.9106,
      "step": 1076
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0007370267774699907,
      "loss": 1.0113,
      "step": 1077
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0007364265927977839,
      "loss": 0.9549,
      "step": 1078
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0007358264081255771,
      "loss": 0.9569,
      "step": 1079
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0007352262234533702,
      "loss": 0.9573,
      "step": 1080
    },
    {
      "epoch": 2.34,
      "learning_rate": 0.0007346260387811634,
      "loss": 1.077,
      "step": 1081
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.0007340258541089566,
      "loss": 0.9498,
      "step": 1082
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.0007334256694367499,
      "loss": 0.9905,
      "step": 1083
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.0007328254847645428,
      "loss": 1.0985,
      "step": 1084
    },
    {
      "epoch": 2.35,
      "learning_rate": 0.000732225300092336,
      "loss": 0.9368,
      "step": 1085
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.0007316251154201291,
      "loss": 1.089,
      "step": 1086
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.0007310249307479224,
      "loss": 0.9693,
      "step": 1087
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.0007304247460757156,
      "loss": 1.0169,
      "step": 1088
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.0007298245614035087,
      "loss": 1.0249,
      "step": 1089
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.0007292243767313019,
      "loss": 0.9421,
      "step": 1090
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.0007286241920590951,
      "loss": 1.19,
      "step": 1091
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.0007280240073868883,
      "loss": 0.942,
      "step": 1092
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.0007274238227146814,
      "loss": 0.9804,
      "step": 1093
    },
    {
      "epoch": 2.37,
      "learning_rate": 0.0007268236380424746,
      "loss": 1.0366,
      "step": 1094
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0007262234533702678,
      "loss": 0.9079,
      "step": 1095
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0007256232686980609,
      "loss": 0.9955,
      "step": 1096
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0007250230840258541,
      "loss": 0.8384,
      "step": 1097
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0007244228993536473,
      "loss": 0.8913,
      "step": 1098
    },
    {
      "epoch": 2.38,
      "learning_rate": 0.0007238227146814404,
      "loss": 0.9422,
      "step": 1099
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.0007232225300092336,
      "loss": 0.914,
      "step": 1100
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.0007226223453370268,
      "loss": 1.0417,
      "step": 1101
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.00072202216066482,
      "loss": 1.0027,
      "step": 1102
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.0007214219759926131,
      "loss": 0.987,
      "step": 1103
    },
    {
      "epoch": 2.39,
      "learning_rate": 0.0007208217913204063,
      "loss": 0.9482,
      "step": 1104
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.0007202216066481995,
      "loss": 0.9273,
      "step": 1105
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.0007196214219759926,
      "loss": 0.9283,
      "step": 1106
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.0007190212373037858,
      "loss": 1.0928,
      "step": 1107
    },
    {
      "epoch": 2.4,
      "learning_rate": 0.000718421052631579,
      "loss": 0.898,
      "step": 1108
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.000717820867959372,
      "loss": 0.9508,
      "step": 1109
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0007172206832871652,
      "loss": 0.9263,
      "step": 1110
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0007166204986149584,
      "loss": 1.0186,
      "step": 1111
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0007160203139427515,
      "loss": 1.0211,
      "step": 1112
    },
    {
      "epoch": 2.41,
      "learning_rate": 0.0007154201292705447,
      "loss": 0.9264,
      "step": 1113
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.0007148199445983379,
      "loss": 0.9627,
      "step": 1114
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.000714219759926131,
      "loss": 0.9371,
      "step": 1115
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.0007136195752539242,
      "loss": 0.9032,
      "step": 1116
    },
    {
      "epoch": 2.42,
      "learning_rate": 0.0007130193905817174,
      "loss": 1.026,
      "step": 1117
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.0007124192059095105,
      "loss": 1.0161,
      "step": 1118
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.0007118190212373037,
      "loss": 1.0109,
      "step": 1119
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.0007112188365650969,
      "loss": 0.9218,
      "step": 1120
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.0007106186518928901,
      "loss": 1.0318,
      "step": 1121
    },
    {
      "epoch": 2.43,
      "learning_rate": 0.0007100184672206832,
      "loss": 0.8726,
      "step": 1122
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.0007094182825484764,
      "loss": 1.0519,
      "step": 1123
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.0007088180978762696,
      "loss": 1.1281,
      "step": 1124
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.0007082179132040627,
      "loss": 0.9814,
      "step": 1125
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.000707617728531856,
      "loss": 1.0246,
      "step": 1126
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.0007070175438596492,
      "loss": 0.9838,
      "step": 1127
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.0007064173591874423,
      "loss": 1.0659,
      "step": 1128
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.0007058171745152355,
      "loss": 0.9295,
      "step": 1129
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.0007052169898430287,
      "loss": 0.9016,
      "step": 1130
    },
    {
      "epoch": 2.45,
      "learning_rate": 0.0007046168051708219,
      "loss": 0.9761,
      "step": 1131
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.000704016620498615,
      "loss": 0.974,
      "step": 1132
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.0007034164358264082,
      "loss": 1.0321,
      "step": 1133
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.0007028162511542012,
      "loss": 0.8714,
      "step": 1134
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.0007022160664819944,
      "loss": 0.8926,
      "step": 1135
    },
    {
      "epoch": 2.46,
      "learning_rate": 0.0007016158818097876,
      "loss": 0.8742,
      "step": 1136
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.0007010156971375807,
      "loss": 0.9443,
      "step": 1137
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.0007004155124653739,
      "loss": 1.0707,
      "step": 1138
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.0006998153277931671,
      "loss": 0.9844,
      "step": 1139
    },
    {
      "epoch": 2.47,
      "learning_rate": 0.0006992151431209603,
      "loss": 1.0186,
      "step": 1140
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.0006986149584487534,
      "loss": 1.0009,
      "step": 1141
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.0006980147737765466,
      "loss": 1.099,
      "step": 1142
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.0006974145891043398,
      "loss": 0.9949,
      "step": 1143
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.0006968144044321329,
      "loss": 0.9983,
      "step": 1144
    },
    {
      "epoch": 2.48,
      "learning_rate": 0.0006962142197599261,
      "loss": 1.0696,
      "step": 1145
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.0006956140350877193,
      "loss": 0.9645,
      "step": 1146
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.0006950138504155124,
      "loss": 1.1294,
      "step": 1147
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.0006944136657433056,
      "loss": 0.887,
      "step": 1148
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.0006938134810710988,
      "loss": 1.0584,
      "step": 1149
    },
    {
      "epoch": 2.49,
      "learning_rate": 0.000693213296398892,
      "loss": 1.0958,
      "step": 1150
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.0006926131117266851,
      "loss": 1.0823,
      "step": 1151
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.0006920129270544783,
      "loss": 1.0505,
      "step": 1152
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.0006914127423822715,
      "loss": 0.9542,
      "step": 1153
    },
    {
      "epoch": 2.5,
      "learning_rate": 0.0006908125577100646,
      "loss": 0.9985,
      "step": 1154
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.0006902123730378578,
      "loss": 0.9009,
      "step": 1155
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.000689612188365651,
      "loss": 1.0332,
      "step": 1156
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.0006890120036934441,
      "loss": 0.9491,
      "step": 1157
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.0006884118190212373,
      "loss": 0.9592,
      "step": 1158
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.0006878116343490305,
      "loss": 0.9423,
      "step": 1159
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.0006872114496768235,
      "loss": 1.0165,
      "step": 1160
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.0006866112650046167,
      "loss": 1.0075,
      "step": 1161
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.0006860110803324099,
      "loss": 0.9578,
      "step": 1162
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.000685410895660203,
      "loss": 1.0252,
      "step": 1163
    },
    {
      "epoch": 2.52,
      "learning_rate": 0.0006848107109879962,
      "loss": 0.9653,
      "step": 1164
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.0006842105263157894,
      "loss": 0.8652,
      "step": 1165
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.0006836103416435825,
      "loss": 0.997,
      "step": 1166
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.0006830101569713757,
      "loss": 0.8288,
      "step": 1167
    },
    {
      "epoch": 2.53,
      "learning_rate": 0.0006824099722991689,
      "loss": 1.0061,
      "step": 1168
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.0006818097876269621,
      "loss": 0.8269,
      "step": 1169
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.0006812096029547552,
      "loss": 0.9973,
      "step": 1170
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.0006806094182825485,
      "loss": 1.0263,
      "step": 1171
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.0006800092336103417,
      "loss": 0.8956,
      "step": 1172
    },
    {
      "epoch": 2.54,
      "learning_rate": 0.0006794090489381348,
      "loss": 0.8906,
      "step": 1173
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.000678808864265928,
      "loss": 0.9634,
      "step": 1174
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.0006782086795937212,
      "loss": 1.0969,
      "step": 1175
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.0006776084949215143,
      "loss": 0.8933,
      "step": 1176
    },
    {
      "epoch": 2.55,
      "learning_rate": 0.0006770083102493075,
      "loss": 0.9931,
      "step": 1177
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.0006764081255771007,
      "loss": 0.9869,
      "step": 1178
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.0006758079409048939,
      "loss": 1.0235,
      "step": 1179
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.000675207756232687,
      "loss": 0.9668,
      "step": 1180
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.0006746075715604802,
      "loss": 0.9102,
      "step": 1181
    },
    {
      "epoch": 2.56,
      "learning_rate": 0.0006740073868882734,
      "loss": 0.908,
      "step": 1182
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.0006734072022160665,
      "loss": 0.903,
      "step": 1183
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.0006728070175438597,
      "loss": 0.8799,
      "step": 1184
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.0006722068328716527,
      "loss": 0.9451,
      "step": 1185
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.0006716066481994459,
      "loss": 0.9868,
      "step": 1186
    },
    {
      "epoch": 2.57,
      "learning_rate": 0.0006710064635272391,
      "loss": 0.7591,
      "step": 1187
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.0006704062788550322,
      "loss": 1.0438,
      "step": 1188
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.0006698060941828254,
      "loss": 1.0383,
      "step": 1189
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.0006692059095106186,
      "loss": 0.8556,
      "step": 1190
    },
    {
      "epoch": 2.58,
      "learning_rate": 0.0006686057248384118,
      "loss": 0.9293,
      "step": 1191
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.0006680055401662049,
      "loss": 0.9211,
      "step": 1192
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.0006674053554939981,
      "loss": 1.0784,
      "step": 1193
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.0006668051708217913,
      "loss": 0.972,
      "step": 1194
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.0006662049861495844,
      "loss": 0.9477,
      "step": 1195
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.0006656048014773776,
      "loss": 1.0991,
      "step": 1196
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.0006650046168051708,
      "loss": 0.9721,
      "step": 1197
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.000664404432132964,
      "loss": 0.9768,
      "step": 1198
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.0006638042474607571,
      "loss": 0.9797,
      "step": 1199
    },
    {
      "epoch": 2.6,
      "learning_rate": 0.0006632040627885503,
      "loss": 0.9316,
      "step": 1200
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.0006626038781163435,
      "loss": 0.9539,
      "step": 1201
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.0006620036934441366,
      "loss": 1.0235,
      "step": 1202
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.0006614035087719298,
      "loss": 0.8824,
      "step": 1203
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.000660803324099723,
      "loss": 0.9045,
      "step": 1204
    },
    {
      "epoch": 2.61,
      "learning_rate": 0.0006602031394275161,
      "loss": 0.963,
      "step": 1205
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.0006596029547553093,
      "loss": 0.9561,
      "step": 1206
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.0006590027700831025,
      "loss": 1.0671,
      "step": 1207
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.0006584025854108957,
      "loss": 1.0034,
      "step": 1208
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.0006578024007386888,
      "loss": 1.0444,
      "step": 1209
    },
    {
      "epoch": 2.62,
      "learning_rate": 0.0006572022160664819,
      "loss": 0.983,
      "step": 1210
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.000656602031394275,
      "loss": 0.9601,
      "step": 1211
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.0006560018467220682,
      "loss": 1.005,
      "step": 1212
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.0006554016620498614,
      "loss": 1.009,
      "step": 1213
    },
    {
      "epoch": 2.63,
      "learning_rate": 0.0006548014773776545,
      "loss": 0.9204,
      "step": 1214
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.0006542012927054477,
      "loss": 0.9737,
      "step": 1215
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.000653601108033241,
      "loss": 1.0532,
      "step": 1216
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.000653000923361034,
      "loss": 0.9585,
      "step": 1217
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.0006524007386888273,
      "loss": 0.9877,
      "step": 1218
    },
    {
      "epoch": 2.64,
      "learning_rate": 0.0006518005540166205,
      "loss": 1.0733,
      "step": 1219
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.0006512003693444137,
      "loss": 0.9759,
      "step": 1220
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.0006506001846722068,
      "loss": 0.8816,
      "step": 1221
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.00065,
      "loss": 1.0245,
      "step": 1222
    },
    {
      "epoch": 2.65,
      "learning_rate": 0.0006493998153277932,
      "loss": 0.9516,
      "step": 1223
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.0006487996306555863,
      "loss": 1.0375,
      "step": 1224
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.0006481994459833795,
      "loss": 0.9998,
      "step": 1225
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.0006475992613111727,
      "loss": 1.0435,
      "step": 1226
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.0006469990766389659,
      "loss": 0.991,
      "step": 1227
    },
    {
      "epoch": 2.66,
      "learning_rate": 0.000646398891966759,
      "loss": 1.0581,
      "step": 1228
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.0006457987072945521,
      "loss": 0.9398,
      "step": 1229
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.0006451985226223453,
      "loss": 0.9247,
      "step": 1230
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.0006445983379501385,
      "loss": 0.8449,
      "step": 1231
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.0006439981532779316,
      "loss": 1.0333,
      "step": 1232
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.0006433979686057248,
      "loss": 0.9423,
      "step": 1233
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.000642797783933518,
      "loss": 1.074,
      "step": 1234
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.0006421975992613111,
      "loss": 0.9518,
      "step": 1235
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.0006415974145891043,
      "loss": 0.9347,
      "step": 1236
    },
    {
      "epoch": 2.68,
      "learning_rate": 0.0006409972299168975,
      "loss": 1.0069,
      "step": 1237
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.0006403970452446907,
      "loss": 0.9978,
      "step": 1238
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.0006397968605724838,
      "loss": 1.0774,
      "step": 1239
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.000639196675900277,
      "loss": 0.9292,
      "step": 1240
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.0006385964912280701,
      "loss": 1.009,
      "step": 1241
    },
    {
      "epoch": 2.69,
      "learning_rate": 0.0006379963065558633,
      "loss": 1.0228,
      "step": 1242
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.0006373961218836564,
      "loss": 1.0626,
      "step": 1243
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.0006367959372114496,
      "loss": 1.053,
      "step": 1244
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.0006361957525392428,
      "loss": 0.9628,
      "step": 1245
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.0006355955678670359,
      "loss": 0.8724,
      "step": 1246
    },
    {
      "epoch": 2.7,
      "learning_rate": 0.0006349953831948291,
      "loss": 0.9119,
      "step": 1247
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.0006343951985226223,
      "loss": 0.9954,
      "step": 1248
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.0006337950138504155,
      "loss": 0.9867,
      "step": 1249
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.0006331948291782086,
      "loss": 0.9337,
      "step": 1250
    },
    {
      "epoch": 2.71,
      "learning_rate": 0.0006325946445060018,
      "loss": 0.8957,
      "step": 1251
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.000631994459833795,
      "loss": 0.8952,
      "step": 1252
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.0006313942751615881,
      "loss": 0.9266,
      "step": 1253
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.0006307940904893812,
      "loss": 1.0133,
      "step": 1254
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.0006301939058171744,
      "loss": 0.951,
      "step": 1255
    },
    {
      "epoch": 2.72,
      "learning_rate": 0.0006295937211449676,
      "loss": 0.9626,
      "step": 1256
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.0006289935364727609,
      "loss": 0.9172,
      "step": 1257
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.000628393351800554,
      "loss": 1.0565,
      "step": 1258
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.0006277931671283472,
      "loss": 1.0742,
      "step": 1259
    },
    {
      "epoch": 2.73,
      "learning_rate": 0.0006271929824561404,
      "loss": 0.952,
      "step": 1260
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.0006265927977839335,
      "loss": 1.0288,
      "step": 1261
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.0006259926131117267,
      "loss": 0.8865,
      "step": 1262
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.0006253924284395199,
      "loss": 1.0085,
      "step": 1263
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.000624792243767313,
      "loss": 0.9994,
      "step": 1264
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.0006241920590951062,
      "loss": 1.059,
      "step": 1265
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.0006235918744228994,
      "loss": 1.0322,
      "step": 1266
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.0006229916897506925,
      "loss": 1.1111,
      "step": 1267
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.0006223915050784857,
      "loss": 1.0584,
      "step": 1268
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.0006217913204062788,
      "loss": 1.0131,
      "step": 1269
    },
    {
      "epoch": 2.75,
      "learning_rate": 0.000621191135734072,
      "loss": 1.0356,
      "step": 1270
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.0006205909510618652,
      "loss": 0.9202,
      "step": 1271
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.0006199907663896583,
      "loss": 0.9465,
      "step": 1272
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.0006193905817174515,
      "loss": 1.036,
      "step": 1273
    },
    {
      "epoch": 2.76,
      "learning_rate": 0.0006187903970452447,
      "loss": 0.8899,
      "step": 1274
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0006181902123730378,
      "loss": 1.0025,
      "step": 1275
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.000617590027700831,
      "loss": 0.9076,
      "step": 1276
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0006169898430286242,
      "loss": 0.9168,
      "step": 1277
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0006163896583564174,
      "loss": 0.9096,
      "step": 1278
    },
    {
      "epoch": 2.77,
      "learning_rate": 0.0006157894736842105,
      "loss": 0.9759,
      "step": 1279
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.0006151892890120036,
      "loss": 0.9783,
      "step": 1280
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.0006145891043397968,
      "loss": 0.8593,
      "step": 1281
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.00061398891966759,
      "loss": 1.0393,
      "step": 1282
    },
    {
      "epoch": 2.78,
      "learning_rate": 0.0006133887349953831,
      "loss": 0.9009,
      "step": 1283
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.0006127885503231763,
      "loss": 0.9179,
      "step": 1284
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.0006121883656509695,
      "loss": 0.9678,
      "step": 1285
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.0006115881809787627,
      "loss": 1.0442,
      "step": 1286
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.0006109879963065558,
      "loss": 0.8931,
      "step": 1287
    },
    {
      "epoch": 2.79,
      "learning_rate": 0.000610387811634349,
      "loss": 0.9416,
      "step": 1288
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.0006097876269621422,
      "loss": 1.0413,
      "step": 1289
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.0006091874422899353,
      "loss": 0.99,
      "step": 1290
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.0006085872576177285,
      "loss": 0.9434,
      "step": 1291
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.0006079870729455216,
      "loss": 0.9233,
      "step": 1292
    },
    {
      "epoch": 2.8,
      "learning_rate": 0.0006073868882733148,
      "loss": 1.0037,
      "step": 1293
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.0006067867036011079,
      "loss": 1.0217,
      "step": 1294
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.0006061865189289011,
      "loss": 0.927,
      "step": 1295
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.0006055863342566943,
      "loss": 0.946,
      "step": 1296
    },
    {
      "epoch": 2.81,
      "learning_rate": 0.0006049861495844875,
      "loss": 1.0243,
      "step": 1297
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.0006043859649122806,
      "loss": 0.9615,
      "step": 1298
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.0006037857802400739,
      "loss": 0.9133,
      "step": 1299
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.0006031855955678671,
      "loss": 0.9018,
      "step": 1300
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.0006025854108956602,
      "loss": 0.8441,
      "step": 1301
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.0006019852262234534,
      "loss": 1.0019,
      "step": 1302
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.0006013850415512466,
      "loss": 0.9358,
      "step": 1303
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.0006007848568790397,
      "loss": 1.0303,
      "step": 1304
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.0006001846722068329,
      "loss": 0.9922,
      "step": 1305
    },
    {
      "epoch": 2.83,
      "learning_rate": 0.000599584487534626,
      "loss": 0.9612,
      "step": 1306
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.0005989843028624192,
      "loss": 0.8782,
      "step": 1307
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.0005983841181902124,
      "loss": 0.8491,
      "step": 1308
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.0005977839335180055,
      "loss": 0.9532,
      "step": 1309
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.0005971837488457987,
      "loss": 0.9807,
      "step": 1310
    },
    {
      "epoch": 2.84,
      "learning_rate": 0.0005965835641735919,
      "loss": 1.0053,
      "step": 1311
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.000595983379501385,
      "loss": 1.0438,
      "step": 1312
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.0005953831948291782,
      "loss": 0.8646,
      "step": 1313
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.0005947830101569714,
      "loss": 0.9169,
      "step": 1314
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.0005941828254847646,
      "loss": 1.0142,
      "step": 1315
    },
    {
      "epoch": 2.85,
      "learning_rate": 0.0005935826408125577,
      "loss": 0.9813,
      "step": 1316
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.0005929824561403508,
      "loss": 0.9874,
      "step": 1317
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.000592382271468144,
      "loss": 0.9257,
      "step": 1318
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.0005917820867959372,
      "loss": 0.9186,
      "step": 1319
    },
    {
      "epoch": 2.86,
      "learning_rate": 0.0005911819021237303,
      "loss": 0.8763,
      "step": 1320
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.0005905817174515235,
      "loss": 0.9358,
      "step": 1321
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.0005899815327793167,
      "loss": 1.0712,
      "step": 1322
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.0005893813481071098,
      "loss": 0.9331,
      "step": 1323
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.000588781163434903,
      "loss": 0.9541,
      "step": 1324
    },
    {
      "epoch": 2.87,
      "learning_rate": 0.0005881809787626962,
      "loss": 1.0182,
      "step": 1325
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.0005875807940904894,
      "loss": 1.0986,
      "step": 1326
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.0005869806094182825,
      "loss": 1.0723,
      "step": 1327
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.0005863804247460757,
      "loss": 0.8652,
      "step": 1328
    },
    {
      "epoch": 2.88,
      "learning_rate": 0.0005857802400738689,
      "loss": 0.8565,
      "step": 1329
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.000585180055401662,
      "loss": 0.9548,
      "step": 1330
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.0005845798707294551,
      "loss": 0.995,
      "step": 1331
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.0005839796860572483,
      "loss": 0.9609,
      "step": 1332
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.0005833795013850415,
      "loss": 0.9605,
      "step": 1333
    },
    {
      "epoch": 2.89,
      "learning_rate": 0.0005827793167128347,
      "loss": 1.0278,
      "step": 1334
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.0005821791320406278,
      "loss": 1.0307,
      "step": 1335
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.000581578947368421,
      "loss": 1.0496,
      "step": 1336
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.0005809787626962142,
      "loss": 0.9309,
      "step": 1337
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.0005803785780240073,
      "loss": 0.7627,
      "step": 1338
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.0005797783933518005,
      "loss": 1.0924,
      "step": 1339
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.0005791782086795938,
      "loss": 1.0396,
      "step": 1340
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.0005785780240073868,
      "loss": 0.9921,
      "step": 1341
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.0005779778393351799,
      "loss": 1.0239,
      "step": 1342
    },
    {
      "epoch": 2.91,
      "learning_rate": 0.0005773776546629731,
      "loss": 0.9047,
      "step": 1343
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.0005767774699907664,
      "loss": 0.9053,
      "step": 1344
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.0005761772853185596,
      "loss": 0.8375,
      "step": 1345
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.0005755771006463527,
      "loss": 0.9173,
      "step": 1346
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.0005749769159741459,
      "loss": 0.8564,
      "step": 1347
    },
    {
      "epoch": 2.92,
      "learning_rate": 0.0005743767313019391,
      "loss": 0.8983,
      "step": 1348
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.0005737765466297322,
      "loss": 0.9856,
      "step": 1349
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.0005731763619575254,
      "loss": 1.012,
      "step": 1350
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.0005725761772853186,
      "loss": 0.917,
      "step": 1351
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.0005719759926131117,
      "loss": 1.0667,
      "step": 1352
    },
    {
      "epoch": 2.93,
      "learning_rate": 0.0005713758079409049,
      "loss": 1.0054,
      "step": 1353
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.0005707756232686981,
      "loss": 1.0027,
      "step": 1354
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.0005701754385964912,
      "loss": 1.0743,
      "step": 1355
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.0005695752539242844,
      "loss": 0.9616,
      "step": 1356
    },
    {
      "epoch": 2.94,
      "learning_rate": 0.0005689750692520775,
      "loss": 1.0796,
      "step": 1357
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.0005683748845798707,
      "loss": 1.0257,
      "step": 1358
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.0005677746999076639,
      "loss": 0.9202,
      "step": 1359
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.000567174515235457,
      "loss": 0.9412,
      "step": 1360
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.0005665743305632502,
      "loss": 0.9828,
      "step": 1361
    },
    {
      "epoch": 2.95,
      "learning_rate": 0.0005659741458910434,
      "loss": 0.9313,
      "step": 1362
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.0005653739612188366,
      "loss": 0.9211,
      "step": 1363
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.0005647737765466297,
      "loss": 0.9417,
      "step": 1364
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.0005641735918744229,
      "loss": 1.0674,
      "step": 1365
    },
    {
      "epoch": 2.96,
      "learning_rate": 0.0005635734072022161,
      "loss": 0.8785,
      "step": 1366
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.0005629732225300092,
      "loss": 0.8517,
      "step": 1367
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.0005623730378578023,
      "loss": 0.9338,
      "step": 1368
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.0005617728531855955,
      "loss": 0.8906,
      "step": 1369
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.0005611726685133887,
      "loss": 0.9824,
      "step": 1370
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.0005605724838411818,
      "loss": 0.8913,
      "step": 1371
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.000559972299168975,
      "loss": 0.9932,
      "step": 1372
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.0005593721144967682,
      "loss": 0.9222,
      "step": 1373
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.0005587719298245614,
      "loss": 1.0127,
      "step": 1374
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.0005581717451523545,
      "loss": 0.9303,
      "step": 1375
    },
    {
      "epoch": 2.98,
      "learning_rate": 0.0005575715604801477,
      "loss": 1.024,
      "step": 1376
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.0005569713758079409,
      "loss": 0.9933,
      "step": 1377
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.000556371191135734,
      "loss": 0.9451,
      "step": 1378
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.0005557710064635272,
      "loss": 0.9001,
      "step": 1379
    },
    {
      "epoch": 2.99,
      "learning_rate": 0.0005551708217913203,
      "loss": 1.0191,
      "step": 1380
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.0005545706371191135,
      "loss": 1.003,
      "step": 1381
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.0005539704524469067,
      "loss": 1.0195,
      "step": 1382
    },
    {
      "epoch": 3.0,
      "learning_rate": 0.0005533702677746998,
      "loss": 0.7842,
      "step": 1383
    }
  ],
  "logging_steps": 1,
  "max_steps": 2305,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "total_flos": 7.482702483853148e+17,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
